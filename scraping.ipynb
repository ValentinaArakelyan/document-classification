{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_to_json(script_str):\n",
    "    lines = script_str.strip('\\n| |;').replace(';', ',').replace(\"'\", '\"').split('\\n')\n",
    "    processed_lines = []\n",
    "    for line in lines:\n",
    "        if line.find('=') < 0:\n",
    "            continue\n",
    "        splited = [i.strip(' |;') for i in line.split('=')]\n",
    "        if splited[0][0] != '\"':\n",
    "            splited[0] = '\"'+ splited[0] +'\"'\n",
    "        if splited[1][0] != '\"' and splited[1][0] != '{':\n",
    "            splited[1] = '\"'+ splited[1].strip(',') +'\",'\n",
    "        processed_lines.append(': '.join(splited))\n",
    "        \n",
    "    processed_lines[-1] = processed_lines[-1].strip(',')\n",
    "    \n",
    "    try:\n",
    "        json_str = '{\\n' + '\\n'.join(processed_lines) + '\\n}'\n",
    "        json_obj = json.loads(json_str.encode('utf-8'))\n",
    "        return json_obj\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(json_str)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.aminer.org/conf/ijcai2020/papers\"\n",
    "\n",
    "#If there is no such folder, the script will create one automatically\n",
    "folder_location = r'D:\\Valentina\\Thesis\\papers'\n",
    "#if not os.path.exists(folder_location):os.mkdir(folder_location)\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup= BeautifulSoup(response.text, \"html.parser\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"\">\n",
      " <head>\n",
      "  <title data-react-helmet=\"true\">\n",
      "   IJCAI2020-学术会议 - AMiner\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <!-- <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no\" /> -->\n",
      "  <link href=\"//ssr.aminer.cn/public/umi.605d5d22.css\" rel=\"stylesheet\"/>\n",
      "  <link data-react-helmet=\"true\" href=\"https://originalfileserver.aminer.cn/sys/aminer/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>\n",
      "  <link data-react-helmet=\"true\" href=\"https://originalfileserver.aminer.cn/lib/fa/css/font-awesome.min.css\" rel=\"stylesheet\"/>\n",
      "  <script>\n",
      "   window.routerBase = '/';\n",
      "    window.resourceBaseUrl = '/public/';\n",
      "  </script>\n",
      "  <script src=\"https://static.aminer.cn/misc/ga.js\">\n",
      "  </script>\n",
      "  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=UA-1156684-2\">\n",
      "  </script>\n",
      "  <script>\n",
      "   window.dataLayer = window.dataLayer || [];\n",
      "    function gtag(){dataLayer.push(arguments);}\n",
      "    gtag('js', new Date());\n",
      "    gtag('config', 'UA-1156684-2');\n",
      "  </script>\n",
      "  <meta content=\"IJCAI 2020 会议助手涵盖会议论文、作者列表、论文解读和论文推荐，提供全方位会议信息及分析。\" data-react-helmet=\"true\" name=\"description\"/>\n",
      "  <meta content=\"IJCAI2020, ijcai, ijcai学术会议, Artificial Intelligence, 人工智能\" data-react-helmet=\"true\" name=\"keywords\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div id=\"root\">\n",
      "   <section class=\"mainlayout a-aminer-layouts-index-layout shortNameIndex ant-layout\">\n",
      "    <div class=\"a-aminer-layouts-index-headerPlaceholder\">\n",
      "     <div class=\"a-aminer-layouts-header-header-headerBg a-aminer-layouts-header-header-headerFixed\">\n",
      "      <header class=\"a-aminer-layouts-header-header-header ant-layout-header\">\n",
      "       <div class=\"a-aminer-layouts-header-header-left\">\n",
      "        <div class=\"a-aminer-layouts-header-header-left-zone-logo\">\n",
      "         <a aria-label=\"ckcest\" class=\"a-aminer-layouts-header-header-left-zone-minHide a-aminer-layouts-header-header-left-zone-kst\" href=\"http://www.ckcest.cn/\" rel=\"noopener noreferrer\" target=\"_blank\">\n",
      "          <img alt=\"ckcest\" src=\"https://originalfileserver.aminer.cn/sys/aminer/layout/v1/ckcest_home.png\" style=\"width:38px\" width=\"38px\"/>\n",
      "         </a>\n",
      "         <span class=\"a-aminer-layouts-header-header-left-zone-minHide\">\n",
      "         </span>\n",
      "         <a aria-label=\"aminer\" class=\"a-aminer-layouts-header-header-left-zone-aminer\" href=\"/\">\n",
      "          <svg aria-hidden=\"true\" class=\"icon\" style=\"font-size:72px\">\n",
      "           <use xlink:href=\"#icon-AMinerlogo\">\n",
      "           </use>\n",
      "          </svg>\n",
      "         </a>\n",
      "        </div>\n",
      "        <div class=\"a-aminer-layouts-header-header-nav-nav\">\n",
      "         <div class=\"a-aminer-layouts-header-header-nav-headerNav\">\n",
      "          <a class=\"navItem hiddenNav navNow\" href=\"/\">\n",
      "           Home\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"/user/notification\">\n",
      "           Research-feed\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"/channel\">\n",
      "           Channel\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"/ranks/home\">\n",
      "           Rankings\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"https://gct.aminer.cn/\" target=\"_blank\">\n",
      "           GCT\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"/research_report/articlelist\">\n",
      "           THU AI TR\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"https://aminer.cn/data?nav=openData\" target=\"_blank\">\n",
      "           Open Data\n",
      "          </a>\n",
      "          <a class=\"navItem hiddenNav\" href=\"/topic\">\n",
      "           Must Reading\n",
      "          </a>\n",
      "         </div>\n",
      "         <span class=\"\">\n",
      "          <svg aria-hidden=\"true\" class=\"icon navIcon notHomeColor ant-dropdown-trigger\">\n",
      "           <use xlink:href=\"#icon-caidanshouqi\">\n",
      "           </use>\n",
      "          </svg>\n",
      "         </span>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div class=\"a-aminer-layouts-header-header-right undefined\">\n",
      "        <ul class=\"a-aminer-layouts-header-right-zone-rightInfo\">\n",
      "         <div class=\"a-aminer-layouts-header-widgets-product-list-productIcon\">\n",
      "          <svg aria-hidden=\"true\" class=\"icon product_icon\">\n",
      "           <use xlink:href=\"#icon-list1\">\n",
      "           </use>\n",
      "          </svg>\n",
      "         </div>\n",
      "         <li>\n",
      "          <div class=\"a-aminer-layouts-header-right-zone-dashboard a-aminer-layouts-header-right-zone-text\">\n",
      "           <a class=\"feed\" href=\"/user/notification\">\n",
      "            <span class=\"dot\">\n",
      "            </span>\n",
      "            <svg aria-hidden=\"true\" class=\"icon\">\n",
      "             <use xlink:href=\"#icon-xiaoxi\">\n",
      "             </use>\n",
      "            </svg>\n",
      "            <span class=\"desktop_device\">\n",
      "             Research Feed\n",
      "            </span>\n",
      "           </a>\n",
      "          </div>\n",
      "         </li>\n",
      "         <li class=\"a-aminer-layouts-header-right-zone-user\">\n",
      "          <div class=\"a-aminer-components-widgets-pop-delay-popdelay\">\n",
      "           <div>\n",
      "            <div class=\"user_avatar a-aminer-layouts-header-widgets-user-profile\">\n",
      "             <svg aria-hidden=\"true\" class=\"icon default_icon\">\n",
      "              <use xlink:href=\"#icon-profile\">\n",
      "              </use>\n",
      "             </svg>\n",
      "            </div>\n",
      "           </div>\n",
      "           <div class=\"dropcontent\">\n",
      "            <div class=\"user_info_card a-aminer-layouts-header-widgets-info-card_new-infoCard\">\n",
      "             <div class=\"top not_log\">\n",
      "              <a class=\"image\" href=\"/login?callback=conf%2Fijcai2020%2Fpapers\">\n",
      "               <svg aria-hidden=\"true\" class=\"icon default_icon\">\n",
      "                <use xlink:href=\"#icon-mi\">\n",
      "                </use>\n",
      "               </svg>\n",
      "              </a>\n",
      "              <div class=\"info\">\n",
      "               <a href=\"/login?callback=conf%2Fijcai2020%2Fpapers\">\n",
      "                <span>\n",
      "                 Log in AMiner\n",
      "                </span>\n",
      "               </a>\n",
      "              </div>\n",
      "             </div>\n",
      "             <div class=\"part\">\n",
      "              <a class=\"route list_item\" href=\"/user/scholar\" target=\"_self\">\n",
      "               Academic Profile\n",
      "              </a>\n",
      "              <a class=\"route list_item\" href=\"/user/center\" target=\"_self\">\n",
      "               User Profile\n",
      "              </a>\n",
      "             </div>\n",
      "             <div class=\"part\">\n",
      "              <a class=\"route list_item\" href=\"/user/notification\" target=\"_self\">\n",
      "               Research Feed\n",
      "              </a>\n",
      "              <a class=\"route list_item\" href=\"/user/concern\" target=\"_self\">\n",
      "               My following\n",
      "              </a>\n",
      "              <a class=\"route list_item\" href=\"/user/collections\" target=\"_self\">\n",
      "               Paper Collections\n",
      "              </a>\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "         </li>\n",
      "        </ul>\n",
      "       </div>\n",
      "      </header>\n",
      "     </div>\n",
      "    </div>\n",
      "    <main class=\"layout-body a-aminer-layouts-index-contentWarp a-aminer-layouts-index-contentWidth ant-layout-content\">\n",
      "     <section id=\"aminer_modal\" style=\"visibility:hidden\">\n",
      "      <div class=\"a-aminer-components-widgets-modal-modalBox aminer_common_modal\">\n",
      "       <div class=\"a-aminer-components-widgets-modal-masker\">\n",
      "       </div>\n",
      "       <div class=\"a-aminer-components-widgets-modal-modal\" id=\"aminer_modal_content\">\n",
      "        <div class=\"a-aminer-components-widgets-modal-modalContainer\" style=\"width:600px\">\n",
      "         <header>\n",
      "          <span>\n",
      "          </span>\n",
      "          <span class=\"a-aminer-components-widgets-modal-close\">\n",
      "           <svg aria-hidden=\"true\" class=\"icon a-aminer-components-widgets-modal-closeSvg\">\n",
      "            <use xlink:href=\"#icon-modal_close\">\n",
      "            </use>\n",
      "           </svg>\n",
      "          </span>\n",
      "         </header>\n",
      "         <article>\n",
      "         </article>\n",
      "        </div>\n",
      "       </div>\n",
      "      </div>\n",
      "     </section>\n",
      "     <section id=\"aminer_img_viewer\" style=\"visibility:hidden\">\n",
      "      <div class=\"a-aminer-components-widgets-img-viewer-imgViewerMask\">\n",
      "      </div>\n",
      "      <div class=\"a-aminer-components-widgets-img-viewer-contentWrap\">\n",
      "       <div class=\"a-aminer-components-widgets-img-viewer-imgWrap\">\n",
      "       </div>\n",
      "       <div class=\"a-aminer-components-widgets-img-viewer-close\">\n",
      "        <svg aria-hidden=\"true\" class=\"icon\">\n",
      "         <use xlink:href=\"#icon-close\">\n",
      "         </use>\n",
      "        </svg>\n",
      "       </div>\n",
      "      </div>\n",
      "     </section>\n",
      "     <main class=\"layout-content a-aminer-layouts-index-content ant-layout-content\">\n",
      "      <div class=\"a-aminer-p-conf-c-breadcrumb-navbar\">\n",
      "       <div class=\"a-aminer-p-conf-c-breadcrumb-content\">\n",
      "        <div class=\"a-aminer-p-conf-c-breadcrumb-history\">\n",
      "         <span class=\"a-aminer-p-conf-c-breadcrumb-outBlock\">\n",
      "          <span class=\"a-aminer-p-conf-c-breadcrumb-otherHistory\">\n",
      "           <span>\n",
      "            Conference System\n",
      "           </span>\n",
      "          </span>\n",
      "         </span>\n",
      "         <span class=\"a-aminer-p-conf-c-breadcrumb-outBlock\">\n",
      "          <span class=\"a-aminer-p-conf-c-breadcrumb-split\">\n",
      "          </span>\n",
      "          <span class=\"a-aminer-p-conf-c-breadcrumb-otherHistory a-aminer-p-conf-c-breadcrumb-currentPosition\">\n",
      "           <span>\n",
      "            IJCAI2020\n",
      "           </span>\n",
      "          </span>\n",
      "         </span>\n",
      "        </div>\n",
      "        <div class=\"a-aminer-p-conf-c-breadcrumb-rightZone\">\n",
      "        </div>\n",
      "       </div>\n",
      "      </div>\n",
      "      <div class=\"a-aminer-p-conf-short_name-index-containCrumb\">\n",
      "       <h1 style=\"display:none\">\n",
      "        ijcai2020|国际学习表征会议|AMiner\n",
      "       </h1>\n",
      "       <div>\n",
      "        <div alt=\"ijcai2020|国际学习表征会议|AMiner\" class=\"confHeader\" style=\"background-image:url(https://originalfileserver.aminer.cn/data/conf/conf_bg.jpg)\">\n",
      "         <div class=\"homepage\">\n",
      "          <div class=\"content\">\n",
      "           <div class=\"short_name\">\n",
      "            IJCAI2020\n",
      "           </div>\n",
      "           <div class=\"full_name\">\n",
      "            International Joint Conference on Artificial Intelligence\n",
      "           </div>\n",
      "           <div class=\"date\">\n",
      "            01.05 - 01.10\n",
      "           </div>\n",
      "           <div class=\"url\">\n",
      "            <a href=\"http://www.ijcai20.org/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">\n",
      "             <span>\n",
      "              Website:\n",
      "             </span>\n",
      "             http://www.ijcai20.org/\n",
      "            </a>\n",
      "           </div>\n",
      "          </div>\n",
      "         </div>\n",
      "         <div class=\"viewed\">\n",
      "          <svg aria-hidden=\"true\" class=\"icon\">\n",
      "           <use xlink:href=\"#icon-icon-test\">\n",
      "           </use>\n",
      "          </svg>\n",
      "          <span class=\"viewed_num\">\n",
      "          </span>\n",
      "         </div>\n",
      "        </div>\n",
      "        <div class=\"ConfInfo\">\n",
      "         <div class=\"ant-tabs ant-tabs-top ant-tabs-line ant-tabs-no-animation\">\n",
      "          <div class=\"ant-tabs-bar ant-tabs-top-bar\" role=\"tablist\" style=\"background-color:#f3f3f3\" tabindex=\"0\">\n",
      "           <div class=\"ant-tabs-nav-container\">\n",
      "            <span class=\"ant-tabs-tab-prev ant-tabs-tab-btn-disabled\" unselectable=\"unselectable\">\n",
      "             <span class=\"ant-tabs-tab-prev-icon\">\n",
      "              <i aria-label=\"icon: left\" class=\"anticon anticon-left ant-tabs-tab-prev-icon-target\">\n",
      "               <svg aria-hidden=\"true\" class=\"\" data-icon=\"left\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" viewbox=\"64 64 896 896\" width=\"1em\">\n",
      "                <path d=\"M724 218.3V141c0-6.7-7.7-10.4-12.9-6.3L260.3 486.8a31.86 31.86 0 0 0 0 50.3l450.8 352.1c5.3 4.1 12.9.4 12.9-6.3v-77.3c0-4.9-2.3-9.6-6.1-12.6l-360-281 360-281.1c3.8-3 6.1-7.7 6.1-12.6z\">\n",
      "                </path>\n",
      "               </svg>\n",
      "              </i>\n",
      "             </span>\n",
      "            </span>\n",
      "            <span class=\"ant-tabs-tab-next ant-tabs-tab-btn-disabled\" unselectable=\"unselectable\">\n",
      "             <span class=\"ant-tabs-tab-next-icon\">\n",
      "              <i aria-label=\"icon: right\" class=\"anticon anticon-right ant-tabs-tab-next-icon-target\">\n",
      "               <svg aria-hidden=\"true\" class=\"\" data-icon=\"right\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" viewbox=\"64 64 896 896\" width=\"1em\">\n",
      "                <path d=\"M765.7 486.8L314.9 134.7A7.97 7.97 0 0 0 302 141v77.3c0 4.9 2.3 9.6 6.1 12.6l360 281.1-360 281.1c-3.9 3-6.1 7.7-6.1 12.6V883c0 6.7 7.7 10.4 12.9 6.3l450.8-352.1a31.96 31.96 0 0 0 0-50.4z\">\n",
      "                </path>\n",
      "               </svg>\n",
      "              </i>\n",
      "             </span>\n",
      "            </span>\n",
      "            <div class=\"ant-tabs-nav-wrap\">\n",
      "             <div class=\"ant-tabs-nav-scroll\">\n",
      "              <div class=\"ant-tabs-nav ant-tabs-nav-animated\">\n",
      "               <div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Homepage\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Papers\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Chinese authors\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Paper Insights\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Videos\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Contact us\n",
      "                </div>\n",
      "                <div aria-disabled=\"false\" aria-selected=\"false\" class=\"ant-tabs-tab\" role=\"tab\">\n",
      "                 Recommend\n",
      "                </div>\n",
      "               </div>\n",
      "               <div class=\"ant-tabs-ink-bar ant-tabs-ink-bar-no-animated\">\n",
      "               </div>\n",
      "              </div>\n",
      "             </div>\n",
      "            </div>\n",
      "           </div>\n",
      "          </div>\n",
      "          <div role=\"presentation\" style=\"width:0;height:0;overflow:hidden;position:absolute\" tabindex=\"0\">\n",
      "          </div>\n",
      "          <div class=\"ant-tabs-content ant-tabs-content-no-animated ant-tabs-top-content\">\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "           <div aria-hidden=\"true\" class=\"ant-tabs-tabpane ant-tabs-tabpane-inactive\" role=\"tabpanel\">\n",
      "           </div>\n",
      "          </div>\n",
      "          <div role=\"presentation\" style=\"width:0;height:0;overflow:hidden;position:absolute\" tabindex=\"0\">\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "      </div>\n",
      "     </main>\n",
      "    </main>\n",
      "    <div class=\"a-aminer-layouts-footer-footer-footerBg\">\n",
      "     <footer class=\"footer ant-layout-footer\">\n",
      "      <div class=\"bottom\">\n",
      "       <ul class=\"links\">\n",
      "        <li>\n",
      "         <p>\n",
      "          <span>\n",
      "           © 2005-2020 AMiner\n",
      "          </span>\n",
      "          <a href=\"http://www.beian.miit.gov.cn/\" target=\"_blank\">\n",
      "           京ICP备17059297号-2\n",
      "          </a>\n",
      "         </p>\n",
      "        </li>\n",
      "        <li>\n",
      "         <a href=\"/contact\" target=\"_blank\">\n",
      "          <span>\n",
      "           Contact\n",
      "          </span>\n",
      "         </a>\n",
      "        </li>\n",
      "        <li>\n",
      "         <a href=\"/introduction\" target=\"_blank\">\n",
      "          <span>\n",
      "           Introduction\n",
      "          </span>\n",
      "         </a>\n",
      "        </li>\n",
      "        <li>\n",
      "         <a href=\"/joinus\" target=\"_blank\">\n",
      "          <span>\n",
      "           Join-us\n",
      "          </span>\n",
      "         </a>\n",
      "        </li>\n",
      "        <li>\n",
      "         <a href=\"//reco.aminer.cn/\" rel=\"noopener noreferrer\" target=\"_blank\">\n",
      "          <span>\n",
      "           Reader-recommendation\n",
      "          </span>\n",
      "         </a>\n",
      "        </li>\n",
      "       </ul>\n",
      "       <ul class=\"supports\">\n",
      "        <li>\n",
      "         <a aria-label=\"rss\" class=\"bgRss\" href=\"//www.wjx.top/jq/19719234.aspx\" rel=\"noopener noreferrer\" style=\"background-image:url(https://originalfileserver.aminer.cn/sys/aminer/layout/v1/home_sprites.png)\" target=\"_blank\">\n",
      "         </a>\n",
      "        </li>\n",
      "        <li>\n",
      "         <a aria-label=\"weibo\" class=\"bgWeibo\" href=\"//weibo.com/arnetminer\" rel=\"noopener noreferrer\" style=\"background-image:url(https://originalfileserver.aminer.cn/sys/aminer/layout/v1/home_sprites.png)\" target=\"_blank\">\n",
      "         </a>\n",
      "        </li>\n",
      "        <li>\n",
      "         <span class=\"bgWechat\" style=\"background-image:url(https://originalfileserver.aminer.cn/sys/aminer/layout/v1/home_sprites.png)\">\n",
      "         </span>\n",
      "         <div class=\"RQcode\">\n",
      "          <img alt=\"RQcode\" src=\"https://originalfileserver.aminer.cn/sys/aminer/wechat.jpg\"/>\n",
      "         </div>\n",
      "        </li>\n",
      "       </ul>\n",
      "      </div>\n",
      "     </footer>\n",
      "    </div>\n",
      "   </section>\n",
      "  </div>\n",
      "  <script>\n",
      "   window.g_useSSR = true;\n",
      "  window.g_initialProps = {\"aminerConf\":{\"confInfo\":{\"address\":\"Yokohama, Japan\",\"begin_date\":\"2021-01-05T10:11:12.818Z\",\"config\":{\"breadcrumb\":true,\"navigator\":[\"homepage\",\"papers\",\"roster\",\"news\",\"videos\",\"contact\",\"recommend\"],\"homepage\":{\"ads\":true},\"left\":[\"keywords\",\"leftAuthors\"],\"right\":[\"statistics\",\"insight\"],\"paper\":{\"navigator\":[\"paper\"],\"category\":[],\"download_org\":[{\"key\":\"all\",\"val\":\"下载全部\",\"link\":\"https:\\u002F\\u002Fpan.baidu.com\\u002Fs\\u002F11FioZCMwufp-hqLJHpzVzw \",\"code\":\"9pls\"}]},\"roster\":{\"navigator\":[\"chinese-scholar\",\"chinese-first\",\"authors\"]},\"tdk\":{\"pageTitle\":\"IJCAI2020-学术会议\",\"pageDesc\":\"IJCAI 2020 会议助手涵盖会议论文、作者列表、论文解读和论文推荐，提供全方位会议信息及分析。\",\"pageKeywords\":\"IJCAI2020, ijcai, ijcai学术会议, Artificial Intelligence, 人工智能\"}},\"created_time\":\"2020-06-28T10:13:09.291Z\",\"creator\":\"54f5112e45ce1bc6d563b8d9\",\"eid\":[\"5efc4c4a4c775ed682ed406a\",\"5efd3b724c775ed682ed805c\"],\"end_date\":\"2021-01-10T10:11:12.818Z\",\"full_name\":\"International Joint Conference on Artificial Intelligence\",\"id\":\"5ef86d3592c7f9be218d4b9b\",\"introduce\":\"IJCAI-PRICAI2020 will take place in the Pacifico Yokohama, officially known as Pacifico Convention Plaza Yokohama, which is one of the largest convention and exhibition centers in Japan. The center is located in the waterfront Minato Mirai. Minato Mirai is a major center for business, shopping, and tourism, attracting visitors and businesspeople throughout the Greater Tokyo Area. Minato Mirai also attracts numerous tourists, as does the nearby Yokohama Chinatown.\",\"is_public\":true,\"logo\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fbuildin\\u002Fconfs\\u002F1470\\u002F45\\u002F142\\u002F5ef86d3592c7f9be218d4b9b_1.jpg\",\"order\":1,\"paper_count\":645,\"short_name\":\"ijcai2020\",\"updated_time\":\"2020-11-30T09:06:33.153Z\",\"url\":\"http:\\u002F\\u002Fwww.ijcai20.org\\u002F\",\"year\":2020},\"timeTable\":undefined,\"SearchPubsData\":{\"items\":[{\"abstract\":\"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.\",\"aids\":[\"562d52a145cedb3398dc4e62\",\"53f5735cdabfae7b13f8045b\",\"53f4c7b3dabfaee57877ceca\",\"53f39418dabfae4b34a67084\"],\"authors\":[{\"id\":\"562d52a145cedb3398dc4e62\",\"name\":\"Devendra Singh Chaplot\"},{\"name\":\"Lisa Lee\"},{\"id\":\"53f5735cdabfae7b13f8045b\",\"name\":\"Ruslan Salakhutdinov\"},{\"id\":\"53f4c7b3dabfaee57877ceca\",\"name\":\"Devi Parikh\"},{\"id\":\"53f39418dabfae4b34a67084\",\"name\":\"Dhruv Batra\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"\",\"headline\":\"We show that the proposed model is able to transfer the knowledge of concepts across tasks and outperforms the baselines on both Semantic Goal Navigation and Embodied Question Answering by a considerable margin\",\"id\":\"5cede0f0da562983788cec6c\",\"is_like\":false,\"lang\":\"en\",\"mrt_link\":\"5f4e0501d46315233238167a\",\"num_citation\":0,\"num_like\":8,\"num_viewed\":558,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002Fprogram\\u002F5cede0f0da562983788cec6c_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5cede0f0da562983788cec6c_0.pdf_4giexpl7_images_1oa_h4a1\\u002Fimg-002.png\",\"title\":\"Embodied Multimodal Multitask Learning.\",\"year\":2019},{\"abstract\":\"  A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders with arbitrary manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the Diffusion Variational Autoencoder is capable of capturing topological properties of synthetic datasets. Additionally, we train MNIST on spheres, tori, projective spaces, SO(3), and a torus embedded in R3. Although a natural dataset like MNIST does not have latent variables with a clear-cut topological structure, training it on a manifold can still highlight topological and geometrical properties. \",\"aids\":[\"562befd945ce1e59672605d2\",\"53f446a1dabfaee02ad19c3a\"],\"authors\":[{\"id\":\"562befd945ce1e59672605d2\",\"name\":\"Luis A. P&eacute;rez Rey\"},{\"id\":\"53f446a1dabfaee02ad19c3a\",\"name\":\"Vlado Menkovski\"},{\"name\":\"Jacobus W. Portegies\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"headline\":\"We developed and implemented Diffusion Variational Autoencoders, which allow for arbitrary manifolds as a latent space 1\",\"id\":\"5cede0f1da562983788cf9db\",\"is_like\":false,\"lang\":\"en\",\"mrt_link\":\"5f4e050dd4631523323817e0\",\"num_citation\":8,\"num_like\":0,\"num_viewed\":432,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F19\\u002F1901\\u002F1901.08991.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F1901.08991.pdf_7hbjasud_images_h446zzie\\u002Fimg-001.png\",\"title\":\"Diffusion Variational Autoencoders.\",\"year\":2019},{\"aids\":[\"53f4324cdabfaeb22f446b37\",\"560a0cf245ce1e595fb1333b\",\"542a2a04dabfae5848aa3005\"],\"authors\":[{\"id\":\"53f4324cdabfaeb22f446b37\",\"name\":\"Chao Li\"},{\"id\":\"560a0cf245ce1e595fb1333b\",\"name\":\"Baolin Liu\"},{\"id\":\"542a2a04dabfae5848aa3005\",\"name\":\"Jianguo Wei\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F103\",\"headline\":\"Based on the concept of shared features, we built encoding models to explore the relationship between the deep convolutional neural networks and human brain activity, and proposed a reconstruction method for decoding brain signals\",\"id\":\"5ef96b048806af6ef2772066\",\"is_like\":false,\"mrt_link\":\"5f4e0517d4631523323818e6\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":400,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0103.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0103.pdf_i8cosexo_images_p99mhwn4\\u002Fimg-001.png\",\"title\":\"Visual Encoding and Decoding of the Human Brain Based on Shared Features\",\"year\":2020},{\"aids\":[\"561aaf8145cedb3397ea5619\",\"5429704cdabfae82c0e59767\",\"5d43d54e7390bff0db600ec1\",\"5d43d54e7390bff0db600ecb\",\"542a4d53dabfae61d49671e5\",\"53f435c9dabfaee43ec2b29c\",\"542a5f39dabfae61d497310f\"],\"authors\":[{\"id\":\"561aaf8145cedb3397ea5619\",\"name\":\"Hongmin Zhu\"},{\"id\":\"5429704cdabfae82c0e59767\",\"name\":\"Fuli Feng\"},{\"id\":\"5d43d54e7390bff0db600ec1\",\"name\":\"Xiangnan He\"},{\"id\":\"5d43d54e7390bff0db600ecb\",\"name\":\"Xiang Wang\"},{\"id\":\"542a4d53dabfae61d49671e5\",\"name\":\"Yan Li\"},{\"id\":\"53f435c9dabfaee43ec2b29c\",\"name\":\"Kai Zheng\"},{\"id\":\"542a5f39dabfae61d497310f\",\"name\":\"Yongdong Zhang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F202\",\"headline\":\"We proposed Bilinear Graph Neural Network, a new graph neural network framework, which augments the expressiveness of vanilla Graph Neural Network by considering the interactions between neighbor nodes\",\"id\":\"5ef96b048806af6ef2772079\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238168a\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":353,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0202.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0202.pdf_oljtg_ml_images_a6ukth8v\\u002Fimg-001.png\",\"title\":\"Bilinear Graph Neural Network with Neighbor Interactions\",\"year\":2020},{\"aids\":[\"5609328045cedb3396e4fb5a\",\"5625328c45cedb3398592763\",\"542ce893dabfae216e635dd8\",\"53f43e5fdabfaec09f1b56fc\",\"53f325a3dabfae9a8446fa8f\",\"542ce910dabfae4b91c2d971\",\"53f642d9dabfaed4ec0f3d1a\"],\"authors\":[{\"id\":\"5609328045cedb3396e4fb5a\",\"name\":\"Zhongxia Chen\"},{\"id\":\"5625328c45cedb3398592763\",\"name\":\"Xiting Wang\"},{\"id\":\"542ce893dabfae216e635dd8\",\"name\":\"Xing Xie\"},{\"id\":\"53f43e5fdabfaec09f1b56fc\",\"name\":\"Mehul Parsana\"},{\"id\":\"53f325a3dabfae9a8446fa8f\",\"name\":\"Akshay Soni\"},{\"id\":\"542ce910dabfae4b91c2d971\",\"name\":\"Xiang Ao\"},{\"id\":\"53f642d9dabfaed4ec0f3d1a\",\"name\":\"Enhong Chen\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F414\",\"headline\":\"We propose a framework for explainable conversational recommendation, which enables tight collaboration between the recommendation task, the explanation generation task, and the incremental feedback integration module\",\"id\":\"5ef96b048806af6ef277218c\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381679\",\"num_citation\":0,\"num_like\":2,\"num_viewed\":336,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0414.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0414.pdf_59o7rmld_images_idbhf1ao\\u002Fimg-001.png\",\"title\":\"Towards Explainable Conversational Recommendation\",\"year\":2020},{\"aids\":[\"542d8ffddabfae48d12392e2\",\"561a410a45ce1e59645fd5c0\",\"53f4720bdabfaee1c0b9435d\",\"56046cf445cedb33963c4447\"],\"authors\":[{\"id\":\"542d8ffddabfae48d12392e2\",\"name\":\"Tong Wu\"},{\"id\":\"561a410a45ce1e59645fd5c0\",\"name\":\"Bicheng Dai\"},{\"name\":\"Shuxin Chen\"},{\"id\":\"53f4720bdabfaee1c0b9435d\",\"name\":\"Yanyun Qu\"},{\"id\":\"56046cf445cedb33963c4447\",\"name\":\"Yuan Xie\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F76\",\"headline\":\"We propose Meta Segmentation Network for the effective segmentation of medical ultra-resolution image\",\"id\":\"5ef96b048806af6ef2772042\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167f\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":318,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0076.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0076.pdf_ke1f37gq_images_os6i52d4\\u002Fimg-001.png\",\"title\":\"Meta Segmentation Network for Ultra-Resolution Medical Images\",\"year\":2020},{\"abstract\":\"  Multi-lingual contextualized embeddings, such as multilingual-BERT (mBERT), have shown success in a variety of zero-shot cross-lingual tasks. However, these models are limited by having inconsistent contextualized representations of subwords across different languages. Existing work addresses this issue by bilingual projection and fine-tuning technique. We propose a data augmentation framework to generate multi-lingual code-switching data to fine-tune mBERT, which encourages model to align representations from source and multiple target languages once by mixing their context information. Compared with the existing work, our method does not rely on bilingual sentences for training, and requires only one training process for multiple target languages. Experimental results on five tasks with 19 languages show that our method leads to significantly improved performances for all the tasks compared with mBERT. \",\"aids\":[\"5448b07bdabfae1e04135dad\",\"53f80060dabfae8faa4cea01\",\"53f42c90dabfaee02ac54f1b\"],\"authors\":[{\"id\":\"5448b07bdabfae1e04135dad\",\"name\":\"Qin Libo\"},{\"name\":\"Ni Minheng\"},{\"id\":\"53f80060dabfae8faa4cea01\",\"name\":\"Zhang Yue\"},{\"id\":\"53f42c90dabfaee02ac54f1b\",\"name\":\"Che Wanxiang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F533\",\"headline\":\"We proposed an augmentation framework to generate multilingual code-switching data to fine-tune mBERT for aligning representations from source and multiple target languages\",\"id\":\"5ee3527191e011cb3bff760a\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381689\",\"num_citation\":0,\"num_like\":2,\"num_viewed\":312,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F265\\u002F1170\\u002F1990\\u002F5ee3527191e011cb3bff760a_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5ee3527191e011cb3bff760a_0.pdf_b5t6394e_images_ndba6j0m\\u002Fimg-001.png\",\"resources\":{\"code\":[{\"desc\":\"\",\"link\":\"https:\\u002F\\u002Fgithub.com\\u002Fkodenii\\u002FCoSDA-ML\",\"peek\":\"\"}]},\"title\":\"CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot\\n  Cross-Lingual NLP\",\"year\":2020},{\"abstract\":\"  Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. \",\"aids\":[\"562b072845cedb3398967594\",\"53f43331dabfaedce550dffa\",\"54055181dabfae92b41c32d0\",\"53f4da76dabfaef7e377b3e6\",\"53f470e3dabfaee02adbdea8\",\"53fa0e27dabfae91d3fc74ec\",\"5486c666dabfae9b40134002\"],\"authors\":[{\"name\":\"Chen Daoyuan\"},{\"id\":\"562b072845cedb3398967594\",\"name\":\"Li Yaliang\"},{\"id\":\"53f43331dabfaedce550dffa\",\"name\":\"Qiu Minghui\"},{\"name\":\"Wang Zhen\"},{\"name\":\"Li Bofang\"},{\"id\":\"53f4da76dabfaef7e377b3e6\",\"name\":\"Ding Bolin\"},{\"id\":\"53f470e3dabfaee02adbdea8\",\"name\":\"Deng Hongbo\"},{\"name\":\"Huang Jun\"},{\"id\":\"53fa0e27dabfae91d3fc74ec\",\"name\":\"Lin Wei\"},{\"id\":\"5486c666dabfae9b40134002\",\"name\":\"Zhou Jingren\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F341\",\"headline\":\"Extensive experiments demonstrate that AdaBERT achieves comparable performance while significantly improves the efficiency by 12.7x to 29.3x speedup in inference time and 11.5x to 17.0x compression ratio in parameter size\",\"id\":\"5e1d915f3a55ac91798fe9bf\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167d\",\"num_citation\":5,\"num_like\":0,\"num_viewed\":310,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2001\\u002F2001.04246.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2001.04246.pdf_u5d6lumm_images_471yak8x\\u002Fimg-001.png\",\"title\":\"AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\\n  Architecture Search\",\"year\":2020},{\"abstract\":\"  Channel pruning is among the predominant approaches to compress deep neural networks. To this end, most existing pruning methods focus on selecting channels (filters) by importance\\u002Foptimization or regularization based on rule-of-thumb designs, which defects in sub-optimal pruning. In this paper, we propose a new channel pruning method based on artificial bee colony algorithm (ABC), dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \\\"important\\\" channels as previous works did. To solve the intractably huge combinations of pruned structure for deep networks, we first propose to shrink the combinations where the preserved channels are limited to a specific space, thus the combinations of pruned structure can be significantly reduced. And then, we formulate the search of optimal pruned structure as an optimization problem and integrate the ABC algorithm to solve it in an automatic manner to lessen human interference. ABCPruner has been demonstrated to be more effective, which also enables the fine-tuning to be conducted efficiently in an end-to-end manner. Experiments on CIFAR-10 show that ABCPruner reduces 73.68\\\\% of FLOPs and 88.68\\\\% of parameters with even 0.06\\\\% accuracy improvement for VGGNet-16. On ILSVRC-2012, it achieves a reduction of 62.87\\\\% FLOPs and removes 60.01\\\\% of parameters with negligible accuracy cost for ResNet-152. The source codes can be available at https:\\u002F\\u002Fgithub.com\\u002Flmbxmu\\u002FABCPruner. \",\"aids\":[\"5620512a45ceff436be1f4c2\",\"5484d882dabfaed7b5fa1c4d\",\"560fc42d45cedb339777a222\",\"560b36c945cedb33972977e1\",\"53f43c26dabfaee2a1d1a9b6\",\"542a50a2dabfae61d496977f\"],\"authors\":[{\"id\":\"5620512a45ceff436be1f4c2\",\"name\":\"Lin Mingbao\"},{\"id\":\"5484d882dabfaed7b5fa1c4d\",\"name\":\"Ji Rongrong\"},{\"id\":\"560fc42d45cedb339777a222\",\"name\":\"Zhang Yuxin\"},{\"id\":\"560b36c945cedb33972977e1\",\"name\":\"Zhang Baochang\"},{\"id\":\"53f43c26dabfaee2a1d1a9b6\",\"name\":\"Wu Yongjian\"},{\"id\":\"542a50a2dabfae61d496977f\",\"name\":\"Tian Yonghong\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F94\",\"headline\":\"We propose a new channel pruning method based on artificial bee colony algorithm, dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \\\"important\\\" channels as previous works did\",\"id\":\"5e2ac03c3a55ac8999c1ae65\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381684\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":307,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2001\\u002F2001.08565.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2001.08565.pdf_gcdhtczj_images_w8c2jure\\u002Fimg-001.png\",\"title\":\"Channel Pruning via Automatic Structure Search\",\"year\":2020},{\"abstract\":\"  To enable DNNs on edge devices like mobile phones, low-rank approximation has been widely adopted because of its solid theoretical rationale and efficient implementations. Several previous works attempted to directly approximate a pretrained model by low-rank decomposition; however, small approximation errors in parameters can ripple over a large prediction loss. As a result, performance usually drops significantly and a sophisticated effort on fine-tuning is required to recover accuracy. Apparently, it is not optimal to separate low-rank approximation from training. Unlike previous works, this paper integrates low rank approximation and regularization into the training process. We propose Trained Rank Pruning (TRP), which alternates between low rank approximation and training. TRP maintains the capacity of the original network while imposing low-rank constraints during training. A nuclear regularization optimized by stochastic sub-gradient descent is utilized to further promote low rank in TRP. The TRP trained network inherently has a low-rank structure, and is approximated with negligible performance loss, thus eliminating the fine-tuning process after low rank decomposition. The proposed method is comprehensively evaluated on CIFAR-10 and ImageNet, outperforming previous compression methods using low rank approximation. \",\"aids\":[\"5606d9d345ce1e595ed46ac1\",\"562c7d4445cedb3398c3a177\",\"5632020f45cedb3399f90317\",\"53f4496bdabfaee4dc7dd654\",\"53f42f40dabfaeb1a7ba3174\",\"53f43838dabfaeb22f48248b\",\"562b045545cedb3398963955\",\"53f4675edabfaeecd6a10d6d\"],\"authors\":[{\"id\":\"5606d9d345ce1e595ed46ac1\",\"name\":\"Xu Yuhui\"},{\"name\":\"Li Yuxi\"},{\"id\":\"562c7d4445cedb3398c3a177\",\"name\":\"Zhang Shuai\"},{\"id\":\"5632020f45cedb3399f90317\",\"name\":\"Wen Wei\"},{\"id\":\"53f4496bdabfaee4dc7dd654\",\"name\":\"Wang Botao\"},{\"id\":\"53f42f40dabfaeb1a7ba3174\",\"name\":\"Qi Yingyong\"},{\"id\":\"53f43838dabfaeb22f48248b\",\"name\":\"Chen Yiran\"},{\"id\":\"562b045545cedb3398963955\",\"name\":\"Lin Weiyao\"},{\"id\":\"53f4675edabfaeecd6a10d6d\",\"name\":\"Xiong Hongkai\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F136\",\"headline\":\"We proposed a new scheme Trained Rank Pruning for training low-rank networks\",\"id\":\"5eabf34391e011664ffd2878\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167e\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":302,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2004\\u002F2004.14566.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2004.14566.pdf_bjg7kym8_images_5mr7lob2\\u002Fimg-001.png\",\"title\":\"TRP: Trained Rank Pruning for Efficient Deep Neural Networks\",\"year\":2020},{\"abstract\":\"  Deep neural networks have gained tremendous success in a broad range of machine learning tasks due to its remarkable capability to learn semantic-rich features from high-dimensional data. However, they often require large-scale labelled data to successfully learn such features, which significantly hinders their adaption into unsupervised learning tasks, such as anomaly detection and clustering, and limits their applications into critical domains where obtaining massive labelled data is prohibitively expensive. To enable downstream unsupervised learning on those domains, in this work we propose to learn features without using any labelled data by training neural networks to predict data distances in a randomly projected space. Random mapping is a theoretical proven approach to obtain approximately preserved distances. To well predict these random distances, the representation learner is optimised to learn genuine class structures that are implicitly embedded in the randomly projected space. Experimental results on 19 real-world datasets show our learned representations substantially outperform state-of-the-art competing methods in both anomaly detection and clustering tasks. \",\"aids\":[\"542cc671dabfae498ae10964\",\"53f46a4ddabfaee2a1dbeb2c\",\"54850e41dabfaed7b5fa1edb\"],\"authors\":[{\"id\":\"542cc671dabfae498ae10964\",\"name\":\"Wang Hu\"},{\"id\":\"53f46a4ddabfaee2a1dbeb2c\",\"name\":\"Pang Guansong\"},{\"id\":\"54850e41dabfaed7b5fa1edb\",\"name\":\"Shen Chunhua\"},{\"name\":\"Ma Congbo\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F408\",\"headline\":\"We introduce a novel Random Distance Prediction model which learns features in a fully unsupervised fashion by predicting data distances in a randomly projected space\",\"id\":\"5e09caba3a55ac662f721bd7\",\"is_like\":false,\"mrt_link\":\"5f4e0502d463152332381698\",\"num_citation\":1,\"num_like\":1,\"num_viewed\":264,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F1589\\u002F822\\u002F248\\u002F5e09caba3a55ac662f721bd7_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5e09caba3a55ac662f721bd7_0.pdf_sww0vua9_images_3r8rue87\\u002Fimg-001.png\",\"title\":\"Unsupervised Representation Learning by Predicting Random Distances\",\"year\":2019},{\"abstract\":\"  System combination is an important technique for combining the hypotheses of different machine translation systems to improve translation performance. Although early statistical approaches to system combination have been proven effective in analyzing the consensus between hypotheses, they suffer from the error propagation problem due to the use of pipelines. While this problem has been alleviated by end-to-end training of multi-source sequence-to-sequence models recently, these neural models do not explicitly analyze the relations between hypotheses and fail to capture their agreement because the attention to a word in a hypothesis is calculated independently, ignoring the fact that the word might occur in multiple hypotheses. In this work, we propose an approach to modeling voting for system combination in machine translation. The basic idea is to enable words in hypotheses from different systems to vote on words that are representative and should get involved in the generation process. This can be done by quantifying the influence of each voter and its preference for each candidate. Our approach combines the advantages of statistical and neural methods since it can not only analyze the relations between hypotheses but also allow for end-to-end training. Experiments show that our approach is capable of better taking advantage of the consensus between hypotheses and achieves significant improvements over state-of-the-art baselines on Chinese-English and English-German machine translation tasks. \",\"aids\":[\"53f43253dabfaeb2ac0290d7\",\"53f42eeadabfaee02ac747ce\",\"542c23f0dabfaed7e63f7b4f\",\"53f4d3f6dabfaef205f81ad0\",\"53f42dc0dabfaedce54ca0bb\",\"5624979245cedb3398527696\",\"5429defadabfaec7081c26e4\",\"562506cd45cedb3398570152\"],\"authors\":[{\"id\":\"53f43253dabfaeb2ac0290d7\",\"name\":\"Xuancheng Huang\"},{\"id\":\"53f42eeadabfaee02ac747ce\",\"name\":\"Jiacheng Zhang\"},{\"id\":\"542c23f0dabfaed7e63f7b4f\",\"name\":\"Zhixing Tan\"},{\"id\":\"53f4d3f6dabfaef205f81ad0\",\"name\":\"Derek F. Wong\"},{\"id\":\"53f42dc0dabfaedce54ca0bb\",\"name\":\"Huanbo Luan\"},{\"id\":\"5624979245cedb3398527696\",\"name\":\"Jingfang Xu\"},{\"id\":\"5429defadabfaec7081c26e4\",\"name\":\"Maosong Sun\"},{\"id\":\"562506cd45cedb3398570152\",\"name\":\"Yang Liu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F511\",\"headline\":\"We have presented a voting mechanism for system combination in machine translation\",\"id\":\"5ef96b048806af6ef27721ea\",\"is_like\":false,\"mrt_link\":\"5f364d979e9598217a91c6ad\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":253,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2007\\u002F2007.06943.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2007.06943.pdf_7auhy_l0_images_ndvzt9kh\\u002Fimg-001.png\",\"title\":\"Modeling Voting for System Combination in Machine Translation\",\"year\":2020},{\"abstract\":\"  Implicit discourse relation classification is one of the most difficult parts in shallow discourse parsing as the relation prediction without explicit connectives requires the language understanding at both the text span level and the sentence level. Previous studies mainly focus on the interactions between two arguments. We argue that a powerful contextualized representation module, a bilateral multi-perspective matching module, and a global information fusion module are all important to implicit discourse analysis. We propose a novel model to combine these modules together. Extensive experiments show that our proposed model outperforms BERT and other state-of-the-art systems on the PDTB dataset by around 8% and CoNLL 2016 datasets around 16%. We also analyze the effectiveness of different modules in the implicit discourse relation classification task and demonstrate how different levels of representation learning can affect the results. \",\"aids\":[\"56077d1c45ce1e595f127ae1\",\"54849c88dabfae9b40132fad\",\"5d43d51b7390bff0db5fefc5\"],\"authors\":[{\"id\":\"56077d1c45ce1e595f127ae1\",\"name\":\"Liu Xin\"},{\"name\":\"Ou Jiefu\"},{\"id\":\"54849c88dabfae9b40132fad\",\"name\":\"Song Yangqiu\"},{\"id\":\"5d43d51b7390bff0db5fefc5\",\"name\":\"Jiang Xin\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F530\",\"headline\":\"We present a novel model, BMGF-RoBERTa, that combines representation, matching, and fusion modules for implicit discourse relation classification\",\"id\":\"5ea8009091e0111d387ee83a\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381681\",\"num_citation\":0,\"num_like\":4,\"num_viewed\":250,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2004\\u002F2004.12617.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2004.12617.pdf_3760bwmn_images_y7v96djw\\u002Fimg-001.png\",\"title\":\"On the Importance of Word and Sentence Representation Learning in\\n  Implicit Discourse Relation Classification\",\"year\":2020},{\"aids\":[\"56187ad945ce1e5964076103\",\"562b072845cedb3398967594\",\"542ce9bddabfae216e635f49\",\"53f446a6dabfaee02ad19d77\",\"53f47977dabfae8a6845b643\"],\"authors\":[{\"id\":\"56187ad945ce1e5964076103\",\"name\":\"Chenwei Zhang\"},{\"id\":\"562b072845cedb3398967594\",\"name\":\"Yaliang Li\"},{\"id\":\"542ce9bddabfae216e635f49\",\"name\":\"Nan Du\"},{\"id\":\"53f446a6dabfaee02ad19d77\",\"name\":\"Wei Fan\"},{\"id\":\"53f47977dabfae8a6845b643\",\"name\":\"Philip S. Yu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F199\",\"headline\":\"We report the precision at position K, recall at position K, and F1 score at position K\",\"id\":\"5ef96b048806af6ef277207e\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167b\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":249,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F1865\\u002F1703\\u002F1909\\u002F5ef96b048806af6ef277207e_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0199.pdf_4dnz7bt0_images_i1zijwl1\\u002Fimg-001.png\",\"title\":\"Entity Synonym Discovery via Multipiece Bilateral Context Matching\",\"year\":2020},{\"abstract\":\"  Neural architecture search (NAS) proves to be among the best approaches for many tasks by generating an application-adaptive neural architecture, which is still challenged by high computational cost and memory consumption. At the same time, 1-bit convolutional neural networks (CNNs) with binarized weights and activations show their potential for resource-limited embedded devices. One natural approach is to use 1-bit CNNs to reduce the computation and memory cost of NAS by taking advantage of the strengths of each in a unified framework. To this end, a Child-Parent (CP) model is introduced to a differentiable NAS to search the binarized architecture (Child) under the supervision of a full-precision model (Parent). In the search stage, the Child-Parent model uses an indicator generated by the child and parent model accuracy to evaluate the performance and abandon operations with less potential. In the training stage, a kernel-level CP loss is introduced to optimize the binarized network. Extensive experiments demonstrate that the proposed CP-NAS achieves a comparable accuracy with traditional NAS on both the CIFAR and ImageNet databases. It achieves the accuracy of $95.27\\\\%$ on CIFAR-10, $64.3\\\\%$ on ImageNet with binarized weights and activations, and a $30\\\\%$ faster search than prior arts. \",\"aids\":[\"560b36c945cedb33972977e1\",\"542a623fdabfae646d559b98\",\"542ab5a8dabfae646d58179a\",\"562df3e845ce1e5967b7a48c\",\"53f4d100dabfaeedd977eb33\"],\"authors\":[{\"name\":\"Li'an Zhuo\"},{\"id\":\"560b36c945cedb33972977e1\",\"name\":\"Baochang Zhang\"},{\"id\":\"542a623fdabfae646d559b98\",\"name\":\"Hanlin Chen\"},{\"id\":\"542ab5a8dabfae646d58179a\",\"name\":\"Linlin Yang\"},{\"id\":\"562df3e845ce1e5967b7a48c\",\"name\":\"Chen Chen\"},{\"name\":\"Yanjun Zhu\"},{\"id\":\"53f4d100dabfaeedd977eb33\",\"name\":\"David Doermann\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F144\",\"headline\":\"We calculate 1-bit convolutional neural networks based on the proposed Child-Parent model under the full-precision network supervision\",\"id\":\"5eafe7e091e01198d3986547\",\"is_like\":false,\"mrt_link\":\"5eba73c1d9c8f52685b16eb9\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":235,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F873\\u002F1798\\u002F118\\u002F5eafe7e091e01198d3986547_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5eafe7e091e01198d3986547_0.pdf_qg_ou4z2_images_d30h6o33\\u002Fimg-001.png\",\"title\":\"CP-NAS: Child-Parent Neural Architecture Search for 1-bit CNNs\",\"year\":2020},{\"abstract\":\"  Policy distillation, which transfers a teacher policy to a student policy has achieved great success in challenging tasks of deep reinforcement learning. This teacher-student framework requires a well-trained teacher model which is computationally expensive. Moreover, the performance of the student model could be limited by the teacher model if the teacher model is not optimal. In the light of collaborative learning, we study the feasibility of involving joint intellectual efforts from diverse perspectives of student models. In this work, we introduce dual policy distillation(DPD), a student-student framework in which two learners operate on the same environment to explore different perspectives of the environment and extract knowledge from each other to enhance their learning. The key challenge in developing this dual learning framework is to identify the beneficial knowledge from the peer learner for contemporary learning-based reinforcement learning algorithms, since it is unclear whether the knowledge distilled from an imperfect and noisy peer learner would be helpful. To address the challenge, we theoretically justify that distilling knowledge from a peer learner will lead to policy improvement and propose a disadvantageous distillation strategy based on the theoretical results. The conducted experiments on several continuous control tasks show that the proposed framework achieves superior performance with a learning-based agent and function approximation without the use of expensive teacher models. \",\"aids\":[\"562c44f945cedb3398bd61e8\",\"5d50c3f97390bff0db2abd30\",\"5d415c0c7390bff0db70c464\",\"542a95efdabfae61d4993355\"],\"authors\":[{\"id\":\"562c44f945cedb3398bd61e8\",\"name\":\"Lai Kwei-Herng\"},{\"id\":\"5d50c3f97390bff0db2abd30\",\"name\":\"Zha Daochen\"},{\"id\":\"5d415c0c7390bff0db70c464\",\"name\":\"Li Yuening\"},{\"id\":\"542a95efdabfae61d4993355\",\"name\":\"Hu Xia\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F435\",\"headline\":\"We introduce dual policy distillation, a studentstudent framework which enables two policies to explore different aspects of the environment and exploit the knowledge from each other\",\"id\":\"5edf5dd891e011bc656ded14\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381685\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":234,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F826\\u002F467\\u002F128\\u002F5edf5dd891e011bc656ded14_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5edf5dd891e011bc656ded14_0.pdf_na6ejhu6_images_lzmy8dlk\\u002Fimg-001.png\",\"title\":\"Dual Policy Distillation\",\"year\":2020},{\"abstract\":\"  A rising vision for AI in the open world centers on the development of systems that can complement humans for perceptual, diagnostic, and reasoning tasks. To date, systems aimed at complementing the skills of people have employed models trained to be as accurate as possible in isolation. We demonstrate how an end-to-end learning strategy can be harnessed to optimize the combined performance of human-machine teams by considering the distinct abilities of people and machines. The goal is to focus machine learning on problem instances that are difficult for humans, while recognizing instances that are difficult for the machine and seeking human input on them. We demonstrate in two real-world domains (scientific discovery and medical diagnosis) that human-machine teams built via these methods outperform the individual performance of machines and people. We then analyze conditions under which this complementarity is strongest, and which training methods amplify it. Taken together, our work provides the first systematic investigation of how machine learning systems can be trained to complement human reasoning. \",\"aids\":[\"5d50c3de7390bff0db2aa5fd\",\"53f48d8bdabfaea7cd1d315a\",\"53f4306fdabfaec09f13af74\"],\"authors\":[{\"id\":\"5d50c3de7390bff0db2aa5fd\",\"name\":\"Wilder Bryan\"},{\"id\":\"53f48d8bdabfaea7cd1d315a\",\"name\":\"Horvitz Eric\"},{\"id\":\"53f4306fdabfaec09f13af74\",\"name\":\"Kamar Ece\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F212\",\"headline\":\"We studied how machine learning systems can be optimized to complement humans via the use of discriminative and decision-theoretic modeling methodologies\",\"id\":\"5eb78919da5629cf2443038f\",\"is_like\":false,\"mrt_link\":\"5f4e0502d4631523323816b2\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":231,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2005\\u002F2005.00582.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2005.00582.pdf__n4c9qjj_images_je5xv5_g\\u002Fimg-001.png\",\"title\":\"Learning to Complement Humans\",\"year\":2020},{\"abstract\":\"  Graph Neural Networks (GNNs) are powerful to learn the representation of graph-structured data. Most of the GNNs use the message-passing scheme, where the embedding of a node is iteratively updated by aggregating the information of its neighbors. To achieve a better expressive capability of node influences, attention mechanism has grown to become a popular way to assign trainable weights of a node's neighbors in the aggregation. However, though the attention-based GNNs have achieved state-of-the-art results on several tasks, a clear understanding of their discriminative capacities is missing. In this work, we present a theoretical analysis of the representational properties of the GNN that adopts attention mechanism as an aggregator. In the analysis, we show all of the cases when those GNNs always fail to distinguish distinct structures. The finding shows existing attention-based aggregators fail to preserve the cardinality of the multiset of node feature vectors in the aggregation, thus limits their discriminative ability. To improve the performance of attention-based GNNs, we propose two cardinality preserved modifications that can be applied to any kind of attention mechanisms. We evaluate them in our GNN framework on benchmark datasets for graph classification. The results validate the improvements and show the competitive performance of our models. \",\"aids\":[\"540fd658dabfae450f4ab286\"],\"authors\":[{\"id\":\"540fd658dabfae450f4ab286\",\"name\":\"Zhang Shuo\"},{\"name\":\"Xie Lei\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F194\",\"headline\":\"We propose cardinality preserved attention models to solve this issue\",\"id\":\"5d1f1fd13a55ac72f611c7f0\",\"is_like\":false,\"mrt_link\":\"5f4e0502d4631523323816ad\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":220,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F1364\\u002F1977\\u002F1313\\u002F5d1f1fd13a55ac72f611c7f0_1.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5d1f1fd13a55ac72f611c7f0_0.pdf_bfi0bmfa_images_paxal3ld\\u002Fimg-001.png\",\"resources\":{\"code\":[{\"desc\":\"\",\"link\":\"https:\\u002F\\u002Fgithub.com\\u002Fzetayue\\u002FCPA\",\"peek\":\"\"}]},\"title\":\"Improving Attention Mechanism in Graph Neural Networks via Cardinality\\n  Preservation\",\"year\":2019},{\"aids\":[\"5619fa9145cedb3397e14216\",\"53f43454dabfaedce551b305\",\"5613428445cedb33979ac577\",\"5632006045cedb3399f8cbab\",\"5405e2b0dabfae44f0830d0b\",\"561ea8b245cedb339813b58c\",\"5d50c3947390bff0db2a689f\",\"560fe71345ce1e5961f0fe0f\",\"53f43a9cdabfaeb2ac075577\",\"542b88e7dabfae20066006ce\",\"5613fcd345ce1e59632c4534\"],\"authors\":[{\"id\":\"5619fa9145cedb3397e14216\",\"name\":\"Tianpei Yang\"},{\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Jianye Hao\"},{\"id\":\"5613428445cedb33979ac577\",\"name\":\"Zhaopeng Meng\"},{\"id\":\"5632006045cedb3399f8cbab\",\"name\":\"Zongzhang Zhang\"},{\"id\":\"5405e2b0dabfae44f0830d0b\",\"name\":\"Yujing Hu\"},{\"id\":\"561ea8b245cedb339813b58c\",\"name\":\"Yingfeng Chen\"},{\"id\":\"5d50c3947390bff0db2a689f\",\"name\":\"Changjie Fan\"},{\"id\":\"560fe71345ce1e5961f0fe0f\",\"name\":\"Weixun Wang\"},{\"id\":\"53f43a9cdabfaeb2ac075577\",\"name\":\"Wulong Liu\"},{\"id\":\"542b88e7dabfae20066006ce\",\"name\":\"Zhaodong Wang\"},{\"id\":\"5613fcd345ce1e59632c4534\",\"name\":\"Jiajie Peng\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F428\",\"headline\":\"We propose a novel Policy Transfer Framework by taking advantage of this idea\",\"id\":\"5ef96b048806af6ef2772111\",\"is_like\":false,\"mrt_link\":\"5f4e0503d4631523323816cc\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":218,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0428.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0428.pdf_rrkam_3v_images_hsp6ggyd\\u002Fimg-001.png\",\"title\":\"Efficient Deep Reinforcement Learning via Adaptive Policy Transfer\",\"year\":2020},{\"aids\":[\"5d50c3b57390bff0db2a8363\",\"562d490f45cedb3398db09bc\",\"53f564e9dabfae60b4f8045b\",\"5630f06645ceb49c5de19c07\",\"53f43bcedabfaec09f1b03a8\"],\"authors\":[{\"id\":\"5d50c3b57390bff0db2a8363\",\"name\":\"Zhongyang Li\"},{\"id\":\"562d490f45cedb3398db09bc\",\"name\":\"Xiao Ding\"},{\"id\":\"53f564e9dabfae60b4f8045b\",\"name\":\"Ting Liu\"},{\"id\":\"5630f06645ceb49c5de19c07\",\"name\":\"J. Edward Hu\"},{\"id\":\"53f43bcedabfaec09f1b03a8\",\"name\":\"Benjamin Van Durme\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F502\",\"headline\":\"We introduced a novel extension to lexically-constrained decoding that supports disjunctive positive constraints, where generated output is forced to contain one of a set of candidates\",\"id\":\"5ef96b048806af6ef27721d9\",\"is_like\":false,\"mrt_link\":\"5f4e0503d4631523323816bf\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":207,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0502.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0502.pdf_l5v4uks8_images_nivotp40\\u002Fimg-001.png\",\"title\":\"Guided Generation of Cause and Effect\",\"year\":2020}],\"meta\":{\"context\":\"D776EA76\",\"time\":\"838.779127ms\"},\"succeed\":true,\"total\":645},\"MostViewPubsData\":[{\"abstract\":\"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.\",\"aids\":[\"562d52a145cedb3398dc4e62\",\"53f5735cdabfae7b13f8045b\",\"53f4c7b3dabfaee57877ceca\",\"53f39418dabfae4b34a67084\"],\"authors\":[{\"id\":\"562d52a145cedb3398dc4e62\",\"name\":\"Devendra Singh Chaplot\"},{\"name\":\"Lisa Lee\"},{\"id\":\"53f5735cdabfae7b13f8045b\",\"name\":\"Ruslan Salakhutdinov\"},{\"id\":\"53f4c7b3dabfaee57877ceca\",\"name\":\"Devi Parikh\"},{\"id\":\"53f39418dabfae4b34a67084\",\"name\":\"Dhruv Batra\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"\",\"headline\":\"We show that the proposed model is able to transfer the knowledge of concepts across tasks and outperforms the baselines on both Semantic Goal Navigation and Embodied Question Answering by a considerable margin\",\"id\":\"5cede0f0da562983788cec6c\",\"is_like\":false,\"lang\":\"en\",\"mrt_link\":\"5f4e0501d46315233238167a\",\"num_citation\":0,\"num_like\":8,\"num_viewed\":558,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002Fprogram\\u002F5cede0f0da562983788cec6c_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5cede0f0da562983788cec6c_0.pdf_4giexpl7_images_1oa_h4a1\\u002Fimg-002.png\",\"title\":\"Embodied Multimodal Multitask Learning.\",\"year\":2019},{\"abstract\":\"  A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders with arbitrary manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the Diffusion Variational Autoencoder is capable of capturing topological properties of synthetic datasets. Additionally, we train MNIST on spheres, tori, projective spaces, SO(3), and a torus embedded in R3. Although a natural dataset like MNIST does not have latent variables with a clear-cut topological structure, training it on a manifold can still highlight topological and geometrical properties. \",\"aids\":[\"562befd945ce1e59672605d2\",\"53f446a1dabfaee02ad19c3a\"],\"authors\":[{\"id\":\"562befd945ce1e59672605d2\",\"name\":\"Luis A. P&eacute;rez Rey\"},{\"id\":\"53f446a1dabfaee02ad19c3a\",\"name\":\"Vlado Menkovski\"},{\"name\":\"Jacobus W. Portegies\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"headline\":\"We developed and implemented Diffusion Variational Autoencoders, which allow for arbitrary manifolds as a latent space 1\",\"id\":\"5cede0f1da562983788cf9db\",\"is_like\":false,\"lang\":\"en\",\"mrt_link\":\"5f4e050dd4631523323817e0\",\"num_citation\":8,\"num_like\":0,\"num_viewed\":432,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F19\\u002F1901\\u002F1901.08991.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F1901.08991.pdf_7hbjasud_images_h446zzie\\u002Fimg-001.png\",\"title\":\"Diffusion Variational Autoencoders.\",\"year\":2019},{\"aids\":[\"53f4324cdabfaeb22f446b37\",\"560a0cf245ce1e595fb1333b\",\"542a2a04dabfae5848aa3005\"],\"authors\":[{\"id\":\"53f4324cdabfaeb22f446b37\",\"name\":\"Chao Li\"},{\"id\":\"560a0cf245ce1e595fb1333b\",\"name\":\"Baolin Liu\"},{\"id\":\"542a2a04dabfae5848aa3005\",\"name\":\"Jianguo Wei\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F103\",\"headline\":\"Based on the concept of shared features, we built encoding models to explore the relationship between the deep convolutional neural networks and human brain activity, and proposed a reconstruction method for decoding brain signals\",\"id\":\"5ef96b048806af6ef2772066\",\"is_like\":false,\"mrt_link\":\"5f4e0517d4631523323818e6\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":400,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0103.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0103.pdf_i8cosexo_images_p99mhwn4\\u002Fimg-001.png\",\"title\":\"Visual Encoding and Decoding of the Human Brain Based on Shared Features\",\"year\":2020},{\"aids\":[\"561aaf8145cedb3397ea5619\",\"5429704cdabfae82c0e59767\",\"5d43d54e7390bff0db600ec1\",\"5d43d54e7390bff0db600ecb\",\"542a4d53dabfae61d49671e5\",\"53f435c9dabfaee43ec2b29c\",\"542a5f39dabfae61d497310f\"],\"authors\":[{\"id\":\"561aaf8145cedb3397ea5619\",\"name\":\"Hongmin Zhu\"},{\"id\":\"5429704cdabfae82c0e59767\",\"name\":\"Fuli Feng\"},{\"id\":\"5d43d54e7390bff0db600ec1\",\"name\":\"Xiangnan He\"},{\"id\":\"5d43d54e7390bff0db600ecb\",\"name\":\"Xiang Wang\"},{\"id\":\"542a4d53dabfae61d49671e5\",\"name\":\"Yan Li\"},{\"id\":\"53f435c9dabfaee43ec2b29c\",\"name\":\"Kai Zheng\"},{\"id\":\"542a5f39dabfae61d497310f\",\"name\":\"Yongdong Zhang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F202\",\"headline\":\"We proposed Bilinear Graph Neural Network, a new graph neural network framework, which augments the expressiveness of vanilla Graph Neural Network by considering the interactions between neighbor nodes\",\"id\":\"5ef96b048806af6ef2772079\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238168a\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":353,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0202.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0202.pdf_oljtg_ml_images_a6ukth8v\\u002Fimg-001.png\",\"title\":\"Bilinear Graph Neural Network with Neighbor Interactions\",\"year\":2020},{\"aids\":[\"5609328045cedb3396e4fb5a\",\"5625328c45cedb3398592763\",\"542ce893dabfae216e635dd8\",\"53f43e5fdabfaec09f1b56fc\",\"53f325a3dabfae9a8446fa8f\",\"542ce910dabfae4b91c2d971\",\"53f642d9dabfaed4ec0f3d1a\"],\"authors\":[{\"id\":\"5609328045cedb3396e4fb5a\",\"name\":\"Zhongxia Chen\"},{\"id\":\"5625328c45cedb3398592763\",\"name\":\"Xiting Wang\"},{\"id\":\"542ce893dabfae216e635dd8\",\"name\":\"Xing Xie\"},{\"id\":\"53f43e5fdabfaec09f1b56fc\",\"name\":\"Mehul Parsana\"},{\"id\":\"53f325a3dabfae9a8446fa8f\",\"name\":\"Akshay Soni\"},{\"id\":\"542ce910dabfae4b91c2d971\",\"name\":\"Xiang Ao\"},{\"id\":\"53f642d9dabfaed4ec0f3d1a\",\"name\":\"Enhong Chen\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F414\",\"headline\":\"We propose a framework for explainable conversational recommendation, which enables tight collaboration between the recommendation task, the explanation generation task, and the incremental feedback integration module\",\"id\":\"5ef96b048806af6ef277218c\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381679\",\"num_citation\":0,\"num_like\":2,\"num_viewed\":336,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0414.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0414.pdf_59o7rmld_images_idbhf1ao\\u002Fimg-001.png\",\"title\":\"Towards Explainable Conversational Recommendation\",\"year\":2020},{\"aids\":[\"542d8ffddabfae48d12392e2\",\"561a410a45ce1e59645fd5c0\",\"53f4720bdabfaee1c0b9435d\",\"56046cf445cedb33963c4447\"],\"authors\":[{\"id\":\"542d8ffddabfae48d12392e2\",\"name\":\"Tong Wu\"},{\"id\":\"561a410a45ce1e59645fd5c0\",\"name\":\"Bicheng Dai\"},{\"name\":\"Shuxin Chen\"},{\"id\":\"53f4720bdabfaee1c0b9435d\",\"name\":\"Yanyun Qu\"},{\"id\":\"56046cf445cedb33963c4447\",\"name\":\"Yuan Xie\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F76\",\"headline\":\"We propose Meta Segmentation Network for the effective segmentation of medical ultra-resolution image\",\"id\":\"5ef96b048806af6ef2772042\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167f\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":318,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Fijcai\\u002F20\\u002F0076.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F0076.pdf_ke1f37gq_images_os6i52d4\\u002Fimg-001.png\",\"title\":\"Meta Segmentation Network for Ultra-Resolution Medical Images\",\"year\":2020},{\"abstract\":\"  Multi-lingual contextualized embeddings, such as multilingual-BERT (mBERT), have shown success in a variety of zero-shot cross-lingual tasks. However, these models are limited by having inconsistent contextualized representations of subwords across different languages. Existing work addresses this issue by bilingual projection and fine-tuning technique. We propose a data augmentation framework to generate multi-lingual code-switching data to fine-tune mBERT, which encourages model to align representations from source and multiple target languages once by mixing their context information. Compared with the existing work, our method does not rely on bilingual sentences for training, and requires only one training process for multiple target languages. Experimental results on five tasks with 19 languages show that our method leads to significantly improved performances for all the tasks compared with mBERT. \",\"aids\":[\"5448b07bdabfae1e04135dad\",\"53f80060dabfae8faa4cea01\",\"53f42c90dabfaee02ac54f1b\"],\"authors\":[{\"id\":\"5448b07bdabfae1e04135dad\",\"name\":\"Qin Libo\"},{\"name\":\"Ni Minheng\"},{\"id\":\"53f80060dabfae8faa4cea01\",\"name\":\"Zhang Yue\"},{\"id\":\"53f42c90dabfaee02ac54f1b\",\"name\":\"Che Wanxiang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F533\",\"headline\":\"We proposed an augmentation framework to generate multilingual code-switching data to fine-tune mBERT for aligning representations from source and multiple target languages\",\"id\":\"5ee3527191e011cb3bff760a\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381689\",\"num_citation\":0,\"num_like\":2,\"num_viewed\":312,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fupload\\u002Fpdf\\u002F265\\u002F1170\\u002F1990\\u002F5ee3527191e011cb3bff760a_0.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F5ee3527191e011cb3bff760a_0.pdf_b5t6394e_images_ndba6j0m\\u002Fimg-001.png\",\"resources\":{\"code\":[{\"desc\":\"\",\"link\":\"https:\\u002F\\u002Fgithub.com\\u002Fkodenii\\u002FCoSDA-ML\",\"peek\":\"\"}]},\"title\":\"CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot\\n  Cross-Lingual NLP\",\"year\":2020},{\"abstract\":\"  Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. \",\"aids\":[\"562b072845cedb3398967594\",\"53f43331dabfaedce550dffa\",\"54055181dabfae92b41c32d0\",\"53f4da76dabfaef7e377b3e6\",\"53f470e3dabfaee02adbdea8\",\"53fa0e27dabfae91d3fc74ec\",\"5486c666dabfae9b40134002\"],\"authors\":[{\"name\":\"Chen Daoyuan\"},{\"id\":\"562b072845cedb3398967594\",\"name\":\"Li Yaliang\"},{\"id\":\"53f43331dabfaedce550dffa\",\"name\":\"Qiu Minghui\"},{\"name\":\"Wang Zhen\"},{\"name\":\"Li Bofang\"},{\"id\":\"53f4da76dabfaef7e377b3e6\",\"name\":\"Ding Bolin\"},{\"id\":\"53f470e3dabfaee02adbdea8\",\"name\":\"Deng Hongbo\"},{\"name\":\"Huang Jun\"},{\"id\":\"53fa0e27dabfae91d3fc74ec\",\"name\":\"Lin Wei\"},{\"id\":\"5486c666dabfae9b40134002\",\"name\":\"Zhou Jingren\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F341\",\"headline\":\"Extensive experiments demonstrate that AdaBERT achieves comparable performance while significantly improves the efficiency by 12.7x to 29.3x speedup in inference time and 11.5x to 17.0x compression ratio in parameter size\",\"id\":\"5e1d915f3a55ac91798fe9bf\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167d\",\"num_citation\":5,\"num_like\":0,\"num_viewed\":310,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2001\\u002F2001.04246.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2001.04246.pdf_u5d6lumm_images_471yak8x\\u002Fimg-001.png\",\"title\":\"AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\\n  Architecture Search\",\"year\":2020},{\"abstract\":\"  Channel pruning is among the predominant approaches to compress deep neural networks. To this end, most existing pruning methods focus on selecting channels (filters) by importance\\u002Foptimization or regularization based on rule-of-thumb designs, which defects in sub-optimal pruning. In this paper, we propose a new channel pruning method based on artificial bee colony algorithm (ABC), dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \\\"important\\\" channels as previous works did. To solve the intractably huge combinations of pruned structure for deep networks, we first propose to shrink the combinations where the preserved channels are limited to a specific space, thus the combinations of pruned structure can be significantly reduced. And then, we formulate the search of optimal pruned structure as an optimization problem and integrate the ABC algorithm to solve it in an automatic manner to lessen human interference. ABCPruner has been demonstrated to be more effective, which also enables the fine-tuning to be conducted efficiently in an end-to-end manner. Experiments on CIFAR-10 show that ABCPruner reduces 73.68\\\\% of FLOPs and 88.68\\\\% of parameters with even 0.06\\\\% accuracy improvement for VGGNet-16. On ILSVRC-2012, it achieves a reduction of 62.87\\\\% FLOPs and removes 60.01\\\\% of parameters with negligible accuracy cost for ResNet-152. The source codes can be available at https:\\u002F\\u002Fgithub.com\\u002Flmbxmu\\u002FABCPruner. \",\"aids\":[\"5620512a45ceff436be1f4c2\",\"5484d882dabfaed7b5fa1c4d\",\"560fc42d45cedb339777a222\",\"560b36c945cedb33972977e1\",\"53f43c26dabfaee2a1d1a9b6\",\"542a50a2dabfae61d496977f\"],\"authors\":[{\"id\":\"5620512a45ceff436be1f4c2\",\"name\":\"Lin Mingbao\"},{\"id\":\"5484d882dabfaed7b5fa1c4d\",\"name\":\"Ji Rongrong\"},{\"id\":\"560fc42d45cedb339777a222\",\"name\":\"Zhang Yuxin\"},{\"id\":\"560b36c945cedb33972977e1\",\"name\":\"Zhang Baochang\"},{\"id\":\"53f43c26dabfaee2a1d1a9b6\",\"name\":\"Wu Yongjian\"},{\"id\":\"542a50a2dabfae61d496977f\",\"name\":\"Tian Yonghong\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F94\",\"headline\":\"We propose a new channel pruning method based on artificial bee colony algorithm, dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \\\"important\\\" channels as previous works did\",\"id\":\"5e2ac03c3a55ac8999c1ae65\",\"is_like\":false,\"mrt_link\":\"5f4e0501d463152332381684\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":307,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2001\\u002F2001.08565.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2001.08565.pdf_gcdhtczj_images_w8c2jure\\u002Fimg-001.png\",\"title\":\"Channel Pruning via Automatic Structure Search\",\"year\":2020},{\"abstract\":\"  To enable DNNs on edge devices like mobile phones, low-rank approximation has been widely adopted because of its solid theoretical rationale and efficient implementations. Several previous works attempted to directly approximate a pretrained model by low-rank decomposition; however, small approximation errors in parameters can ripple over a large prediction loss. As a result, performance usually drops significantly and a sophisticated effort on fine-tuning is required to recover accuracy. Apparently, it is not optimal to separate low-rank approximation from training. Unlike previous works, this paper integrates low rank approximation and regularization into the training process. We propose Trained Rank Pruning (TRP), which alternates between low rank approximation and training. TRP maintains the capacity of the original network while imposing low-rank constraints during training. A nuclear regularization optimized by stochastic sub-gradient descent is utilized to further promote low rank in TRP. The TRP trained network inherently has a low-rank structure, and is approximated with negligible performance loss, thus eliminating the fine-tuning process after low rank decomposition. The proposed method is comprehensively evaluated on CIFAR-10 and ImageNet, outperforming previous compression methods using low rank approximation. \",\"aids\":[\"5606d9d345ce1e595ed46ac1\",\"562c7d4445cedb3398c3a177\",\"5632020f45cedb3399f90317\",\"53f4496bdabfaee4dc7dd654\",\"53f42f40dabfaeb1a7ba3174\",\"53f43838dabfaeb22f48248b\",\"562b045545cedb3398963955\",\"53f4675edabfaeecd6a10d6d\"],\"authors\":[{\"id\":\"5606d9d345ce1e595ed46ac1\",\"name\":\"Xu Yuhui\"},{\"name\":\"Li Yuxi\"},{\"id\":\"562c7d4445cedb3398c3a177\",\"name\":\"Zhang Shuai\"},{\"id\":\"5632020f45cedb3399f90317\",\"name\":\"Wen Wei\"},{\"id\":\"53f4496bdabfaee4dc7dd654\",\"name\":\"Wang Botao\"},{\"id\":\"53f42f40dabfaeb1a7ba3174\",\"name\":\"Qi Yingyong\"},{\"id\":\"53f43838dabfaeb22f48248b\",\"name\":\"Chen Yiran\"},{\"id\":\"562b045545cedb3398963955\",\"name\":\"Lin Weiyao\"},{\"id\":\"53f4675edabfaeecd6a10d6d\",\"name\":\"Xiong Hongkai\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963\\u002Fijcai.2020\\u002F136\",\"headline\":\"We proposed a new scheme Trained Rank Pruning for training low-rank networks\",\"id\":\"5eabf34391e011664ffd2878\",\"is_like\":false,\"mrt_link\":\"5f4e0501d46315233238167e\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":302,\"pdf\":\"https:\\u002F\\u002Fstatic.aminer.cn\\u002Fstorage\\u002Fpdf\\u002Farxiv\\u002F20\\u002F2004\\u002F2004.14566.pdf\",\"picture\":\"https:\\u002F\\u002Fcloud-api.scholarcy.com\\u002Fimages\\u002F2004.14566.pdf_bjg7kym8_images_5mr7lob2\\u002Fimg-001.png\",\"title\":\"TRP: Trained Rank Pruning for Efficient Deep Neural Networks\",\"year\":2020}],\"KeywordsList\":[{\"e\":12,\"keywords\":\"Learning\",\"n\":12,\"w\":12},{\"e\":8,\"keywords\":\"Unsupervised\",\"n\":8,\"w\":8},{\"e\":7,\"k\":4,\"keywords\":\"Graph Neural Network\",\"n\":8,\"w\":7},{\"e\":7,\"k\":2,\"keywords\":\"Attention Network\",\"n\":8,\"w\":7},{\"e\":8,\"keywords\":\"Representation Learning\",\"n\":8,\"w\":8},{\"e\":7,\"k\":2,\"keywords\":\"Deep Reinforcement Learning\",\"n\":7,\"w\":7},{\"e\":7,\"k\":2,\"keywords\":\"Deep Neural Network\",\"n\":7,\"w\":7},{\"e\":6,\"k\":1,\"keywords\":\"Convolutional Network\",\"n\":6,\"w\":6},{\"e\":6,\"keywords\":\"Search\",\"n\":6,\"w\":6},{\"e\":6,\"k\":2,\"keywords\":\"Neural Machine Translation\",\"n\":6,\"w\":6},{\"e\":5,\"k\":3,\"keywords\":\"Reinforcement Learning\",\"n\":6,\"w\":5},{\"e\":5,\"keywords\":\"Hierarchical\",\"n\":5,\"w\":5},{\"e\":2,\"k\":3,\"keywords\":\"Neural Network\",\"n\":5,\"w\":3},{\"e\":5,\"keywords\":\"Network\",\"n\":5,\"w\":5},{\"e\":5,\"k\":3,\"keywords\":\"Multi-label Learning\",\"n\":5,\"w\":5},{\"e\":5,\"keywords\":\"Neural Architecture\",\"n\":5,\"w\":5},{\"e\":3,\"k\":5,\"keywords\":\"Convolutional Neural Network\",\"n\":5,\"w\":5},{\"e\":5,\"keywords\":\"Embedding\",\"n\":5,\"w\":5},{\"e\":4,\"k\":2,\"keywords\":\"Domain Adaptation\",\"n\":5,\"w\":4},{\"e\":4,\"keywords\":\"Multi-view\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Reading Comprehension\",\"n\":4,\"w\":4},{\"e\":3,\"k\":3,\"keywords\":\"Deep Learning\",\"n\":4,\"w\":3},{\"e\":4,\"keywords\":\"Preference\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Semantic\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"VIUM\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Adversarial\",\"n\":4,\"w\":4},{\"e\":3,\"k\":2,\"keywords\":\"Description Logic\",\"n\":4,\"w\":3},{\"e\":4,\"keywords\":\"Diversity\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Generating\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Reasoning\",\"n\":4,\"w\":4},{\"e\":4,\"keywords\":\"Autoencoder\",\"n\":4,\"w\":4},{\"e\":3,\"k\":1,\"keywords\":\"Anomaly Detection\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Pomdp\",\"n\":3,\"w\":3},{\"k\":3,\"keywords\":\"Entity Recognition\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Adversarial Training\",\"n\":3,\"w\":3},{\"e\":3,\"k\":1,\"keywords\":\"Optimal Transport\",\"n\":3,\"w\":3},{\"e\":2,\"k\":2,\"keywords\":\"Adversarial Network\",\"n\":3,\"w\":2},{\"e\":2,\"k\":1,\"keywords\":\"Metric Learning\",\"n\":3,\"w\":2},{\"e\":3,\"keywords\":\"Differentiable\",\"n\":3,\"w\":3},{\"e\":3,\"k\":1,\"keywords\":\"Knowledge Graph\",\"n\":3,\"w\":3},{\"e\":3,\"k\":1,\"keywords\":\"Dialogue Generation\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Attention\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"DEEP\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Graph-based\",\"n\":3,\"w\":3},{\"e\":2,\"k\":3,\"keywords\":\"Unsupervised Domain Adaptation\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Pruning\",\"n\":3,\"w\":3},{\"e\":3,\"k\":1,\"keywords\":\"Person Re-identification\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Online\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Weakly Supervised\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Named Entity Recognition\",\"n\":3,\"w\":3},{\"e\":3,\"k\":3,\"keywords\":\"Few-shot Learning\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Explanation\",\"n\":3,\"w\":3},{\"e\":3,\"k\":2,\"keywords\":\"Question Answering\",\"n\":3,\"w\":3},{\"e\":3,\"k\":2,\"keywords\":\"Relation Extraction\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Hashing\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Counting\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Segmentation\",\"n\":3,\"w\":3},{\"e\":1,\"k\":2,\"keywords\":\"Medical Image\",\"n\":3,\"w\":2},{\"e\":3,\"keywords\":\"Prediction\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Accelerating\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Meta Learning\",\"n\":3,\"w\":3},{\"e\":3,\"keywords\":\"Robust\",\"n\":3,\"w\":3},{\"e\":2,\"keywords\":\"Sparse\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Consistent\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Reconstructing\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Discrepancy\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Training\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Discovering\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Constraint\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Automatic\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Reasoner\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Strategic\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Modeling\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Multi-scale\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Representation\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Generalization\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Error\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Multilingual\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Problem\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Reinforcement Learning Approach\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Gradient\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"One-shot\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Generation\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Neural\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Driven\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Operation\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Multi-task Learning\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Beyond\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Bi-level\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Semantic Segmentation\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Blockchain\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Human-object Interaction\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\": Learning\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Sequential\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Action\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Dialogue\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Constrained\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Adversarial Learning\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Probabilistic\",\"n\":2,\"w\":2},{\"e\":2,\"keywords\":\"Clustering\",\"n\":2,\"w\":2}],\"SearchAuthorsData\":{\"items\":[{\"aid\":\"540683ccdabfae44f083b82c\",\"id\":\"540683ccdabfae44f083b82c\",\"name\":\"Yang Gao（高阳）\",\"name_zh\":\"\",\"pub_num\":5,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5e3940be3a55ace46ed435e7\",\"5ef96b048806af6ef2772081\",\"5ef96b048806af6ef2772017\",\"5ef96b048806af6ef277203f\",\"5ef96b048806af6ef27720fe\"]}]},{\"aid\":\"53f43454dabfaedce551b305\",\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Jianye Hao\",\"name_zh\":\"郝建业\",\"pub_num\":5,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5eba73be91e01108d77cf63e\",\"5e4d083f3a55ac8cfd770c23\",\"5ec7a33091e0118397f3ef17\",\"5ef96b048806af6ef2772111\",\"5ef96b048806af6ef277219d\"]}]},{\"aid\":\"56cb18c2c35f4f3c65660dc2\",\"id\":\"56cb18c2c35f4f3c65660dc2\",\"name\":\"Bo Du\",\"name_zh\":\"杜博\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef96b048806af6ef2772166\",\"5ef96b048806af6ef27720fd\",\"5ef96b048806af6ef277205f\",\"5ef96b048806af6ef2772047\"]}]},{\"aid\":\"56cb1891c35f4f3c6565176f\",\"id\":\"56cb1891c35f4f3c6565176f\",\"name\":\"Meng Wang\",\"name_zh\":\"汪萌\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef476b691e01165a63bbbdc\",\"5ef3247091e0110c353da56d\",\"5ef96b048806af6ef2772040\",\"5ef96b048806af6ef2772046\"]}]},{\"aid\":\"560cd53c45cedb339757a831\",\"id\":\"560cd53c45cedb339757a831\",\"name\":\"Wenbin Li\",\"name_zh\":\"李文斌\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5e3940be3a55ace46ed435e7\",\"5ef96b048806af6ef2772017\",\"5ef96b048806af6ef2772131\",\"5ef96b048806af6ef277203f\"]}]},{\"aid\":\"53f638cfdabfae7e00c71628\",\"id\":\"53f638cfdabfae7e00c71628\",\"name\":\"Carla P. Gomes\",\"name_zh\":\"\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5eda19d991e01187f5d6db49\",\"5ef96b048806af6ef277222c\",\"5ef96b048806af6ef277222b\",\"5ef96b048806af6ef2772252\"]}]},{\"aid\":\"53f48c9bdabfaea7cd1cf6cc\",\"id\":\"53f48c9bdabfaea7cd1cf6cc\",\"name\":\"Yong Yu\",\"name_zh\":\"俞勇\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef96b048806af6ef27720a1\",\"5ef96b048806af6ef2772219\",\"5ef96b048806af6ef27720a2\",\"5ef96b048806af6ef277210e\"]}]},{\"aid\":\"53f466dfdabfaedd74e6b9e2\",\"id\":\"53f466dfdabfaedd74e6b9e2\",\"name\":\"Bo An\",\"name_zh\":\"安波\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef96b048806af6ef2771ffd\",\"5ef96b048806af6ef2772127\",\"5ef96b048806af6ef27720f1\",\"5ef96b048806af6ef2771fe0\"]}]},{\"aid\":\"53f466badabfaee2a1db0053\",\"id\":\"53f466badabfaee2a1db0053\",\"name\":\"Zhengjun Zha\",\"name_zh\":\"\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef96b048806af6ef2772151\",\"5ef96b048806af6ef2772040\",\"5ef96b048806af6ef2772046\",\"5ef96b048806af6ef2772039\"]}]},{\"aid\":\"53f45915dabfaee2a1d7e6d0\",\"id\":\"53f45915dabfaee2a1d7e6d0\",\"name\":\"Shaowei Cai\",\"name_zh\":\"蔡少伟\",\"pub_num\":4,\"related_info\":[{\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"conf_name\":\"ijcai2020\",\"pids\":[\"5ef96b048806af6ef277209e\",\"5e3006423a55ac0524a25b70\",\"5ef96b048806af6ef277209c\",\"5ef96b048806af6ef277206f\"]}]}],\"meta\":{\"context\":\"D51D0838\",\"time\":\"36.53507ms\"},\"succeed\":true,\"total\":2367}}};\n",
      "  </script>\n",
      "  <script src=\"https://fileserver.aminer.cn/lib/react-latest/react.production.min.js\">\n",
      "  </script>\n",
      "  <script src=\"https://fileserver.aminer.cn/lib/react-latest/react-dom.production.min.js\">\n",
      "  </script>\n",
      "  <script>\n",
      "   window.__webpack_public_path__ = '/public/';\n",
      "  </script>\n",
      "  <script src=\"//ssr.aminer.cn/public/umi.dee96d5a.js\">\n",
      "  </script>\n",
      "  <script src=\"https://hm.baidu.com/hm.js?dc703135c31ddfba7bcda2d15caab04e\">\n",
      "  </script>\n",
      "  <script src=\"https://hm.baidu.com/hm.js?789fd650fa0be6a2a064d019d890b87f\">\n",
      "  </script>\n",
      "  <!-- GIO -->\n",
      "  <script>\n",
      "   var _vds = _vds || [];\n",
      "    window._vds = _vds;\n",
      "    (function () {\n",
      "      _vds.push([\"setAccountId\", \"ae8dfb99e5e4cda1\"]);\n",
      "      (function () {\n",
      "        var vds = document.createElement(\"script\");\n",
      "        vds.type = \"text/javascript\";\n",
      "        vds.async = true;\n",
      "        vds.src =\n",
      "          (\"https:\" == document.location.protocol ? \"https://\" : \"http://\") +\n",
      "          \"assets.giocdn.com/vds.js\";\n",
      "        var s = document.getElementsByTagName(\"script\")[0];\n",
      "        s.parentNode.insertBefore(vds, s);\n",
      "      })();\n",
      "    })();\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in scripts:\n",
    "    if script.string and script.string.find('window.g_initialProps') > -1:\n",
    "        content = script.string.split('\\n')[2].split(' = ')[1].strip(' |;').replace(\"'\", \"\")\n",
    "        content = content.replace('\\\\', '\\\\').replace('undefined', '\"undefined\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aminerConf': {'confInfo': {'address': 'Yokohama, Japan',\n",
       "   'begin_date': '2021-01-05T10:11:12.818Z',\n",
       "   'config': {'breadcrumb': True,\n",
       "    'navigator': ['homepage',\n",
       "     'papers',\n",
       "     'roster',\n",
       "     'news',\n",
       "     'videos',\n",
       "     'contact',\n",
       "     'recommend'],\n",
       "    'homepage': {'ads': True},\n",
       "    'left': ['keywords', 'leftAuthors'],\n",
       "    'right': ['statistics', 'insight'],\n",
       "    'paper': {'navigator': ['paper'],\n",
       "     'category': [],\n",
       "     'download_org': [{'key': 'all',\n",
       "       'val': '下载全部',\n",
       "       'link': 'https://pan.baidu.com/s/11FioZCMwufp-hqLJHpzVzw ',\n",
       "       'code': '9pls'}]},\n",
       "    'roster': {'navigator': ['chinese-scholar', 'chinese-first', 'authors']},\n",
       "    'tdk': {'pageTitle': 'IJCAI2020-学术会议',\n",
       "     'pageDesc': 'IJCAI 2020 会议助手涵盖会议论文、作者列表、论文解读和论文推荐，提供全方位会议信息及分析。',\n",
       "     'pageKeywords': 'IJCAI2020, ijcai, ijcai学术会议, Artificial Intelligence, 人工智能'}},\n",
       "   'created_time': '2020-06-28T10:13:09.291Z',\n",
       "   'creator': '54f5112e45ce1bc6d563b8d9',\n",
       "   'eid': ['5efc4c4a4c775ed682ed406a', '5efd3b724c775ed682ed805c'],\n",
       "   'end_date': '2021-01-10T10:11:12.818Z',\n",
       "   'full_name': 'International Joint Conference on Artificial Intelligence',\n",
       "   'id': '5ef86d3592c7f9be218d4b9b',\n",
       "   'introduce': 'IJCAI-PRICAI2020 will take place in the Pacifico Yokohama, officially known as Pacifico Convention Plaza Yokohama, which is one of the largest convention and exhibition centers in Japan. The center is located in the waterfront Minato Mirai. Minato Mirai is a major center for business, shopping, and tourism, attracting visitors and businesspeople throughout the Greater Tokyo Area. Minato Mirai also attracts numerous tourists, as does the nearby Yokohama Chinatown.',\n",
       "   'is_public': True,\n",
       "   'logo': 'https://static.aminer.cn/buildin/confs/1470/45/142/5ef86d3592c7f9be218d4b9b_1.jpg',\n",
       "   'order': 1,\n",
       "   'paper_count': 645,\n",
       "   'short_name': 'ijcai2020',\n",
       "   'updated_time': '2020-11-30T09:06:33.153Z',\n",
       "   'url': 'http://www.ijcai20.org/',\n",
       "   'year': 2020},\n",
       "  'timeTable': 'undefined',\n",
       "  'SearchPubsData': {'items': [{'abstract': 'Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.',\n",
       "     'aids': ['562d52a145cedb3398dc4e62',\n",
       "      '53f5735cdabfae7b13f8045b',\n",
       "      '53f4c7b3dabfaee57877ceca',\n",
       "      '53f39418dabfae4b34a67084'],\n",
       "     'authors': [{'id': '562d52a145cedb3398dc4e62',\n",
       "       'name': 'Devendra Singh Chaplot'},\n",
       "      {'name': 'Lisa Lee'},\n",
       "      {'id': '53f5735cdabfae7b13f8045b', 'name': 'Ruslan Salakhutdinov'},\n",
       "      {'id': '53f4c7b3dabfaee57877ceca', 'name': 'Devi Parikh'},\n",
       "      {'id': '53f39418dabfae4b34a67084', 'name': 'Dhruv Batra'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '',\n",
       "     'headline': 'We show that the proposed model is able to transfer the knowledge of concepts across tasks and outperforms the baselines on both Semantic Goal Navigation and Embodied Question Answering by a considerable margin',\n",
       "     'id': '5cede0f0da562983788cec6c',\n",
       "     'is_like': False,\n",
       "     'lang': 'en',\n",
       "     'mrt_link': '5f4e0501d46315233238167a',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 8,\n",
       "     'num_viewed': 558,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/program/5cede0f0da562983788cec6c_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5cede0f0da562983788cec6c_0.pdf_4giexpl7_images_1oa_h4a1/img-002.png',\n",
       "     'title': 'Embodied Multimodal Multitask Learning.',\n",
       "     'year': 2019},\n",
       "    {'abstract': '  A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders with arbitrary manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the Diffusion Variational Autoencoder is capable of capturing topological properties of synthetic datasets. Additionally, we train MNIST on spheres, tori, projective spaces, SO(3), and a torus embedded in R3. Although a natural dataset like MNIST does not have latent variables with a clear-cut topological structure, training it on a manifold can still highlight topological and geometrical properties. ',\n",
       "     'aids': ['562befd945ce1e59672605d2', '53f446a1dabfaee02ad19c3a'],\n",
       "     'authors': [{'id': '562befd945ce1e59672605d2',\n",
       "       'name': 'Luis A. P&eacute;rez Rey'},\n",
       "      {'id': '53f446a1dabfaee02ad19c3a', 'name': 'Vlado Menkovski'},\n",
       "      {'name': 'Jacobus W. Portegies'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'headline': 'We developed and implemented Diffusion Variational Autoencoders, which allow for arbitrary manifolds as a latent space 1',\n",
       "     'id': '5cede0f1da562983788cf9db',\n",
       "     'is_like': False,\n",
       "     'lang': 'en',\n",
       "     'mrt_link': '5f4e050dd4631523323817e0',\n",
       "     'num_citation': 8,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 432,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/19/1901/1901.08991.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/1901.08991.pdf_7hbjasud_images_h446zzie/img-001.png',\n",
       "     'title': 'Diffusion Variational Autoencoders.',\n",
       "     'year': 2019},\n",
       "    {'aids': ['53f4324cdabfaeb22f446b37',\n",
       "      '560a0cf245ce1e595fb1333b',\n",
       "      '542a2a04dabfae5848aa3005'],\n",
       "     'authors': [{'id': '53f4324cdabfaeb22f446b37', 'name': 'Chao Li'},\n",
       "      {'id': '560a0cf245ce1e595fb1333b', 'name': 'Baolin Liu'},\n",
       "      {'id': '542a2a04dabfae5848aa3005', 'name': 'Jianguo Wei'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/103',\n",
       "     'headline': 'Based on the concept of shared features, we built encoding models to explore the relationship between the deep convolutional neural networks and human brain activity, and proposed a reconstruction method for decoding brain signals',\n",
       "     'id': '5ef96b048806af6ef2772066',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0517d4631523323818e6',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 1,\n",
       "     'num_viewed': 400,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0103.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0103.pdf_i8cosexo_images_p99mhwn4/img-001.png',\n",
       "     'title': 'Visual Encoding and Decoding of the Human Brain Based on Shared Features',\n",
       "     'year': 2020},\n",
       "    {'aids': ['561aaf8145cedb3397ea5619',\n",
       "      '5429704cdabfae82c0e59767',\n",
       "      '5d43d54e7390bff0db600ec1',\n",
       "      '5d43d54e7390bff0db600ecb',\n",
       "      '542a4d53dabfae61d49671e5',\n",
       "      '53f435c9dabfaee43ec2b29c',\n",
       "      '542a5f39dabfae61d497310f'],\n",
       "     'authors': [{'id': '561aaf8145cedb3397ea5619', 'name': 'Hongmin Zhu'},\n",
       "      {'id': '5429704cdabfae82c0e59767', 'name': 'Fuli Feng'},\n",
       "      {'id': '5d43d54e7390bff0db600ec1', 'name': 'Xiangnan He'},\n",
       "      {'id': '5d43d54e7390bff0db600ecb', 'name': 'Xiang Wang'},\n",
       "      {'id': '542a4d53dabfae61d49671e5', 'name': 'Yan Li'},\n",
       "      {'id': '53f435c9dabfaee43ec2b29c', 'name': 'Kai Zheng'},\n",
       "      {'id': '542a5f39dabfae61d497310f', 'name': 'Yongdong Zhang'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/202',\n",
       "     'headline': 'We proposed Bilinear Graph Neural Network, a new graph neural network framework, which augments the expressiveness of vanilla Graph Neural Network by considering the interactions between neighbor nodes',\n",
       "     'id': '5ef96b048806af6ef2772079',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d46315233238168a',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 353,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0202.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0202.pdf_oljtg_ml_images_a6ukth8v/img-001.png',\n",
       "     'title': 'Bilinear Graph Neural Network with Neighbor Interactions',\n",
       "     'year': 2020},\n",
       "    {'aids': ['5609328045cedb3396e4fb5a',\n",
       "      '5625328c45cedb3398592763',\n",
       "      '542ce893dabfae216e635dd8',\n",
       "      '53f43e5fdabfaec09f1b56fc',\n",
       "      '53f325a3dabfae9a8446fa8f',\n",
       "      '542ce910dabfae4b91c2d971',\n",
       "      '53f642d9dabfaed4ec0f3d1a'],\n",
       "     'authors': [{'id': '5609328045cedb3396e4fb5a', 'name': 'Zhongxia Chen'},\n",
       "      {'id': '5625328c45cedb3398592763', 'name': 'Xiting Wang'},\n",
       "      {'id': '542ce893dabfae216e635dd8', 'name': 'Xing Xie'},\n",
       "      {'id': '53f43e5fdabfaec09f1b56fc', 'name': 'Mehul Parsana'},\n",
       "      {'id': '53f325a3dabfae9a8446fa8f', 'name': 'Akshay Soni'},\n",
       "      {'id': '542ce910dabfae4b91c2d971', 'name': 'Xiang Ao'},\n",
       "      {'id': '53f642d9dabfaed4ec0f3d1a', 'name': 'Enhong Chen'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/414',\n",
       "     'headline': 'We propose a framework for explainable conversational recommendation, which enables tight collaboration between the recommendation task, the explanation generation task, and the incremental feedback integration module',\n",
       "     'id': '5ef96b048806af6ef277218c',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d463152332381679',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 2,\n",
       "     'num_viewed': 336,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0414.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0414.pdf_59o7rmld_images_idbhf1ao/img-001.png',\n",
       "     'title': 'Towards Explainable Conversational Recommendation',\n",
       "     'year': 2020},\n",
       "    {'aids': ['542d8ffddabfae48d12392e2',\n",
       "      '561a410a45ce1e59645fd5c0',\n",
       "      '53f4720bdabfaee1c0b9435d',\n",
       "      '56046cf445cedb33963c4447'],\n",
       "     'authors': [{'id': '542d8ffddabfae48d12392e2', 'name': 'Tong Wu'},\n",
       "      {'id': '561a410a45ce1e59645fd5c0', 'name': 'Bicheng Dai'},\n",
       "      {'name': 'Shuxin Chen'},\n",
       "      {'id': '53f4720bdabfaee1c0b9435d', 'name': 'Yanyun Qu'},\n",
       "      {'id': '56046cf445cedb33963c4447', 'name': 'Yuan Xie'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/76',\n",
       "     'headline': 'We propose Meta Segmentation Network for the effective segmentation of medical ultra-resolution image',\n",
       "     'id': '5ef96b048806af6ef2772042',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d46315233238167f',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 318,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0076.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0076.pdf_ke1f37gq_images_os6i52d4/img-001.png',\n",
       "     'title': 'Meta Segmentation Network for Ultra-Resolution Medical Images',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Multi-lingual contextualized embeddings, such as multilingual-BERT (mBERT), have shown success in a variety of zero-shot cross-lingual tasks. However, these models are limited by having inconsistent contextualized representations of subwords across different languages. Existing work addresses this issue by bilingual projection and fine-tuning technique. We propose a data augmentation framework to generate multi-lingual code-switching data to fine-tune mBERT, which encourages model to align representations from source and multiple target languages once by mixing their context information. Compared with the existing work, our method does not rely on bilingual sentences for training, and requires only one training process for multiple target languages. Experimental results on five tasks with 19 languages show that our method leads to significantly improved performances for all the tasks compared with mBERT. ',\n",
       "     'aids': ['5448b07bdabfae1e04135dad',\n",
       "      '53f80060dabfae8faa4cea01',\n",
       "      '53f42c90dabfaee02ac54f1b'],\n",
       "     'authors': [{'id': '5448b07bdabfae1e04135dad', 'name': 'Qin Libo'},\n",
       "      {'name': 'Ni Minheng'},\n",
       "      {'id': '53f80060dabfae8faa4cea01', 'name': 'Zhang Yue'},\n",
       "      {'id': '53f42c90dabfaee02ac54f1b', 'name': 'Che Wanxiang'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/533',\n",
       "     'headline': 'We proposed an augmentation framework to generate multilingual code-switching data to fine-tune mBERT for aligning representations from source and multiple target languages',\n",
       "     'id': '5ee3527191e011cb3bff760a',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d463152332381689',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 2,\n",
       "     'num_viewed': 312,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/265/1170/1990/5ee3527191e011cb3bff760a_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5ee3527191e011cb3bff760a_0.pdf_b5t6394e_images_ndba6j0m/img-001.png',\n",
       "     'resources': {'code': [{'desc': '',\n",
       "        'link': 'https://github.com/kodenii/CoSDA-ML',\n",
       "        'peek': ''}]},\n",
       "     'title': 'CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot\\n  Cross-Lingual NLP',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. ',\n",
       "     'aids': ['562b072845cedb3398967594',\n",
       "      '53f43331dabfaedce550dffa',\n",
       "      '54055181dabfae92b41c32d0',\n",
       "      '53f4da76dabfaef7e377b3e6',\n",
       "      '53f470e3dabfaee02adbdea8',\n",
       "      '53fa0e27dabfae91d3fc74ec',\n",
       "      '5486c666dabfae9b40134002'],\n",
       "     'authors': [{'name': 'Chen Daoyuan'},\n",
       "      {'id': '562b072845cedb3398967594', 'name': 'Li Yaliang'},\n",
       "      {'id': '53f43331dabfaedce550dffa', 'name': 'Qiu Minghui'},\n",
       "      {'name': 'Wang Zhen'},\n",
       "      {'name': 'Li Bofang'},\n",
       "      {'id': '53f4da76dabfaef7e377b3e6', 'name': 'Ding Bolin'},\n",
       "      {'id': '53f470e3dabfaee02adbdea8', 'name': 'Deng Hongbo'},\n",
       "      {'name': 'Huang Jun'},\n",
       "      {'id': '53fa0e27dabfae91d3fc74ec', 'name': 'Lin Wei'},\n",
       "      {'id': '5486c666dabfae9b40134002', 'name': 'Zhou Jingren'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/341',\n",
       "     'headline': 'Extensive experiments demonstrate that AdaBERT achieves comparable performance while significantly improves the efficiency by 12.7x to 29.3x speedup in inference time and 11.5x to 17.0x compression ratio in parameter size',\n",
       "     'id': '5e1d915f3a55ac91798fe9bf',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d46315233238167d',\n",
       "     'num_citation': 5,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 310,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2001/2001.04246.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2001.04246.pdf_u5d6lumm_images_471yak8x/img-001.png',\n",
       "     'title': 'AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\\n  Architecture Search',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Channel pruning is among the predominant approaches to compress deep neural networks. To this end, most existing pruning methods focus on selecting channels (filters) by importance/optimization or regularization based on rule-of-thumb designs, which defects in sub-optimal pruning. In this paper, we propose a new channel pruning method based on artificial bee colony algorithm (ABC), dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \"important\" channels as previous works did. To solve the intractably huge combinations of pruned structure for deep networks, we first propose to shrink the combinations where the preserved channels are limited to a specific space, thus the combinations of pruned structure can be significantly reduced. And then, we formulate the search of optimal pruned structure as an optimization problem and integrate the ABC algorithm to solve it in an automatic manner to lessen human interference. ABCPruner has been demonstrated to be more effective, which also enables the fine-tuning to be conducted efficiently in an end-to-end manner. Experiments on CIFAR-10 show that ABCPruner reduces 73.68\\\\% of FLOPs and 88.68\\\\% of parameters with even 0.06\\\\% accuracy improvement for VGGNet-16. On ILSVRC-2012, it achieves a reduction of 62.87\\\\% FLOPs and removes 60.01\\\\% of parameters with negligible accuracy cost for ResNet-152. The source codes can be available at https://github.com/lmbxmu/ABCPruner. ',\n",
       "     'aids': ['5620512a45ceff436be1f4c2',\n",
       "      '5484d882dabfaed7b5fa1c4d',\n",
       "      '560fc42d45cedb339777a222',\n",
       "      '560b36c945cedb33972977e1',\n",
       "      '53f43c26dabfaee2a1d1a9b6',\n",
       "      '542a50a2dabfae61d496977f'],\n",
       "     'authors': [{'id': '5620512a45ceff436be1f4c2', 'name': 'Lin Mingbao'},\n",
       "      {'id': '5484d882dabfaed7b5fa1c4d', 'name': 'Ji Rongrong'},\n",
       "      {'id': '560fc42d45cedb339777a222', 'name': 'Zhang Yuxin'},\n",
       "      {'id': '560b36c945cedb33972977e1', 'name': 'Zhang Baochang'},\n",
       "      {'id': '53f43c26dabfaee2a1d1a9b6', 'name': 'Wu Yongjian'},\n",
       "      {'id': '542a50a2dabfae61d496977f', 'name': 'Tian Yonghong'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/94',\n",
       "     'headline': 'We propose a new channel pruning method based on artificial bee colony algorithm, dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \"important\" channels as previous works did',\n",
       "     'id': '5e2ac03c3a55ac8999c1ae65',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d463152332381684',\n",
       "     'num_citation': 1,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 307,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2001/2001.08565.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2001.08565.pdf_gcdhtczj_images_w8c2jure/img-001.png',\n",
       "     'title': 'Channel Pruning via Automatic Structure Search',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  To enable DNNs on edge devices like mobile phones, low-rank approximation has been widely adopted because of its solid theoretical rationale and efficient implementations. Several previous works attempted to directly approximate a pretrained model by low-rank decomposition; however, small approximation errors in parameters can ripple over a large prediction loss. As a result, performance usually drops significantly and a sophisticated effort on fine-tuning is required to recover accuracy. Apparently, it is not optimal to separate low-rank approximation from training. Unlike previous works, this paper integrates low rank approximation and regularization into the training process. We propose Trained Rank Pruning (TRP), which alternates between low rank approximation and training. TRP maintains the capacity of the original network while imposing low-rank constraints during training. A nuclear regularization optimized by stochastic sub-gradient descent is utilized to further promote low rank in TRP. The TRP trained network inherently has a low-rank structure, and is approximated with negligible performance loss, thus eliminating the fine-tuning process after low rank decomposition. The proposed method is comprehensively evaluated on CIFAR-10 and ImageNet, outperforming previous compression methods using low rank approximation. ',\n",
       "     'aids': ['5606d9d345ce1e595ed46ac1',\n",
       "      '562c7d4445cedb3398c3a177',\n",
       "      '5632020f45cedb3399f90317',\n",
       "      '53f4496bdabfaee4dc7dd654',\n",
       "      '53f42f40dabfaeb1a7ba3174',\n",
       "      '53f43838dabfaeb22f48248b',\n",
       "      '562b045545cedb3398963955',\n",
       "      '53f4675edabfaeecd6a10d6d'],\n",
       "     'authors': [{'id': '5606d9d345ce1e595ed46ac1', 'name': 'Xu Yuhui'},\n",
       "      {'name': 'Li Yuxi'},\n",
       "      {'id': '562c7d4445cedb3398c3a177', 'name': 'Zhang Shuai'},\n",
       "      {'id': '5632020f45cedb3399f90317', 'name': 'Wen Wei'},\n",
       "      {'id': '53f4496bdabfaee4dc7dd654', 'name': 'Wang Botao'},\n",
       "      {'id': '53f42f40dabfaeb1a7ba3174', 'name': 'Qi Yingyong'},\n",
       "      {'id': '53f43838dabfaeb22f48248b', 'name': 'Chen Yiran'},\n",
       "      {'id': '562b045545cedb3398963955', 'name': 'Lin Weiyao'},\n",
       "      {'id': '53f4675edabfaeecd6a10d6d', 'name': 'Xiong Hongkai'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/136',\n",
       "     'headline': 'We proposed a new scheme Trained Rank Pruning for training low-rank networks',\n",
       "     'id': '5eabf34391e011664ffd2878',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d46315233238167e',\n",
       "     'num_citation': 1,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 302,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.14566.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2004.14566.pdf_bjg7kym8_images_5mr7lob2/img-001.png',\n",
       "     'title': 'TRP: Trained Rank Pruning for Efficient Deep Neural Networks',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Deep neural networks have gained tremendous success in a broad range of machine learning tasks due to its remarkable capability to learn semantic-rich features from high-dimensional data. However, they often require large-scale labelled data to successfully learn such features, which significantly hinders their adaption into unsupervised learning tasks, such as anomaly detection and clustering, and limits their applications into critical domains where obtaining massive labelled data is prohibitively expensive. To enable downstream unsupervised learning on those domains, in this work we propose to learn features without using any labelled data by training neural networks to predict data distances in a randomly projected space. Random mapping is a theoretical proven approach to obtain approximately preserved distances. To well predict these random distances, the representation learner is optimised to learn genuine class structures that are implicitly embedded in the randomly projected space. Experimental results on 19 real-world datasets show our learned representations substantially outperform state-of-the-art competing methods in both anomaly detection and clustering tasks. ',\n",
       "     'aids': ['542cc671dabfae498ae10964',\n",
       "      '53f46a4ddabfaee2a1dbeb2c',\n",
       "      '54850e41dabfaed7b5fa1edb'],\n",
       "     'authors': [{'id': '542cc671dabfae498ae10964', 'name': 'Wang Hu'},\n",
       "      {'id': '53f46a4ddabfaee2a1dbeb2c', 'name': 'Pang Guansong'},\n",
       "      {'id': '54850e41dabfaed7b5fa1edb', 'name': 'Shen Chunhua'},\n",
       "      {'name': 'Ma Congbo'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/408',\n",
       "     'headline': 'We introduce a novel Random Distance Prediction model which learns features in a fully unsupervised fashion by predicting data distances in a randomly projected space',\n",
       "     'id': '5e09caba3a55ac662f721bd7',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0502d463152332381698',\n",
       "     'num_citation': 1,\n",
       "     'num_like': 1,\n",
       "     'num_viewed': 263,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/1589/822/248/5e09caba3a55ac662f721bd7_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5e09caba3a55ac662f721bd7_0.pdf_sww0vua9_images_3r8rue87/img-001.png',\n",
       "     'title': 'Unsupervised Representation Learning by Predicting Random Distances',\n",
       "     'year': 2019},\n",
       "    {'abstract': '  Implicit discourse relation classification is one of the most difficult parts in shallow discourse parsing as the relation prediction without explicit connectives requires the language understanding at both the text span level and the sentence level. Previous studies mainly focus on the interactions between two arguments. We argue that a powerful contextualized representation module, a bilateral multi-perspective matching module, and a global information fusion module are all important to implicit discourse analysis. We propose a novel model to combine these modules together. Extensive experiments show that our proposed model outperforms BERT and other state-of-the-art systems on the PDTB dataset by around 8% and CoNLL 2016 datasets around 16%. We also analyze the effectiveness of different modules in the implicit discourse relation classification task and demonstrate how different levels of representation learning can affect the results. ',\n",
       "     'aids': ['56077d1c45ce1e595f127ae1',\n",
       "      '54849c88dabfae9b40132fad',\n",
       "      '5d43d51b7390bff0db5fefc5'],\n",
       "     'authors': [{'id': '56077d1c45ce1e595f127ae1', 'name': 'Liu Xin'},\n",
       "      {'name': 'Ou Jiefu'},\n",
       "      {'id': '54849c88dabfae9b40132fad', 'name': 'Song Yangqiu'},\n",
       "      {'id': '5d43d51b7390bff0db5fefc5', 'name': 'Jiang Xin'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/530',\n",
       "     'headline': 'We present a novel model, BMGF-RoBERTa, that combines representation, matching, and fusion modules for implicit discourse relation classification',\n",
       "     'id': '5ea8009091e0111d387ee83a',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d463152332381681',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 4,\n",
       "     'num_viewed': 250,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.12617.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2004.12617.pdf_3760bwmn_images_y7v96djw/img-001.png',\n",
       "     'title': 'On the Importance of Word and Sentence Representation Learning in\\n  Implicit Discourse Relation Classification',\n",
       "     'year': 2020},\n",
       "    {'aids': ['56187ad945ce1e5964076103',\n",
       "      '562b072845cedb3398967594',\n",
       "      '542ce9bddabfae216e635f49',\n",
       "      '53f446a6dabfaee02ad19d77',\n",
       "      '53f47977dabfae8a6845b643'],\n",
       "     'authors': [{'id': '56187ad945ce1e5964076103', 'name': 'Chenwei Zhang'},\n",
       "      {'id': '562b072845cedb3398967594', 'name': 'Yaliang Li'},\n",
       "      {'id': '542ce9bddabfae216e635f49', 'name': 'Nan Du'},\n",
       "      {'id': '53f446a6dabfaee02ad19d77', 'name': 'Wei Fan'},\n",
       "      {'id': '53f47977dabfae8a6845b643', 'name': 'Philip S. Yu'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/199',\n",
       "     'headline': 'We report the precision at position K, recall at position K, and F1 score at position K',\n",
       "     'id': '5ef96b048806af6ef277207e',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d46315233238167b',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 1,\n",
       "     'num_viewed': 249,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/1865/1703/1909/5ef96b048806af6ef277207e_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0199.pdf_4dnz7bt0_images_i1zijwl1/img-001.png',\n",
       "     'title': 'Entity Synonym Discovery via Multipiece Bilateral Context Matching',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  System combination is an important technique for combining the hypotheses of different machine translation systems to improve translation performance. Although early statistical approaches to system combination have been proven effective in analyzing the consensus between hypotheses, they suffer from the error propagation problem due to the use of pipelines. While this problem has been alleviated by end-to-end training of multi-source sequence-to-sequence models recently, these neural models do not explicitly analyze the relations between hypotheses and fail to capture their agreement because the attention to a word in a hypothesis is calculated independently, ignoring the fact that the word might occur in multiple hypotheses. In this work, we propose an approach to modeling voting for system combination in machine translation. The basic idea is to enable words in hypotheses from different systems to vote on words that are representative and should get involved in the generation process. This can be done by quantifying the influence of each voter and its preference for each candidate. Our approach combines the advantages of statistical and neural methods since it can not only analyze the relations between hypotheses but also allow for end-to-end training. Experiments show that our approach is capable of better taking advantage of the consensus between hypotheses and achieves significant improvements over state-of-the-art baselines on Chinese-English and English-German machine translation tasks. ',\n",
       "     'aids': ['53f43253dabfaeb2ac0290d7',\n",
       "      '53f42eeadabfaee02ac747ce',\n",
       "      '542c23f0dabfaed7e63f7b4f',\n",
       "      '53f4d3f6dabfaef205f81ad0',\n",
       "      '53f42dc0dabfaedce54ca0bb',\n",
       "      '5624979245cedb3398527696',\n",
       "      '5429defadabfaec7081c26e4',\n",
       "      '562506cd45cedb3398570152'],\n",
       "     'authors': [{'id': '53f43253dabfaeb2ac0290d7', 'name': 'Xuancheng Huang'},\n",
       "      {'id': '53f42eeadabfaee02ac747ce', 'name': 'Jiacheng Zhang'},\n",
       "      {'id': '542c23f0dabfaed7e63f7b4f', 'name': 'Zhixing Tan'},\n",
       "      {'id': '53f4d3f6dabfaef205f81ad0', 'name': 'Derek F. Wong'},\n",
       "      {'id': '53f42dc0dabfaedce54ca0bb', 'name': 'Huanbo Luan'},\n",
       "      {'id': '5624979245cedb3398527696', 'name': 'Jingfang Xu'},\n",
       "      {'id': '5429defadabfaec7081c26e4', 'name': 'Maosong Sun'},\n",
       "      {'id': '562506cd45cedb3398570152', 'name': 'Yang Liu'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/511',\n",
       "     'headline': 'We have presented a voting mechanism for system combination in machine translation',\n",
       "     'id': '5ef96b048806af6ef27721ea',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f364d979e9598217a91c6ad',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 248,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2007/2007.06943.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2007.06943.pdf_7auhy_l0_images_ndvzt9kh/img-001.png',\n",
       "     'title': 'Modeling Voting for System Combination in Machine Translation',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Neural architecture search (NAS) proves to be among the best approaches for many tasks by generating an application-adaptive neural architecture, which is still challenged by high computational cost and memory consumption. At the same time, 1-bit convolutional neural networks (CNNs) with binarized weights and activations show their potential for resource-limited embedded devices. One natural approach is to use 1-bit CNNs to reduce the computation and memory cost of NAS by taking advantage of the strengths of each in a unified framework. To this end, a Child-Parent (CP) model is introduced to a differentiable NAS to search the binarized architecture (Child) under the supervision of a full-precision model (Parent). In the search stage, the Child-Parent model uses an indicator generated by the child and parent model accuracy to evaluate the performance and abandon operations with less potential. In the training stage, a kernel-level CP loss is introduced to optimize the binarized network. Extensive experiments demonstrate that the proposed CP-NAS achieves a comparable accuracy with traditional NAS on both the CIFAR and ImageNet databases. It achieves the accuracy of $95.27\\\\%$ on CIFAR-10, $64.3\\\\%$ on ImageNet with binarized weights and activations, and a $30\\\\%$ faster search than prior arts. ',\n",
       "     'aids': ['560b36c945cedb33972977e1',\n",
       "      '542a623fdabfae646d559b98',\n",
       "      '542ab5a8dabfae646d58179a',\n",
       "      '562df3e845ce1e5967b7a48c',\n",
       "      '53f4d100dabfaeedd977eb33'],\n",
       "     'authors': [{'name': 'Lian Zhuo'},\n",
       "      {'id': '560b36c945cedb33972977e1', 'name': 'Baochang Zhang'},\n",
       "      {'id': '542a623fdabfae646d559b98', 'name': 'Hanlin Chen'},\n",
       "      {'id': '542ab5a8dabfae646d58179a', 'name': 'Linlin Yang'},\n",
       "      {'id': '562df3e845ce1e5967b7a48c', 'name': 'Chen Chen'},\n",
       "      {'name': 'Yanjun Zhu'},\n",
       "      {'id': '53f4d100dabfaeedd977eb33', 'name': 'David Doermann'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/144',\n",
       "     'headline': 'We calculate 1-bit convolutional neural networks based on the proposed Child-Parent model under the full-precision network supervision',\n",
       "     'id': '5eafe7e091e01198d3986547',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5eba73c1d9c8f52685b16eb9',\n",
       "     'num_citation': 2,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 234,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/873/1798/118/5eafe7e091e01198d3986547_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5eafe7e091e01198d3986547_0.pdf_qg_ou4z2_images_d30h6o33/img-001.png',\n",
       "     'title': 'CP-NAS: Child-Parent Neural Architecture Search for 1-bit CNNs',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Policy distillation, which transfers a teacher policy to a student policy has achieved great success in challenging tasks of deep reinforcement learning. This teacher-student framework requires a well-trained teacher model which is computationally expensive. Moreover, the performance of the student model could be limited by the teacher model if the teacher model is not optimal. In the light of collaborative learning, we study the feasibility of involving joint intellectual efforts from diverse perspectives of student models. In this work, we introduce dual policy distillation(DPD), a student-student framework in which two learners operate on the same environment to explore different perspectives of the environment and extract knowledge from each other to enhance their learning. The key challenge in developing this dual learning framework is to identify the beneficial knowledge from the peer learner for contemporary learning-based reinforcement learning algorithms, since it is unclear whether the knowledge distilled from an imperfect and noisy peer learner would be helpful. To address the challenge, we theoretically justify that distilling knowledge from a peer learner will lead to policy improvement and propose a disadvantageous distillation strategy based on the theoretical results. The conducted experiments on several continuous control tasks show that the proposed framework achieves superior performance with a learning-based agent and function approximation without the use of expensive teacher models. ',\n",
       "     'aids': ['562c44f945cedb3398bd61e8',\n",
       "      '5d50c3f97390bff0db2abd30',\n",
       "      '5d415c0c7390bff0db70c464',\n",
       "      '542a95efdabfae61d4993355'],\n",
       "     'authors': [{'id': '562c44f945cedb3398bd61e8', 'name': 'Lai Kwei-Herng'},\n",
       "      {'id': '5d50c3f97390bff0db2abd30', 'name': 'Zha Daochen'},\n",
       "      {'id': '5d415c0c7390bff0db70c464', 'name': 'Li Yuening'},\n",
       "      {'id': '542a95efdabfae61d4993355', 'name': 'Hu Xia'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/435',\n",
       "     'headline': 'We introduce dual policy distillation, a studentstudent framework which enables two policies to explore different aspects of the environment and exploit the knowledge from each other',\n",
       "     'id': '5edf5dd891e011bc656ded14',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0501d463152332381685',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 234,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/826/467/128/5edf5dd891e011bc656ded14_0.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5edf5dd891e011bc656ded14_0.pdf_na6ejhu6_images_lzmy8dlk/img-001.png',\n",
       "     'title': 'Dual Policy Distillation',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  A rising vision for AI in the open world centers on the development of systems that can complement humans for perceptual, diagnostic, and reasoning tasks. To date, systems aimed at complementing the skills of people have employed models trained to be as accurate as possible in isolation. We demonstrate how an end-to-end learning strategy can be harnessed to optimize the combined performance of human-machine teams by considering the distinct abilities of people and machines. The goal is to focus machine learning on problem instances that are difficult for humans, while recognizing instances that are difficult for the machine and seeking human input on them. We demonstrate in two real-world domains (scientific discovery and medical diagnosis) that human-machine teams built via these methods outperform the individual performance of machines and people. We then analyze conditions under which this complementarity is strongest, and which training methods amplify it. Taken together, our work provides the first systematic investigation of how machine learning systems can be trained to complement human reasoning. ',\n",
       "     'aids': ['5d50c3de7390bff0db2aa5fd',\n",
       "      '53f48d8bdabfaea7cd1d315a',\n",
       "      '53f4306fdabfaec09f13af74'],\n",
       "     'authors': [{'id': '5d50c3de7390bff0db2aa5fd', 'name': 'Wilder Bryan'},\n",
       "      {'id': '53f48d8bdabfaea7cd1d315a', 'name': 'Horvitz Eric'},\n",
       "      {'id': '53f4306fdabfaec09f13af74', 'name': 'Kamar Ece'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/212',\n",
       "     'headline': 'We studied how machine learning systems can be optimized to complement humans via the use of discriminative and decision-theoretic modeling methodologies',\n",
       "     'id': '5eb78919da5629cf2443038f',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0502d4631523323816b2',\n",
       "     'num_citation': 1,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 231,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.00582.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/2005.00582.pdf__n4c9qjj_images_je5xv5_g/img-001.png',\n",
       "     'title': 'Learning to Complement Humans',\n",
       "     'year': 2020},\n",
       "    {'abstract': '  Graph Neural Networks (GNNs) are powerful to learn the representation of graph-structured data. Most of the GNNs use the message-passing scheme, where the embedding of a node is iteratively updated by aggregating the information of its neighbors. To achieve a better expressive capability of node influences, attention mechanism has grown to become a popular way to assign trainable weights of a nodes neighbors in the aggregation. However, though the attention-based GNNs have achieved state-of-the-art results on several tasks, a clear understanding of their discriminative capacities is missing. In this work, we present a theoretical analysis of the representational properties of the GNN that adopts attention mechanism as an aggregator. In the analysis, we show all of the cases when those GNNs always fail to distinguish distinct structures. The finding shows existing attention-based aggregators fail to preserve the cardinality of the multiset of node feature vectors in the aggregation, thus limits their discriminative ability. To improve the performance of attention-based GNNs, we propose two cardinality preserved modifications that can be applied to any kind of attention mechanisms. We evaluate them in our GNN framework on benchmark datasets for graph classification. The results validate the improvements and show the competitive performance of our models. ',\n",
       "     'aids': ['540fd658dabfae450f4ab286'],\n",
       "     'authors': [{'id': '540fd658dabfae450f4ab286', 'name': 'Zhang Shuo'},\n",
       "      {'name': 'Xie Lei'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/194',\n",
       "     'headline': 'We propose cardinality preserved attention models to solve this issue',\n",
       "     'id': '5d1f1fd13a55ac72f611c7f0',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0502d4631523323816ad',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 1,\n",
       "     'num_viewed': 220,\n",
       "     'pdf': 'https://static.aminer.cn/upload/pdf/1364/1977/1313/5d1f1fd13a55ac72f611c7f0_1.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/5d1f1fd13a55ac72f611c7f0_0.pdf_bfi0bmfa_images_paxal3ld/img-001.png',\n",
       "     'resources': {'code': [{'desc': '',\n",
       "        'link': 'https://github.com/zetayue/CPA',\n",
       "        'peek': ''}]},\n",
       "     'title': 'Improving Attention Mechanism in Graph Neural Networks via Cardinality\\n  Preservation',\n",
       "     'year': 2019},\n",
       "    {'aids': ['5619fa9145cedb3397e14216',\n",
       "      '53f43454dabfaedce551b305',\n",
       "      '5613428445cedb33979ac577',\n",
       "      '5632006045cedb3399f8cbab',\n",
       "      '5405e2b0dabfae44f0830d0b',\n",
       "      '561ea8b245cedb339813b58c',\n",
       "      '5d50c3947390bff0db2a689f',\n",
       "      '560fe71345ce1e5961f0fe0f',\n",
       "      '53f43a9cdabfaeb2ac075577',\n",
       "      '542b88e7dabfae20066006ce',\n",
       "      '5613fcd345ce1e59632c4534'],\n",
       "     'authors': [{'id': '5619fa9145cedb3397e14216', 'name': 'Tianpei Yang'},\n",
       "      {'id': '53f43454dabfaedce551b305', 'name': 'Jianye Hao'},\n",
       "      {'id': '5613428445cedb33979ac577', 'name': 'Zhaopeng Meng'},\n",
       "      {'id': '5632006045cedb3399f8cbab', 'name': 'Zongzhang Zhang'},\n",
       "      {'id': '5405e2b0dabfae44f0830d0b', 'name': 'Yujing Hu'},\n",
       "      {'id': '561ea8b245cedb339813b58c', 'name': 'Yingfeng Chen'},\n",
       "      {'id': '5d50c3947390bff0db2a689f', 'name': 'Changjie Fan'},\n",
       "      {'id': '560fe71345ce1e5961f0fe0f', 'name': 'Weixun Wang'},\n",
       "      {'id': '53f43a9cdabfaeb2ac075577', 'name': 'Wulong Liu'},\n",
       "      {'id': '542b88e7dabfae20066006ce', 'name': 'Zhaodong Wang'},\n",
       "      {'id': '5613fcd345ce1e59632c4534', 'name': 'Jiajie Peng'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/428',\n",
       "     'headline': 'We propose a novel Policy Transfer Framework by taking advantage of this idea',\n",
       "     'id': '5ef96b048806af6ef2772111',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0503d4631523323816cc',\n",
       "     'num_citation': 0,\n",
       "     'num_like': 1,\n",
       "     'num_viewed': 218,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0428.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0428.pdf_rrkam_3v_images_hsp6ggyd/img-001.png',\n",
       "     'title': 'Efficient Deep Reinforcement Learning via Adaptive Policy Transfer',\n",
       "     'year': 2020},\n",
       "    {'aids': ['5d50c3b57390bff0db2a8363',\n",
       "      '562d490f45cedb3398db09bc',\n",
       "      '53f564e9dabfae60b4f8045b',\n",
       "      '5630f06645ceb49c5de19c07',\n",
       "      '53f43bcedabfaec09f1b03a8'],\n",
       "     'authors': [{'id': '5d50c3b57390bff0db2a8363', 'name': 'Zhongyang Li'},\n",
       "      {'id': '562d490f45cedb3398db09bc', 'name': 'Xiao Ding'},\n",
       "      {'id': '53f564e9dabfae60b4f8045b', 'name': 'Ting Liu'},\n",
       "      {'id': '5630f06645ceb49c5de19c07', 'name': 'J. Edward Hu'},\n",
       "      {'id': '53f43bcedabfaec09f1b03a8', 'name': 'Benjamin Van Durme'}],\n",
       "     'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "     'doi': '10.24963/ijcai.2020/502',\n",
       "     'headline': 'We introduced a novel extension to lexically-constrained decoding that supports disjunctive positive constraints, where generated output is forced to contain one of a set of candidates',\n",
       "     'id': '5ef96b048806af6ef27721d9',\n",
       "     'is_like': False,\n",
       "     'mrt_link': '5f4e0503d4631523323816bf',\n",
       "     'num_citation': 1,\n",
       "     'num_like': 0,\n",
       "     'num_viewed': 207,\n",
       "     'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0502.pdf',\n",
       "     'picture': 'https://cloud-api.scholarcy.com/images/0502.pdf_l5v4uks8_images_nivotp40/img-001.png',\n",
       "     'title': 'Guided Generation of Cause and Effect',\n",
       "     'year': 2020}],\n",
       "   'meta': {'context': 'C97E7A74', 'time': '803.557762ms'},\n",
       "   'succeed': True,\n",
       "   'total': 645},\n",
       "  'MostViewPubsData': [{'abstract': 'Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.',\n",
       "    'aids': ['562d52a145cedb3398dc4e62',\n",
       "     '53f5735cdabfae7b13f8045b',\n",
       "     '53f4c7b3dabfaee57877ceca',\n",
       "     '53f39418dabfae4b34a67084'],\n",
       "    'authors': [{'id': '562d52a145cedb3398dc4e62',\n",
       "      'name': 'Devendra Singh Chaplot'},\n",
       "     {'name': 'Lisa Lee'},\n",
       "     {'id': '53f5735cdabfae7b13f8045b', 'name': 'Ruslan Salakhutdinov'},\n",
       "     {'id': '53f4c7b3dabfaee57877ceca', 'name': 'Devi Parikh'},\n",
       "     {'id': '53f39418dabfae4b34a67084', 'name': 'Dhruv Batra'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '',\n",
       "    'headline': 'We show that the proposed model is able to transfer the knowledge of concepts across tasks and outperforms the baselines on both Semantic Goal Navigation and Embodied Question Answering by a considerable margin',\n",
       "    'id': '5cede0f0da562983788cec6c',\n",
       "    'is_like': False,\n",
       "    'lang': 'en',\n",
       "    'mrt_link': '5f4e0501d46315233238167a',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 8,\n",
       "    'num_viewed': 555,\n",
       "    'pdf': 'https://static.aminer.cn/upload/pdf/program/5cede0f0da562983788cec6c_0.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/5cede0f0da562983788cec6c_0.pdf_4giexpl7_images_1oa_h4a1/img-002.png',\n",
       "    'title': 'Embodied Multimodal Multitask Learning.',\n",
       "    'year': 2019},\n",
       "   {'abstract': '  A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders with arbitrary manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the Diffusion Variational Autoencoder is capable of capturing topological properties of synthetic datasets. Additionally, we train MNIST on spheres, tori, projective spaces, SO(3), and a torus embedded in R3. Although a natural dataset like MNIST does not have latent variables with a clear-cut topological structure, training it on a manifold can still highlight topological and geometrical properties. ',\n",
       "    'aids': ['562befd945ce1e59672605d2', '53f446a1dabfaee02ad19c3a'],\n",
       "    'authors': [{'id': '562befd945ce1e59672605d2',\n",
       "      'name': 'Luis A. P&eacute;rez Rey'},\n",
       "     {'id': '53f446a1dabfaee02ad19c3a', 'name': 'Vlado Menkovski'},\n",
       "     {'name': 'Jacobus W. Portegies'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'headline': 'We developed and implemented Diffusion Variational Autoencoders, which allow for arbitrary manifolds as a latent space 1',\n",
       "    'id': '5cede0f1da562983788cf9db',\n",
       "    'is_like': False,\n",
       "    'lang': 'en',\n",
       "    'mrt_link': '5f4e050dd4631523323817e0',\n",
       "    'num_citation': 8,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 432,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/19/1901/1901.08991.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/1901.08991.pdf_7hbjasud_images_h446zzie/img-001.png',\n",
       "    'title': 'Diffusion Variational Autoencoders.',\n",
       "    'year': 2019},\n",
       "   {'aids': ['53f4324cdabfaeb22f446b37',\n",
       "     '560a0cf245ce1e595fb1333b',\n",
       "     '542a2a04dabfae5848aa3005'],\n",
       "    'authors': [{'id': '53f4324cdabfaeb22f446b37', 'name': 'Chao Li'},\n",
       "     {'id': '560a0cf245ce1e595fb1333b', 'name': 'Baolin Liu'},\n",
       "     {'id': '542a2a04dabfae5848aa3005', 'name': 'Jianguo Wei'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/103',\n",
       "    'headline': 'Based on the concept of shared features, we built encoding models to explore the relationship between the deep convolutional neural networks and human brain activity, and proposed a reconstruction method for decoding brain signals',\n",
       "    'id': '5ef96b048806af6ef2772066',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0517d4631523323818e6',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 1,\n",
       "    'num_viewed': 400,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0103.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/0103.pdf_i8cosexo_images_p99mhwn4/img-001.png',\n",
       "    'title': 'Visual Encoding and Decoding of the Human Brain Based on Shared Features',\n",
       "    'year': 2020},\n",
       "   {'aids': ['561aaf8145cedb3397ea5619',\n",
       "     '5429704cdabfae82c0e59767',\n",
       "     '5d43d54e7390bff0db600ec1',\n",
       "     '5d43d54e7390bff0db600ecb',\n",
       "     '542a4d53dabfae61d49671e5',\n",
       "     '53f435c9dabfaee43ec2b29c',\n",
       "     '542a5f39dabfae61d497310f'],\n",
       "    'authors': [{'id': '561aaf8145cedb3397ea5619', 'name': 'Hongmin Zhu'},\n",
       "     {'id': '5429704cdabfae82c0e59767', 'name': 'Fuli Feng'},\n",
       "     {'id': '5d43d54e7390bff0db600ec1', 'name': 'Xiangnan He'},\n",
       "     {'id': '5d43d54e7390bff0db600ecb', 'name': 'Xiang Wang'},\n",
       "     {'id': '542a4d53dabfae61d49671e5', 'name': 'Yan Li'},\n",
       "     {'id': '53f435c9dabfaee43ec2b29c', 'name': 'Kai Zheng'},\n",
       "     {'id': '542a5f39dabfae61d497310f', 'name': 'Yongdong Zhang'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/202',\n",
       "    'headline': 'We proposed Bilinear Graph Neural Network, a new graph neural network framework, which augments the expressiveness of vanilla Graph Neural Network by considering the interactions between neighbor nodes',\n",
       "    'id': '5ef96b048806af6ef2772079',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d46315233238168a',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 353,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0202.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/0202.pdf_oljtg_ml_images_a6ukth8v/img-001.png',\n",
       "    'title': 'Bilinear Graph Neural Network with Neighbor Interactions',\n",
       "    'year': 2020},\n",
       "   {'aids': ['5609328045cedb3396e4fb5a',\n",
       "     '5625328c45cedb3398592763',\n",
       "     '542ce893dabfae216e635dd8',\n",
       "     '53f43e5fdabfaec09f1b56fc',\n",
       "     '53f325a3dabfae9a8446fa8f',\n",
       "     '542ce910dabfae4b91c2d971',\n",
       "     '53f642d9dabfaed4ec0f3d1a'],\n",
       "    'authors': [{'id': '5609328045cedb3396e4fb5a', 'name': 'Zhongxia Chen'},\n",
       "     {'id': '5625328c45cedb3398592763', 'name': 'Xiting Wang'},\n",
       "     {'id': '542ce893dabfae216e635dd8', 'name': 'Xing Xie'},\n",
       "     {'id': '53f43e5fdabfaec09f1b56fc', 'name': 'Mehul Parsana'},\n",
       "     {'id': '53f325a3dabfae9a8446fa8f', 'name': 'Akshay Soni'},\n",
       "     {'id': '542ce910dabfae4b91c2d971', 'name': 'Xiang Ao'},\n",
       "     {'id': '53f642d9dabfaed4ec0f3d1a', 'name': 'Enhong Chen'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/414',\n",
       "    'headline': 'We propose a framework for explainable conversational recommendation, which enables tight collaboration between the recommendation task, the explanation generation task, and the incremental feedback integration module',\n",
       "    'id': '5ef96b048806af6ef277218c',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d463152332381679',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 2,\n",
       "    'num_viewed': 335,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0414.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/0414.pdf_59o7rmld_images_idbhf1ao/img-001.png',\n",
       "    'title': 'Towards Explainable Conversational Recommendation',\n",
       "    'year': 2020},\n",
       "   {'aids': ['542d8ffddabfae48d12392e2',\n",
       "     '561a410a45ce1e59645fd5c0',\n",
       "     '53f4720bdabfaee1c0b9435d',\n",
       "     '56046cf445cedb33963c4447'],\n",
       "    'authors': [{'id': '542d8ffddabfae48d12392e2', 'name': 'Tong Wu'},\n",
       "     {'id': '561a410a45ce1e59645fd5c0', 'name': 'Bicheng Dai'},\n",
       "     {'name': 'Shuxin Chen'},\n",
       "     {'id': '53f4720bdabfaee1c0b9435d', 'name': 'Yanyun Qu'},\n",
       "     {'id': '56046cf445cedb33963c4447', 'name': 'Yuan Xie'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/76',\n",
       "    'headline': 'We propose Meta Segmentation Network for the effective segmentation of medical ultra-resolution image',\n",
       "    'id': '5ef96b048806af6ef2772042',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d46315233238167f',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 318,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/ijcai/20/0076.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/0076.pdf_ke1f37gq_images_os6i52d4/img-001.png',\n",
       "    'title': 'Meta Segmentation Network for Ultra-Resolution Medical Images',\n",
       "    'year': 2020},\n",
       "   {'abstract': '  Multi-lingual contextualized embeddings, such as multilingual-BERT (mBERT), have shown success in a variety of zero-shot cross-lingual tasks. However, these models are limited by having inconsistent contextualized representations of subwords across different languages. Existing work addresses this issue by bilingual projection and fine-tuning technique. We propose a data augmentation framework to generate multi-lingual code-switching data to fine-tune mBERT, which encourages model to align representations from source and multiple target languages once by mixing their context information. Compared with the existing work, our method does not rely on bilingual sentences for training, and requires only one training process for multiple target languages. Experimental results on five tasks with 19 languages show that our method leads to significantly improved performances for all the tasks compared with mBERT. ',\n",
       "    'aids': ['5448b07bdabfae1e04135dad',\n",
       "     '53f80060dabfae8faa4cea01',\n",
       "     '53f42c90dabfaee02ac54f1b'],\n",
       "    'authors': [{'id': '5448b07bdabfae1e04135dad', 'name': 'Qin Libo'},\n",
       "     {'name': 'Ni Minheng'},\n",
       "     {'id': '53f80060dabfae8faa4cea01', 'name': 'Zhang Yue'},\n",
       "     {'id': '53f42c90dabfaee02ac54f1b', 'name': 'Che Wanxiang'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/533',\n",
       "    'headline': 'We proposed an augmentation framework to generate multilingual code-switching data to fine-tune mBERT for aligning representations from source and multiple target languages',\n",
       "    'id': '5ee3527191e011cb3bff760a',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d463152332381689',\n",
       "    'num_citation': 0,\n",
       "    'num_like': 2,\n",
       "    'num_viewed': 312,\n",
       "    'pdf': 'https://static.aminer.cn/upload/pdf/265/1170/1990/5ee3527191e011cb3bff760a_0.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/5ee3527191e011cb3bff760a_0.pdf_b5t6394e_images_ndba6j0m/img-001.png',\n",
       "    'resources': {'code': [{'desc': '',\n",
       "       'link': 'https://github.com/kodenii/CoSDA-ML',\n",
       "       'peek': ''}]},\n",
       "    'title': 'CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot\\n  Cross-Lingual NLP',\n",
       "    'year': 2020},\n",
       "   {'abstract': '  Large pre-trained language models such as BERT have shown their effectiveness in various natural language processing tasks. However, the huge parameter size makes them difficult to be deployed in real-time applications that require quick inference with limited resources. Existing methods compress BERT into small models while such compression is task-independent, i.e., the same compressed BERT for all different downstream tasks. Motivated by the necessity and benefits of task-oriented BERT compression, we propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks. We incorporate a task-oriented knowledge distillation loss to provide search hints and an efficiency-aware loss as search constraints, which enables a good trade-off between efficiency and effectiveness for task-adaptive BERT compression. We evaluate AdaBERT on several NLP tasks, and the results demonstrate that those task-adaptive compressed models are 12.7x to 29.3x faster than BERT in inference time and 11.5x to 17.0x smaller in terms of parameter size, while comparable performance is maintained. ',\n",
       "    'aids': ['562b072845cedb3398967594',\n",
       "     '53f43331dabfaedce550dffa',\n",
       "     '54055181dabfae92b41c32d0',\n",
       "     '53f4da76dabfaef7e377b3e6',\n",
       "     '53f470e3dabfaee02adbdea8',\n",
       "     '53fa0e27dabfae91d3fc74ec',\n",
       "     '5486c666dabfae9b40134002'],\n",
       "    'authors': [{'name': 'Chen Daoyuan'},\n",
       "     {'id': '562b072845cedb3398967594', 'name': 'Li Yaliang'},\n",
       "     {'id': '53f43331dabfaedce550dffa', 'name': 'Qiu Minghui'},\n",
       "     {'name': 'Wang Zhen'},\n",
       "     {'name': 'Li Bofang'},\n",
       "     {'id': '53f4da76dabfaef7e377b3e6', 'name': 'Ding Bolin'},\n",
       "     {'id': '53f470e3dabfaee02adbdea8', 'name': 'Deng Hongbo'},\n",
       "     {'name': 'Huang Jun'},\n",
       "     {'id': '53fa0e27dabfae91d3fc74ec', 'name': 'Lin Wei'},\n",
       "     {'id': '5486c666dabfae9b40134002', 'name': 'Zhou Jingren'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/341',\n",
       "    'headline': 'Extensive experiments demonstrate that AdaBERT achieves comparable performance while significantly improves the efficiency by 12.7x to 29.3x speedup in inference time and 11.5x to 17.0x compression ratio in parameter size',\n",
       "    'id': '5e1d915f3a55ac91798fe9bf',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d46315233238167d',\n",
       "    'num_citation': 5,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 310,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2001/2001.04246.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/2001.04246.pdf_u5d6lumm_images_471yak8x/img-001.png',\n",
       "    'title': 'AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\\n  Architecture Search',\n",
       "    'year': 2020},\n",
       "   {'abstract': '  Channel pruning is among the predominant approaches to compress deep neural networks. To this end, most existing pruning methods focus on selecting channels (filters) by importance/optimization or regularization based on rule-of-thumb designs, which defects in sub-optimal pruning. In this paper, we propose a new channel pruning method based on artificial bee colony algorithm (ABC), dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \"important\" channels as previous works did. To solve the intractably huge combinations of pruned structure for deep networks, we first propose to shrink the combinations where the preserved channels are limited to a specific space, thus the combinations of pruned structure can be significantly reduced. And then, we formulate the search of optimal pruned structure as an optimization problem and integrate the ABC algorithm to solve it in an automatic manner to lessen human interference. ABCPruner has been demonstrated to be more effective, which also enables the fine-tuning to be conducted efficiently in an end-to-end manner. Experiments on CIFAR-10 show that ABCPruner reduces 73.68\\\\% of FLOPs and 88.68\\\\% of parameters with even 0.06\\\\% accuracy improvement for VGGNet-16. On ILSVRC-2012, it achieves a reduction of 62.87\\\\% FLOPs and removes 60.01\\\\% of parameters with negligible accuracy cost for ResNet-152. The source codes can be available at https://github.com/lmbxmu/ABCPruner. ',\n",
       "    'aids': ['5620512a45ceff436be1f4c2',\n",
       "     '5484d882dabfaed7b5fa1c4d',\n",
       "     '560fc42d45cedb339777a222',\n",
       "     '560b36c945cedb33972977e1',\n",
       "     '53f43c26dabfaee2a1d1a9b6',\n",
       "     '542a50a2dabfae61d496977f'],\n",
       "    'authors': [{'id': '5620512a45ceff436be1f4c2', 'name': 'Lin Mingbao'},\n",
       "     {'id': '5484d882dabfaed7b5fa1c4d', 'name': 'Ji Rongrong'},\n",
       "     {'id': '560fc42d45cedb339777a222', 'name': 'Zhang Yuxin'},\n",
       "     {'id': '560b36c945cedb33972977e1', 'name': 'Zhang Baochang'},\n",
       "     {'id': '53f43c26dabfaee2a1d1a9b6', 'name': 'Wu Yongjian'},\n",
       "     {'id': '542a50a2dabfae61d496977f', 'name': 'Tian Yonghong'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/94',\n",
       "    'headline': 'We propose a new channel pruning method based on artificial bee colony algorithm, dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting \"important\" channels as previous works did',\n",
       "    'id': '5e2ac03c3a55ac8999c1ae65',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d463152332381684',\n",
       "    'num_citation': 1,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 307,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2001/2001.08565.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/2001.08565.pdf_gcdhtczj_images_w8c2jure/img-001.png',\n",
       "    'title': 'Channel Pruning via Automatic Structure Search',\n",
       "    'year': 2020},\n",
       "   {'abstract': '  To enable DNNs on edge devices like mobile phones, low-rank approximation has been widely adopted because of its solid theoretical rationale and efficient implementations. Several previous works attempted to directly approximate a pretrained model by low-rank decomposition; however, small approximation errors in parameters can ripple over a large prediction loss. As a result, performance usually drops significantly and a sophisticated effort on fine-tuning is required to recover accuracy. Apparently, it is not optimal to separate low-rank approximation from training. Unlike previous works, this paper integrates low rank approximation and regularization into the training process. We propose Trained Rank Pruning (TRP), which alternates between low rank approximation and training. TRP maintains the capacity of the original network while imposing low-rank constraints during training. A nuclear regularization optimized by stochastic sub-gradient descent is utilized to further promote low rank in TRP. The TRP trained network inherently has a low-rank structure, and is approximated with negligible performance loss, thus eliminating the fine-tuning process after low rank decomposition. The proposed method is comprehensively evaluated on CIFAR-10 and ImageNet, outperforming previous compression methods using low rank approximation. ',\n",
       "    'aids': ['5606d9d345ce1e595ed46ac1',\n",
       "     '562c7d4445cedb3398c3a177',\n",
       "     '5632020f45cedb3399f90317',\n",
       "     '53f4496bdabfaee4dc7dd654',\n",
       "     '53f42f40dabfaeb1a7ba3174',\n",
       "     '53f43838dabfaeb22f48248b',\n",
       "     '562b045545cedb3398963955',\n",
       "     '53f4675edabfaeecd6a10d6d'],\n",
       "    'authors': [{'id': '5606d9d345ce1e595ed46ac1', 'name': 'Xu Yuhui'},\n",
       "     {'name': 'Li Yuxi'},\n",
       "     {'id': '562c7d4445cedb3398c3a177', 'name': 'Zhang Shuai'},\n",
       "     {'id': '5632020f45cedb3399f90317', 'name': 'Wen Wei'},\n",
       "     {'id': '53f4496bdabfaee4dc7dd654', 'name': 'Wang Botao'},\n",
       "     {'id': '53f42f40dabfaeb1a7ba3174', 'name': 'Qi Yingyong'},\n",
       "     {'id': '53f43838dabfaeb22f48248b', 'name': 'Chen Yiran'},\n",
       "     {'id': '562b045545cedb3398963955', 'name': 'Lin Weiyao'},\n",
       "     {'id': '53f4675edabfaeecd6a10d6d', 'name': 'Xiong Hongkai'}],\n",
       "    'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "    'doi': '10.24963/ijcai.2020/136',\n",
       "    'headline': 'We proposed a new scheme Trained Rank Pruning for training low-rank networks',\n",
       "    'id': '5eabf34391e011664ffd2878',\n",
       "    'is_like': False,\n",
       "    'mrt_link': '5f4e0501d46315233238167e',\n",
       "    'num_citation': 1,\n",
       "    'num_like': 0,\n",
       "    'num_viewed': 302,\n",
       "    'pdf': 'https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.14566.pdf',\n",
       "    'picture': 'https://cloud-api.scholarcy.com/images/2004.14566.pdf_bjg7kym8_images_5mr7lob2/img-001.png',\n",
       "    'title': 'TRP: Trained Rank Pruning for Efficient Deep Neural Networks',\n",
       "    'year': 2020}],\n",
       "  'KeywordsList': [{'e': 12, 'keywords': 'Learning', 'n': 12, 'w': 12},\n",
       "   {'e': 8, 'keywords': 'Unsupervised', 'n': 8, 'w': 8},\n",
       "   {'e': 7, 'k': 4, 'keywords': 'Graph Neural Network', 'n': 8, 'w': 7},\n",
       "   {'e': 7, 'k': 2, 'keywords': 'Attention Network', 'n': 8, 'w': 7},\n",
       "   {'e': 8, 'keywords': 'Representation Learning', 'n': 8, 'w': 8},\n",
       "   {'e': 7, 'k': 2, 'keywords': 'Deep Reinforcement Learning', 'n': 7, 'w': 7},\n",
       "   {'e': 7, 'k': 2, 'keywords': 'Deep Neural Network', 'n': 7, 'w': 7},\n",
       "   {'e': 6, 'k': 1, 'keywords': 'Convolutional Network', 'n': 6, 'w': 6},\n",
       "   {'e': 6, 'keywords': 'Search', 'n': 6, 'w': 6},\n",
       "   {'e': 6, 'k': 2, 'keywords': 'Neural Machine Translation', 'n': 6, 'w': 6},\n",
       "   {'e': 5, 'k': 3, 'keywords': 'Reinforcement Learning', 'n': 6, 'w': 5},\n",
       "   {'e': 5, 'keywords': 'Hierarchical', 'n': 5, 'w': 5},\n",
       "   {'e': 2, 'k': 3, 'keywords': 'Neural Network', 'n': 5, 'w': 3},\n",
       "   {'e': 5, 'keywords': 'Network', 'n': 5, 'w': 5},\n",
       "   {'e': 5, 'k': 3, 'keywords': 'Multi-label Learning', 'n': 5, 'w': 5},\n",
       "   {'e': 5, 'keywords': 'Neural Architecture', 'n': 5, 'w': 5},\n",
       "   {'e': 3,\n",
       "    'k': 5,\n",
       "    'keywords': 'Convolutional Neural Network',\n",
       "    'n': 5,\n",
       "    'w': 5},\n",
       "   {'e': 5, 'keywords': 'Embedding', 'n': 5, 'w': 5},\n",
       "   {'e': 4, 'k': 2, 'keywords': 'Domain Adaptation', 'n': 5, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Multi-view', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Reading Comprehension', 'n': 4, 'w': 4},\n",
       "   {'e': 3, 'k': 3, 'keywords': 'Deep Learning', 'n': 4, 'w': 3},\n",
       "   {'e': 4, 'keywords': 'Preference', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Semantic', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'VIUM', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Adversarial', 'n': 4, 'w': 4},\n",
       "   {'e': 3, 'k': 2, 'keywords': 'Description Logic', 'n': 4, 'w': 3},\n",
       "   {'e': 4, 'keywords': 'Diversity', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Generating', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Reasoning', 'n': 4, 'w': 4},\n",
       "   {'e': 4, 'keywords': 'Autoencoder', 'n': 4, 'w': 4},\n",
       "   {'e': 3, 'k': 1, 'keywords': 'Anomaly Detection', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Pomdp', 'n': 3, 'w': 3},\n",
       "   {'k': 3, 'keywords': 'Entity Recognition', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Adversarial Training', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 1, 'keywords': 'Optimal Transport', 'n': 3, 'w': 3},\n",
       "   {'e': 2, 'k': 2, 'keywords': 'Adversarial Network', 'n': 3, 'w': 2},\n",
       "   {'e': 2, 'k': 1, 'keywords': 'Metric Learning', 'n': 3, 'w': 2},\n",
       "   {'e': 3, 'keywords': 'Differentiable', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 1, 'keywords': 'Knowledge Graph', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 1, 'keywords': 'Dialogue Generation', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Attention', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'DEEP', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Graph-based', 'n': 3, 'w': 3},\n",
       "   {'e': 2,\n",
       "    'k': 3,\n",
       "    'keywords': 'Unsupervised Domain Adaptation',\n",
       "    'n': 3,\n",
       "    'w': 3},\n",
       "   {'e': 3, 'keywords': 'Pruning', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 1, 'keywords': 'Person Re-identification', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Online', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Weakly Supervised', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Named Entity Recognition', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 3, 'keywords': 'Few-shot Learning', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Explanation', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 2, 'keywords': 'Question Answering', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'k': 2, 'keywords': 'Relation Extraction', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Hashing', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Counting', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Segmentation', 'n': 3, 'w': 3},\n",
       "   {'e': 1, 'k': 2, 'keywords': 'Medical Image', 'n': 3, 'w': 2},\n",
       "   {'e': 3, 'keywords': 'Prediction', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Accelerating', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Meta Learning', 'n': 3, 'w': 3},\n",
       "   {'e': 3, 'keywords': 'Robust', 'n': 3, 'w': 3},\n",
       "   {'e': 2, 'keywords': 'Sparse', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Consistent', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Reconstructing', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Discrepancy', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Training', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Discovering', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Constraint', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Automatic', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Reasoner', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Strategic', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Modeling', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Multi-scale', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Representation', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Generalization', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Error', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Multilingual', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Problem', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Reinforcement Learning Approach', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Gradient', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'One-shot', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Generation', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Neural', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Driven', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Operation', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Multi-task Learning', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Beyond', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Bi-level', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Semantic Segmentation', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Blockchain', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Human-object Interaction', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': ': Learning', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Sequential', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Action', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Dialogue', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Constrained', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Adversarial Learning', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Probabilistic', 'n': 2, 'w': 2},\n",
       "   {'e': 2, 'keywords': 'Clustering', 'n': 2, 'w': 2}],\n",
       "  'SearchAuthorsData': {'items': [{'aid': '540683ccdabfae44f083b82c',\n",
       "     'id': '540683ccdabfae44f083b82c',\n",
       "     'name': 'Yang Gao（高阳）',\n",
       "     'name_zh': '',\n",
       "     'pub_num': 5,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5e3940be3a55ace46ed435e7',\n",
       "        '5ef96b048806af6ef2772017',\n",
       "        '5ef96b048806af6ef2772081',\n",
       "        '5ef96b048806af6ef277203f',\n",
       "        '5ef96b048806af6ef27720fe']}]},\n",
       "    {'aid': '53f43454dabfaedce551b305',\n",
       "     'id': '53f43454dabfaedce551b305',\n",
       "     'name': 'Jianye Hao',\n",
       "     'name_zh': '郝建业',\n",
       "     'pub_num': 5,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ec7a33091e0118397f3ef17',\n",
       "        '5eba73be91e01108d77cf63e',\n",
       "        '5e4d083f3a55ac8cfd770c23',\n",
       "        '5ef96b048806af6ef2772111',\n",
       "        '5ef96b048806af6ef277219d']}]},\n",
       "    {'aid': '56cb18c2c35f4f3c65660dc2',\n",
       "     'id': '56cb18c2c35f4f3c65660dc2',\n",
       "     'name': 'Bo Du',\n",
       "     'name_zh': '杜博',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ef96b048806af6ef2772166',\n",
       "        '5ef96b048806af6ef277205f',\n",
       "        '5ef96b048806af6ef27720fd',\n",
       "        '5ef96b048806af6ef2772047']}]},\n",
       "    {'aid': '56cb1891c35f4f3c6565176f',\n",
       "     'id': '56cb1891c35f4f3c6565176f',\n",
       "     'name': 'Meng Wang',\n",
       "     'name_zh': '汪萌',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ef476b691e01165a63bbbdc',\n",
       "        '5ef3247091e0110c353da56d',\n",
       "        '5ef96b048806af6ef2772040',\n",
       "        '5ef96b048806af6ef2772046']}]},\n",
       "    {'aid': '560cd53c45cedb339757a831',\n",
       "     'id': '560cd53c45cedb339757a831',\n",
       "     'name': 'Wenbin Li',\n",
       "     'name_zh': '李文斌',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5e3940be3a55ace46ed435e7',\n",
       "        '5ef96b048806af6ef2772017',\n",
       "        '5ef96b048806af6ef2772131',\n",
       "        '5ef96b048806af6ef277203f']}]},\n",
       "    {'aid': '53f638cfdabfae7e00c71628',\n",
       "     'id': '53f638cfdabfae7e00c71628',\n",
       "     'name': 'Carla P. Gomes',\n",
       "     'name_zh': '',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5eda19d991e01187f5d6db49',\n",
       "        '5ef96b048806af6ef277222b',\n",
       "        '5ef96b048806af6ef277222c',\n",
       "        '5ef96b048806af6ef2772252']}]},\n",
       "    {'aid': '53f48c9bdabfaea7cd1cf6cc',\n",
       "     'id': '53f48c9bdabfaea7cd1cf6cc',\n",
       "     'name': 'Yong Yu',\n",
       "     'name_zh': '俞勇',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ef96b048806af6ef2772219',\n",
       "        '5ef96b048806af6ef27720a1',\n",
       "        '5ef96b048806af6ef27720a2',\n",
       "        '5ef96b048806af6ef277210e']}]},\n",
       "    {'aid': '53f466dfdabfaedd74e6b9e2',\n",
       "     'id': '53f466dfdabfaedd74e6b9e2',\n",
       "     'name': 'Bo An',\n",
       "     'name_zh': '安波',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ef96b048806af6ef2772127',\n",
       "        '5ef96b048806af6ef27720f1',\n",
       "        '5ef96b048806af6ef2771fe0',\n",
       "        '5ef96b048806af6ef2771ffd']}]},\n",
       "    {'aid': '53f466badabfaee2a1db0053',\n",
       "     'id': '53f466badabfaee2a1db0053',\n",
       "     'name': 'Zhengjun Zha',\n",
       "     'name_zh': '',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5ef96b048806af6ef2772040',\n",
       "        '5ef96b048806af6ef2772151',\n",
       "        '5ef96b048806af6ef2772046',\n",
       "        '5ef96b048806af6ef2772039']}]},\n",
       "    {'aid': '53f45915dabfaee2a1d7e6d0',\n",
       "     'id': '53f45915dabfaee2a1d7e6d0',\n",
       "     'name': 'Shaowei Cai',\n",
       "     'name_zh': '蔡少伟',\n",
       "     'pub_num': 4,\n",
       "     'related_info': [{'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       "       'conf_name': 'ijcai2020',\n",
       "       'pids': ['5e3006423a55ac0524a25b70',\n",
       "        '5ef96b048806af6ef277209e',\n",
       "        '5ef96b048806af6ef277209c',\n",
       "        '5ef96b048806af6ef277206f']}]}],\n",
       "   'meta': {'context': '4ACE2C47', 'time': '56.999657ms'},\n",
       "   'succeed': True,\n",
       "   'total': 2367}}}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = data_dict['aminerConf']['SearchPubsData']['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping a paper for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.',\n",
       " 'aids': ['562d52a145cedb3398dc4e62',\n",
       "  '53f5735cdabfae7b13f8045b',\n",
       "  '53f4c7b3dabfaee57877ceca',\n",
       "  '53f39418dabfae4b34a67084'],\n",
       " 'authors': [{'id': '562d52a145cedb3398dc4e62',\n",
       "   'name': 'Devendra Singh Chaplot'},\n",
       "  {'name': 'Lisa Lee'},\n",
       "  {'id': '53f5735cdabfae7b13f8045b', 'name': 'Ruslan Salakhutdinov'},\n",
       "  {'id': '53f4c7b3dabfaee57877ceca', 'name': 'Devi Parikh'},\n",
       "  {'id': '53f39418dabfae4b34a67084', 'name': 'Dhruv Batra'}],\n",
       " 'conf_id': '5ef86d3592c7f9be218d4b9b',\n",
       " 'doi': '',\n",
       " 'headline': 'We show that the proposed model is able to transfer the knowledge of concepts across tasks and outperforms the baselines on both Semantic Goal Navigation and Embodied Question Answering by a considerable margin',\n",
       " 'id': '5cede0f0da562983788cec6c',\n",
       " 'is_like': False,\n",
       " 'lang': 'en',\n",
       " 'mrt_link': '5f4e0501d46315233238167a',\n",
       " 'num_citation': 0,\n",
       " 'num_like': 8,\n",
       " 'num_viewed': 558,\n",
       " 'pdf': 'https://static.aminer.cn/upload/pdf/program/5cede0f0da562983788cec6c_0.pdf',\n",
       " 'picture': 'https://cloud-api.scholarcy.com/images/5cede0f0da562983788cec6c_0.pdf_4giexpl7_images_1oa_h4a1/img-002.png',\n",
       " 'title': 'Embodied Multimodal Multitask Learning.',\n",
       " 'year': 2019}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Embodied Multimodal Multitask Learning.'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://static.aminer.cn/upload/pdf/program/5cede0f0da562983788cec6c_0.pdf'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]['pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_location = r'D:\\Valentina\\Thesis\\papers'\n",
    "filename = os.path.join(folder_location, papers[0]['title'] + '.pdf')\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(requests.get(papers[0]['pdf']).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping all papers an the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:44<00:00, 11.23s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_location = r'D:\\Valentina\\Thesis\\papers'\n",
    "for paper in tqdm(papers):\n",
    "    title = paper['title'].replace('\\n', '').replace(':', '')\n",
    "    filename = os.path.join(folder_location, title + '.pdf')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(paper['pdf']).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting other pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = '{\"data\":[{\"items\":[{\"aids\":[\"542a2809dabfae5848aa17b8\",\"53f42df3dabfaedd74d3e053\",\"59489cb29ed5db31dcdd0565\",\"562d526545cedb3398dc474d\",\"562e261a45cedb33990beecb\",\"53f4d81cdabfaef64977b5bf\",\"53f66220dabfae6a71b63777\"],\"authors\":[{\"id\":\"542a2809dabfae5848aa17b8\",\"name\":\"Yunbo Wang\"},{\"id\":\"53f42df3dabfaedd74d3e053\",\"name\":\"Bo Liu\"},{\"id\":\"59489cb29ed5db31dcdd0565\",\"name\":\"Jiajun Wu\"},{\"id\":\"562d526545cedb3398dc474d\",\"name\":\"Yuke Zhu\"},{\"id\":\"562e261a45cedb33990beecb\",\"name\":\"Simon S Du\"},{\"id\":\"53f4d81cdabfaef64977b5bf\",\"name\":\"Li Fei-Fei\"},{\"id\":\"53f66220dabfae6a71b63777\",\"name\":\"Joshua B Tenenbaum\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/579\",\"headline\":\"We provided an end-to-end neural network named Dual Sequential Monte Carlo to solve continuous Partially Observable Markov Decision Processes, which has three advantages\",\"id\":\"5ee07fdc9e795e01364da3ca\",\"is_like\":\"false\",\"lang\":\"en\",\"mrt_link\":\"5f4e050dd4631523323817f3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":150,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0579.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0579.pdf_2k5gsklz_images_4g7wyxp6/img-001.png\",\"title\":\"DualSMC: Tunneling Differentiable Filtering and Planning under Continuous POMDPs\",\"year\":2019},{\"abstract\":\"  Conversational machine reading comprehension (MRC) has proven significantly more challenging compared to traditional MRC since it requires better utilization of conversation history. However, most existing approaches do not effectively capture conversation history and thus have trouble handling questions involving coreference or ellipsis. We propose a novel graph neural network (GNN) based model, namely GraphFlow, which captures conversational flow in the dialog. Specifically, we first propose a new approach to dynamically construct a question-aware context graph from passage text at each turn. We then present a novel flow mechanism to model the temporal dependencies in the sequence of context graphs. The proposed GraphFlow model shows superior performance compared to existing state-of-the-art methods. For instance, GraphFlow outperforms two recently proposed models on the CoQA benchmark dataset: FlowQA by 2.3% and SDNet by 0.7% on F1 score, respectively. In addition, visualization experiments show that our proposed model can better mimic the human reasoning process for conversational MRC compared to existing models. \",\"aids\":[\"53f4339fdabfaedce5512fc6\",\"562d97d045cedb3398e741ce\",\"53f4ab9cdabfaecc2877b55a\"],\"authors\":[{\"id\":\"53f4339fdabfaedce5512fc6\",\"name\":\"Chen Yu\"},{\"id\":\"562d97d045cedb3398e741ce\",\"name\":\"Wu Lingfei\"},{\"id\":\"53f4ab9cdabfaecc2877b55a\",\"name\":\"Zaki Mohammed J.\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/171\",\"headline\":\"Interpretability analysis shows that the model can better mimic the human reasoning process for conversational machine comprehension compared to existing models\",\"id\":\"5d4409be3a55acdd76472372\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0503d4631523323816c3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":147,\"pdf\":\"https://static.aminer.cn/upload/pdf/1882/1022/313/5d4409be3a55acdd76472372_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5d4409be3a55acdd76472372_0.pdf_gqj9971u_images_5n_wq61y/img-001.png\",\"title\":\"GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for\\n  Conversational Machine Comprehension\",\"year\":2019},{\"aids\":[\"542cbe96dabfae478c1973be\",\"5609a30d45ce1e595f86e81d\",\"562f1e3f45cedb339953a644\",\"5440634edabfae805a6b798d\",\"53f43b60dabfaec09f1adf5c\"],\"authors\":[{\"id\":\"542cbe96dabfae478c1973be\",\"name\":\"Xuan Lin\"},{\"id\":\"5609a30d45ce1e595f86e81d\",\"name\":\"Zhe Quan\"},{\"id\":\"562f1e3f45cedb339953a644\",\"name\":\"Zhi-Jie Wang\"},{\"id\":\"5440634edabfae805a6b798d\",\"name\":\"Tengfei Ma\"},{\"id\":\"53f43b60dabfaec09f1adf5c\",\"name\":\"Xiangxiang Zeng\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/380\",\"headline\":\"To address the above limitations, we propose an end-to-end framework, called Knowledge Graph Neural Network, to resolve the DDI prediction\",\"id\":\"5ef96b048806af6ef2772133\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0508d463152332381751\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":147,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0380.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0380.pdf_0rg7yu1__images_ob6beeah/img-001.png\",\"resources\":{},\"title\":\"KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction\",\"year\":2020},{\"abstract\":\"  Accurate local-level poverty measurement is an essential task for governments and humanitarian organizations to track the progress towards improving livelihoods and distribute scarce resources. Recent computer vision advances in using satellite imagery to predict poverty have shown increasing accuracy, but they do not generate features that are interpretable to policymakers, inhibiting adoption by practitioners. Here we demonstrate an interpretable computational framework to accurately predict poverty at a local level by applying object detectors to high resolution (30cm) satellite images. Using the weighted counts of objects as features, we achieve 0.539 Pearson\\'s r^2 in predicting village-level poverty in Uganda, a 31% improvement over existing (and less interpretable) benchmarks. Feature importance and ablation analysis reveal intuitive relationships between object counts and poverty predictions. Our results suggest that interpretability does not have to come at the cost of performance, at least in this important domain. \",\"aids\":[\"5611f0ad45ce1e5962a380f8\",\"53f433bfdabfaeee229903db\",\"53f45f1edabfaee1c0b4d38c\",\"5487fce8dabfae8a11fb3fcf\",\"53f4c9ecdabfaee57f78001f\"],\"authors\":[{\"id\":\"5611f0ad45ce1e5962a380f8\",\"name\":\"Ayush Kumar\"},{\"id\":\"53f433bfdabfaeee229903db\",\"name\":\"Uzkent Burak\"},{\"id\":\"53f45f1edabfaee1c0b4d38c\",\"name\":\"Burke Marshall\"},{\"id\":\"5487fce8dabfae8a11fb3fcf\",\"name\":\"Lobell David\"},{\"id\":\"53f4c9ecdabfaee57f78001f\",\"name\":\"Ermon Stefano\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/608\",\"headline\":\"Our results offer a promising approach for generating interpretable poverty predictions for important livelihood outcomes, even in settings with limited training data\",\"id\":\"5e3be3c33a55ac29c4ae7d26\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0507d463152332381737\",\"num_citation\":8,\"num_like\":0,\"num_viewed\":146,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2002/2002.01612.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2002.01612.pdf_psv7o7yk_images_n1par0u1/img-001.png\",\"title\":\"Generating Interpretable Poverty Maps using Object Detection in\\n  Satellite Images\",\"year\":2020},{\"aids\":[\"562fc2fe45cedb33997ccd12\",\"53f431f4dabfaeb2ac023f3d\",\"56066dff45cedb339687dcf2\",\"53f42fdadabfaee4dc738419\"],\"authors\":[{\"id\":\"562fc2fe45cedb33997ccd12\",\"name\":\"Yongrui Chen\"},{\"id\":\"53f431f4dabfaeb2ac023f3d\",\"name\":\"Huiying Li\"},{\"id\":\"56066dff45cedb339687dcf2\",\"name\":\"Yuncheng Hua\"},{\"id\":\"53f42fdadabfaee4dc738419\",\"name\":\"Guilin Qi\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/519\",\"headline\":\"The experimental results showed that our approach achieved superior results than the existing methods on complex questions, and produced competitive results on other simple question based datasets\",\"id\":\"5ef96b048806af6ef27721d3\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050dd4631523323817df\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0519.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0519.pdf_5fjcozbu_images_v9e06ofm/img-001.png\",\"title\":\"Formal Query Building with Query Structure Prediction for Complex Question Answering over Knowledge Base\",\"year\":2020},{\"abstract\":\"  In this paper, we study the two-facility location game on a line with optional preference where the acceptable set of facilities for each agent could be different and an agent\\'s cost is his distance to the closest facility within his acceptable set. The objective is to minimize the total cost of all agents while achieving strategyproofness. We design a deterministic strategyproof mechanism for the problem with approximation ratio of 2.75, improving upon the earlier best ratio of n/2+1. \",\"aids\":[\"5484aa67dabfaed7b5fa1aff\",\"54879930dabfaed7b5fa31c0\"],\"authors\":[{\"id\":\"5484aa67dabfaed7b5fa1aff\",\"name\":\"Li Minming\"},{\"id\":\"54879930dabfaed7b5fa31c0\",\"name\":\"Lu Pinyan\"},{\"name\":\"Yao Yuhao\"},{\"name\":\"Zhang Jialin\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/34\",\"headline\":\"It is an interesting open question to design a strategyproof mechanism with constant approximation ratio for the facility location game with three or more facilities\",\"id\":\"5d36dcc13a55ac954df90e5a\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d4631523323816f5\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/19/1907/1907.08918.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/1907.08918.pdf_t8hpy5_o_images_ng8r0fw0/img-001.png\",\"title\":\"Strategyproof Mechanism for Two Heterogeneous Facilities with Constant\\n  Approximation Ratio\",\"year\":2019},{\"aids\":[\"53f3b0abdabfae4b34b1a285\",\"5432061edabfae8cc1c0a456\",\"5603bce945cedb339622c268\",\"543074cedabfaed7c7c59851\",\"5606e4b545cedb3396987add\",\"562da30845cedb3398e94041\",\"53f47977dabfae8a6845b643\"],\"authors\":[{\"id\":\"53f3b0abdabfae4b34b1a285\",\"name\":\"Dongxiao He\"},{\"id\":\"5432061edabfae8cc1c0a456\",\"name\":\"Lu Zhai\"},{\"id\":\"5603bce945cedb339622c268\",\"name\":\"Zhigang Li\"},{\"id\":\"543074cedabfaed7c7c59851\",\"name\":\"Di Jin\"},{\"id\":\"5606e4b545cedb3396987add\",\"name\":\"Liang Yang\"},{\"id\":\"562da30845cedb3398e94041\",\"name\":\"Yuxiao Huang\"},{\"id\":\"53f47977dabfae8a6845b643\",\"name\":\"Philip S. Yu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/459\",\"headline\":\"We propose to use the adversarial idea on the representation mechanism, i.e. on the encoding mechanism under the framework of autoencoder\",\"id\":\"5ef96b048806af6ef2772198\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d46315233238167c\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0459.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0459.pdf_f4dq6f80_images_rd9117i2/img-001.png\",\"title\":\"Adversarial Mutual Information Learning for Network Embedding\",\"year\":2020},{\"abstract\":\"  The optimization of expensive to evaluate, black-box, mixed-variable functions, i.e. functions that have continuous and discrete inputs, is a difficult and yet pervasive problem in science and engineering. In Bayesian optimization (BO), special cases of this problem that consider fully continuous or fully discrete domains have been widely studied. However, few methods exist for mixed-variable domains. In this paper, we introduce MiVaBo, a novel BO algorithm for the efficient optimization of mixed-variable functions that combines a linear surrogate model based on expressive feature representations with Thompson sampling. We propose two methods to optimize its acquisition function, a challenging problem for mixed-variable domains, and we show that MiVaBo can handle complex constraints over the discrete part of the domain that other methods cannot take into account. Moreover, we provide the first convergence analysis of a mixed-variable BO algorithm. Finally, we show that MiVaBo is significantly more sample efficient than state-of-the-art mixed-variable BO algorithms on hyperparameter tuning tasks. \",\"aids\":[\"53f7b16cdabfae9467dac519\",\"5624e3c045ce1e5964b0ea24\",\"53f433d5dabfaedce551583c\",\"53f48b19dabfaea6f277b55f\"],\"authors\":[{\"id\":\"53f7b16cdabfae9467dac519\",\"name\":\"Daxberger Erik\"},{\"id\":\"5624e3c045ce1e5964b0ea24\",\"name\":\"Makarova Anastasia\"},{\"id\":\"53f433d5dabfaedce551583c\",\"name\":\"Turchetta Matteo\"},{\"id\":\"53f48b19dabfaea6f277b55f\",\"name\":\"Krause Andreas\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/365\",\"headline\":\"We propose MIVABO, a simple yet effective method for efficient optimization of expensive-toevaluate mixed-variable black-box objective functions, combining a linear model of expressive features with Thompson sampling\",\"id\":\"5d1c7ccb3a55ac8c230aa9b9\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ad463152332381784\",\"num_citation\":4,\"num_like\":0,\"num_viewed\":140,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/19/1907/1907.01329.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/1907.01329.pdf_pu7pz923_images_n3mkqffc/img-001.png\",\"title\":\"Mixed-Variable Bayesian Optimization\",\"year\":2019},{\"aids\":[\"542a8ae3dabfae2b4e1153cf\",\"53f3a52adabfae4b34ad40c8\",\"562ab5af45cedb33989474ac\",\"562d2e3a45cedb3398d7d59c\",\"560d12c945cedb33975a2887\",\"56078c2e45cedb3396af3338\",\"562506cd45cedb3398570152\"],\"authors\":[{\"id\":\"542a8ae3dabfae2b4e1153cf\",\"name\":\"Run Wang\"},{\"id\":\"53f3a52adabfae4b34ad40c8\",\"name\":\"Felix Juefei-Xu\"},{\"id\":\"562ab5af45cedb33989474ac\",\"name\":\"Lei Ma\"},{\"id\":\"562d2e3a45cedb3398d7d59c\",\"name\":\"Xiaofei Xie\"},{\"id\":\"560d12c945cedb33975a2887\",\"name\":\"Yihao Huang\"},{\"id\":\"56078c2e45cedb3396af3338\",\"name\":\"Jian Wang\"},{\"id\":\"562506cd45cedb3398570152\",\"name\":\"Yang Liu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/476\",\"headline\":\"We find that FakeSpotter achieves a better balance between precision and recall on four types of fake faces from Figure 3\",\"id\":\"5ef96b048806af6ef27721af\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0506d463152332381719\",\"num_citation\":3,\"num_like\":0,\"num_viewed\":135,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0476.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0476.pdf_v0gitdok_images_zi7rv_d5/img-001.png\",\"title\":\"FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized Fake Faces\",\"year\":2020},{\"abstract\":\"  Bipartite b-matching is fundamental in algorithm design, and has been widely applied into economic markets, labor markets, etc. These practical problems usually exhibit two distinct features: large-scale and dynamic, which requires the matching algorithm to be repeatedly executed at regular intervals. However, existing exact and approximate algorithms usually fail in such settings due to either requiring intolerable running time or too much computation resource. To address this issue, we propose \\\\texttt{NeuSearcher} which leverages the knowledge learned from previously instances to solve new problem instances. Specifically, we design a multichannel graph neural network to predict the threshold of the matched edges weights, by which the search region could be significantly reduced. We further propose a parallel heuristic search algorithm to iteratively improve the solution quality until convergence. Experiments on both open and industrial datasets demonstrate that \\\\texttt{NeuSearcher} can speed up 2 to 3 times while achieving exactly the same matching solution compared with the state-of-the-art approximation approaches. \",\"aids\":[\"53f44ff9dabfaee4dc7f7cfd\",\"53f43454dabfaedce551b305\",\"560fe71345ce1e5961f0fe0f\",\"53f43d81dabfaee1c0ad528b\",\"542bc160dabfae1bbfd1780e\",\"5d43d51f7390bff0db5ff255\",\"53f43449dabfaeecd694b202\"],\"authors\":[{\"id\":\"53f44ff9dabfaee4dc7f7cfd\",\"name\":\"Hao Xiaotian\"},{\"name\":\"Jin Junqi\"},{\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Hao Jianye\"},{\"name\":\"Li Jin\"},{\"id\":\"560fe71345ce1e5961f0fe0f\",\"name\":\"Wang Weixun\"},{\"name\":\"Ma Yi\"},{\"id\":\"53f43d81dabfaee1c0ad528b\",\"name\":\"Zheng Zhenzhe\"},{\"id\":\"542bc160dabfae1bbfd1780e\",\"name\":\"Li Han\"},{\"id\":\"5d43d51f7390bff0db5ff255\",\"name\":\"Xu Jian\"},{\"id\":\"53f43449dabfaeecd694b202\",\"name\":\"Gai Kun\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/475\",\"headline\":\"Our NeuSearcher transfers knowledge learned from previous solved instances to save more than 50% of the computing time\",\"id\":\"5eba73be91e01108d77cf63e\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381680\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":132,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.04355.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.04355.pdf_jjsj22rk_images_fokpiz5n/img-001.png\",\"title\":\"Learning to Accelerate Heuristic Searching for Large-Scale Maximum\\n  Weighted b-Matching Problems in Online Advertising\",\"year\":2020},{\"aids\":[\"5621f6d445cedb339837892a\",\"5408f140dabfae8faa666053\",\"5d43d53b7390bff0db600282\"],\"authors\":[{\"id\":\"5621f6d445cedb339837892a\",\"name\":\"Ziwei Wang\"},{\"id\":\"5408f140dabfae8faa666053\",\"name\":\"Zi Huang\"},{\"id\":\"5d43d53b7390bff0db600282\",\"name\":\"Yadan Luo\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/92\",\"headline\":\"We propose a human consensus-oriented model for image captioning\",\"id\":\"5ef96b048806af6ef2772038\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0511d463152332381840\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":131,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0092.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0092.pdf_5f4l0eh3_images_12wgs2uw/img-001.png\",\"title\":\"Human Consensus-Oriented Image Captioning\",\"year\":2020},{\"abstract\":\"  Inferring topological characteristics of complex networks from observed data is critical to understand the dynamical behavior of networked systems, ranging from the Internet and the World Wide Web to biological networks and social networks. Prior studies usually focus on the structure-based estimation to infer network sizes, degree distributions, average degrees, and more. Little effort attempted to estimate the specific degree of each vertex from a sampled induced graph, which prevents us from measuring the lethality of nodes in protein networks and influencers in social networks. The current approaches dramatically fail for a tiny sampled induced graph and require a specific sampling method and a large sample size. These approaches neglect information of the vertex state, representing the dynamical behavior of the networked system, such as the biomass of species or expression of a gene, which is useful for degree estimation. We fill this gap by developing a framework to infer individual vertex degrees using both information of the sampled topology and vertex state. We combine the mean-field theory with combinatorial optimization to learn vertex degrees. Experimental results on real networks with a variety of dynamics demonstrate that our framework can produce reliable degree estimates and dramatically improve existing link prediction methods by replacing the sampled degrees with our estimated degrees. \",\"aids\":[\"53f46917dabfaeecd6a17760\",\"53f47d63dabfaee4dc8a59e2\",\"53f39be6dabfae4b34a99107\"],\"authors\":[{\"id\":\"53f46917dabfaeecd6a17760\",\"name\":\"Jiang Chunheng\"},{\"id\":\"53f47d63dabfaee4dc8a59e2\",\"name\":\"Gao Jianxi\"},{\"id\":\"53f39be6dabfae4b34a99107\",\"name\":\"Magdon-Ismail Malik\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/457\",\"headline\":\"We show that our approaches can tolerate high level of noise added to the observed steadystates, as well as model misspecification in the form of noise added to the parameters in the dynamical system\",\"id\":\"5ea16b3491e011fa08b8fb55\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d4631523323816f7\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":130,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.10546.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2004.10546.pdf_pus3hpx__images_r9rfd34h/img-001.png\",\"title\":\"Inferring Degrees from Incomplete Networks and Nonlinear Dynamics\",\"year\":2020},{\"aids\":[\"5d50c3797390bff0db2a5114\",\"542be28cdabfae216e61cab1\",\"53f38139dabfae4b349f8a2b\",\"53f58dc0dabfaed67df8067c\",\"53f46741dabfaee4dc851a50\",\"53f43267dabfaeb1a7bcb584\",\"562d27e145cedb3398d6c781\"],\"authors\":[{\"id\":\"5d50c3797390bff0db2a5114\",\"name\":\"Dor Atzmon\"},{\"id\":\"542be28cdabfae216e61cab1\",\"name\":\"Jiaoyang Li\"},{\"id\":\"53f38139dabfae4b349f8a2b\",\"name\":\"Ariel Felner\"},{\"id\":\"53f58dc0dabfaed67df8067c\",\"name\":\"Eliran Nachmani\"},{\"id\":\"53f46741dabfaee4dc851a50\",\"name\":\"Shahaf S. Shperberg\"},{\"id\":\"53f43267dabfaeb1a7bcb584\",\"name\":\"Nathan R. Sturtevant\"},{\"id\":\"562d27e145cedb3398d6c781\",\"name\":\"Sven Koenig\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/562\",\"headline\":\"We introduced the multi-directional search algorithm Meet in the Middle* that optimally solves Multi-Agent Meeting problem\",\"id\":\"5ef96b048806af6ef2772208\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d463152332381779\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":130,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0562.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0562.pdf_olm0ktwd_images_edq1rnau/img-001.png\",\"title\":\"Multi-Directional Heuristic Search\",\"year\":2020},{\"aids\":[\"542e1ce9dabfae11fc4c5dd0\",\"53f4399fdabfaee2a1d04811\",\"561d1c8b45cedb339803f3f2\",\"53f42b4adabfaeb22f3e6b4a\",\"560cd53c45cedb339757a831\",\"540543afdabfae91d3fcd837\",\"540683ccdabfae44f083b82c\"],\"authors\":[{\"id\":\"542e1ce9dabfae11fc4c5dd0\",\"name\":\"Changbin Shao\"},{\"id\":\"53f4399fdabfaee2a1d04811\",\"name\":\"Jing Huo\"},{\"id\":\"561d1c8b45cedb339803f3f2\",\"name\":\"Lei Qi\"},{\"id\":\"53f42b4adabfaeb22f3e6b4a\",\"name\":\"Zhen-Hua Feng\"},{\"id\":\"560cd53c45cedb339757a831\",\"name\":\"Wenbin Li\"},{\"id\":\"540543afdabfae91d3fcd837\",\"name\":\"Chuanqi Dong\"},{\"id\":\"540683ccdabfae44f083b82c\",\"name\":\"Yang Gao\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/93\",\"headline\":\"The experimental results demonstrated the merits of our Biased Feature Learning method as well as its generalization capability with different network architectures and loss functions\",\"id\":\"5ef96b048806af6ef2772017\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d463152332381702\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":127,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0093.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0093.pdf_xb8wik8h_images_hyj4wfzq/img-001.png\",\"title\":\"Biased Feature Learning for Occlusion Invariant Face Recognition\",\"year\":2020},{\"abstract\":\"  Unsupervised image captioning with no annotations is an emerging challenge in computer vision, where the existing arts usually adopt GAN (Generative Adversarial Networks) models. In this paper, we propose a novel memory-based network rather than GAN, named Recurrent Relational Memory Network ($R^2M$). Unlike complicated and sensitive adversarial learning that non-ideally performs for long sentence generation, $R^2M$ implements a concepts-to-sentence memory translator through two-stage memory mechanisms: fusion and recurrent memories, correlating the relational reasoning between common visual concepts and the generated words for long periods. $R^2M$ encodes visual context through unsupervised training on images, while enabling the memory to learn from irrelevant textual corpus via supervised fashion. Our solution enjoys less learnable parameters and higher computational efficiency than GAN-based methods, which heavily bear parameter sensitivity. We experimentally validate the superiority of $R^2M$ than state-of-the-arts on all benchmark datasets. \",\"aids\":[\"542c00fbdabfae2b4e1cbbb2\",\"560dadd545cedb3397609cf0\",\"56cb1891c35f4f3c6565176f\"],\"authors\":[{\"id\":\"542c00fbdabfae2b4e1cbbb2\",\"name\":\"Dan Guo\"},{\"id\":\"560dadd545cedb3397609cf0\",\"name\":\"Yang Wang\"},{\"name\":\"Peipei Song\"},{\"id\":\"56cb1891c35f4f3c6565176f\",\"name\":\"Meng Wang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/128\",\"headline\":\"This paper proposes a novel recurrent relational memory network for unsupervised image captioning with low cost of supervision\",\"id\":\"5ef476b691e01165a63bbbdc\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381695\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/upload/pdf/884/764/28/5ef476b691e01165a63bbbdc_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5ef476b691e01165a63bbbdc_0.pdf_4du9k826_images_u4qf5m3m/img-001.png\",\"title\":\"Recurrent Relational Memory Network for Unsupervised Image Captioning\",\"year\":2020},{\"abstract\":\"  A major challenge in inductive logic programming (ILP) is learning large programs. We argue that a key limitation of existing systems is that they use entailment to guide the hypothesis search. This approach is limited because entailment is a binary decision: a hypothesis either entails an example or does not, and there is no intermediate position. To address this limitation, we go beyond entailment and use \\\\emph{example-dependent} loss functions to guide the search, where a hypothesis can partially cover an example. We implement our idea in Brute, a new ILP system which uses best-first search, guided by an example-dependent loss function, to incrementally build programs. Our experiments on three diverse program synthesis domains (robot planning, string transformations, and ASCII art), show that Brute can substantially outperform existing ILP systems, both in terms of predictive accuracies and learning times, and can learn programs 20 times larger than state-of-the-art systems. \",\"aids\":[\"5d50c38b7390bff0db2a607a\",\"5d50c38f7390bff0db2a63f9\"],\"authors\":[{\"id\":\"5d50c38b7390bff0db2a607a\",\"name\":\"Cropper Andrew\"},{\"id\":\"5d50c38f7390bff0db2a63f9\",\"name\":\"Dumančić Sebastijan\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/287\",\"headline\":\"We implemented our idea in Brute, a new inductive logic programming which first invents a library of predicates, including recursive predicates, and performs a best-first search informed by a given loss function to build a hypothesis using the library predicates\",\"id\":\"5ea16b2b91e011fa08b8f8a2\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381804\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.09855.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2004.09855.pdf_tz3eo8xy_images_my_y_4ri/img-001.png\",\"title\":\"Learning large logic programs by going beyond entailment\",\"year\":2020},{\"aids\":[\"542ead9adabfae4a9e494982\",\"53f447cbdabfaedf435d1f03\",\"53f466c9dabfaeb22f53efd7\",\"53f45084dabfaeecd69d4b63\",\"53f4926bdabfaedd74eb491b\"],\"authors\":[{\"id\":\"542ead9adabfae4a9e494982\",\"name\":\"Saba Ahmadi\"},{\"id\":\"53f447cbdabfaedf435d1f03\",\"name\":\"Faez Ahmed\"},{\"id\":\"53f466c9dabfaeb22f53efd7\",\"name\":\"John P. Dickerson\"},{\"id\":\"53f45084dabfaeecd69d4b63\",\"name\":\"Mark Fuge\"},{\"id\":\"53f4926bdabfaedd74eb491b\",\"name\":\"Samir Khuller\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/1\",\"headline\":\"We propose an algorithm that guarantees an optimal solution and converges faster than a proposed approach using a black-box industrial Mixed-Integer Quadratic Program solver\",\"id\":\"5ef96b048806af6ef2771fd5\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d46315233238176e\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0001.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0001.pdf_kin01g3p_images_ydd11zeb/img-001.png\",\"title\":\"An Algorithm for Multi-Attribute Diverse Matching\",\"year\":2020},{\"aids\":[\"56311fc245cedb3399cb3327\",\"53f3588fdabfae4b34965da0\"],\"authors\":[{\"id\":\"56311fc245cedb3399cb3327\",\"name\":\"Siyu Lin\"},{\"id\":\"53f3588fdabfae4b34965da0\",\"name\":\"Peter A. Beling\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/627\",\"headline\":\"We propose an end-to-end optimal trade execution framework based on PPO\",\"id\":\"5ef96b048806af6ef2772245\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0517d4631523323818e3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":123,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0627.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0627.pdf_72fuenkj_images_uqbq8fui/img-001.png\",\"title\":\"An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization\",\"year\":2020},{\"abstract\":\"  Existing convergence analyses of Q-learning mostly focus on the vanilla stochastic gradient descent (SGD) type of updates. Despite the Adaptive Moment Estimation (Adam) has been commonly used for practical Q-learning algorithms, there has not been any convergence guarantee provided for Q-learning with such type of updates. In this paper, we first characterize the convergence rate for Q-AMSGrad, which is the Q-learning algorithm with AMSGrad update (a commonly adopted alternative of Adam for theoretical analysis). To further improve the performance, we propose to incorporate the momentum restart scheme to Q-AMSGrad, resulting in the so-called Q-AMSGradR algorithm. The convergence rate of Q-AMSGradR is also established. Our experiments on a linear quadratic regulator problem show that the two proposed Q-learning algorithms outperform the vanilla Q-learning with SGD updates. The two algorithms also exhibit significantly better performance than the DQN learning method over a batch of Atari 2600 games. \",\"aids\":[\"5617a08e45ce1e5963e405e7\",\"5618326645ce1e5963f93d64\",\"5405a7ecdabfae450f3c22a6\",\"53f4b8f6dabfaed83b77b422\"],\"authors\":[{\"id\":\"5617a08e45ce1e5963e405e7\",\"name\":\"Bowen Weng\"},{\"id\":\"5618326645ce1e5963f93d64\",\"name\":\"Huaqing Xiong\"},{\"id\":\"5405a7ecdabfae450f3c22a6\",\"name\":\"Yingbin Liang\"},{\"id\":\"53f4b8f6dabfaed83b77b422\",\"name\":\"Wei Zhang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/422\",\"headline\":\"We study two Q-learning algorithms with Adaptive Moment Estimation-type updates, and demonstrate their superior performance over the vanilla Q-learning and deep Q-Network algorithms through a linear quadratic regulator problem and a batch of 23 Atari 2600 games\",\"id\":\"5ef96b048806af6ef27720e4\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381805\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":123,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0422.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0422.pdf_ikn8agkw_images_86w4v40v/img-001.png\",\"title\":\"Analysis of Q-learning with Adaptation and Momentum Restart for Gradient Descent\",\"year\":2020},{\"aids\":[\"53f35095dabfae4b34945bf1\",\"5611f65745ce1e5962a51665\",\"54875be8dabfae9b40134539\"],\"authors\":[{\"id\":\"53f35095dabfae4b34945bf1\",\"name\":\"Andreas Niskanen\"},{\"id\":\"5611f65745ce1e5962a51665\",\"name\":\"Daniel Neugebauer\"},{\"id\":\"54875be8dabfae9b40134539\",\"name\":\"Matti JÃ¤rvisalo\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/257\",\"headline\":\"We provided complexity results for credulous and skeptical controllability in control argumentation frameworks under five central semantics\",\"id\":\"5ef96b048806af6ef27720b8\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381810\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":121,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0257.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0257.pdf_5chbcjeh_images_uc88qivs/img-001.png\",\"title\":\"Controllability of Control Argumentation Frameworks\",\"year\":2020}],\"meta\":{\"context\":\"3596084E\",\"time\":\"811.139271ms\"},\"succeed\":\"true\",\"total\":645}]}'\n",
    "page3 = page3.replace('\\\\n', '').replace(':false', ':\"false\"').replace(':true', ':\"true\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Invalid control character at: line 1 column 3357 (char 3356)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-b31831800b09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Invalid control character at: line 1 column 3357 (char 3356)"
     ]
    }
   ],
   "source": [
    "json.loads(page3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page3 = {\"data\":[{\"items\":[{\"aids\":[\"542a2809dabfae5848aa17b8\",\"53f42df3dabfaedd74d3e053\",\"59489cb29ed5db31dcdd0565\",\"562d526545cedb3398dc474d\",\"562e261a45cedb33990beecb\",\"53f4d81cdabfaef64977b5bf\",\"53f66220dabfae6a71b63777\"],\"authors\":[{\"id\":\"542a2809dabfae5848aa17b8\",\"name\":\"Yunbo Wang\"},{\"id\":\"53f42df3dabfaedd74d3e053\",\"name\":\"Bo Liu\"},{\"id\":\"59489cb29ed5db31dcdd0565\",\"name\":\"Jiajun Wu\"},{\"id\":\"562d526545cedb3398dc474d\",\"name\":\"Yuke Zhu\"},{\"id\":\"562e261a45cedb33990beecb\",\"name\":\"Simon S Du\"},{\"id\":\"53f4d81cdabfaef64977b5bf\",\"name\":\"Li Fei-Fei\"},{\"id\":\"53f66220dabfae6a71b63777\",\"name\":\"Joshua B Tenenbaum\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/579\",\"headline\":\"We provided an end-to-end neural network named Dual Sequential Monte Carlo to solve continuous Partially Observable Markov Decision Processes, which has three advantages\",\"id\":\"5ee07fdc9e795e01364da3ca\",\"is_like\":\"false\",\"lang\":\"en\",\"mrt_link\":\"5f4e050dd4631523323817f3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":150,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0579.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0579.pdf_2k5gsklz_images_4g7wyxp6/img-001.png\",\"title\":\"DualSMC: Tunneling Differentiable Filtering and Planning under Continuous POMDPs\",\"year\":2019},{\"abstract\":\"  Conversational machine reading comprehension (MRC) has proven significantly more challenging compared to traditional MRC since it requires better utilization of conversation history. However, most existing approaches do not effectively capture conversation history and thus have trouble handling questions involving coreference or ellipsis. We propose a novel graph neural network (GNN) based model, namely GraphFlow, which captures conversational flow in the dialog. Specifically, we first propose a new approach to dynamically construct a question-aware context graph from passage text at each turn. We then present a novel flow mechanism to model the temporal dependencies in the sequence of context graphs. The proposed GraphFlow model shows superior performance compared to existing state-of-the-art methods. For instance, GraphFlow outperforms two recently proposed models on the CoQA benchmark dataset: FlowQA by 2.3% and SDNet by 0.7% on F1 score, respectively. In addition, visualization experiments show that our proposed model can better mimic the human reasoning process for conversational MRC compared to existing models. \",\"aids\":[\"53f4339fdabfaedce5512fc6\",\"562d97d045cedb3398e741ce\",\"53f4ab9cdabfaecc2877b55a\"],\"authors\":[{\"id\":\"53f4339fdabfaedce5512fc6\",\"name\":\"Chen Yu\"},{\"id\":\"562d97d045cedb3398e741ce\",\"name\":\"Wu Lingfei\"},{\"id\":\"53f4ab9cdabfaecc2877b55a\",\"name\":\"Zaki Mohammed J.\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/171\",\"headline\":\"Interpretability analysis shows that the model can better mimic the human reasoning process for conversational machine comprehension compared to existing models\",\"id\":\"5d4409be3a55acdd76472372\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0503d4631523323816c3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":147,\"pdf\":\"https://static.aminer.cn/upload/pdf/1882/1022/313/5d4409be3a55acdd76472372_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5d4409be3a55acdd76472372_0.pdf_gqj9971u_images_5n_wq61y/img-001.png\",\"title\":\"GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for\\n  Conversational Machine Comprehension\",\"year\":2019},{\"aids\":[\"542cbe96dabfae478c1973be\",\"5609a30d45ce1e595f86e81d\",\"562f1e3f45cedb339953a644\",\"5440634edabfae805a6b798d\",\"53f43b60dabfaec09f1adf5c\"],\"authors\":[{\"id\":\"542cbe96dabfae478c1973be\",\"name\":\"Xuan Lin\"},{\"id\":\"5609a30d45ce1e595f86e81d\",\"name\":\"Zhe Quan\"},{\"id\":\"562f1e3f45cedb339953a644\",\"name\":\"Zhi-Jie Wang\"},{\"id\":\"5440634edabfae805a6b798d\",\"name\":\"Tengfei Ma\"},{\"id\":\"53f43b60dabfaec09f1adf5c\",\"name\":\"Xiangxiang Zeng\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/380\",\"headline\":\"To address the above limitations, we propose an end-to-end framework, called Knowledge Graph Neural Network, to resolve the DDI prediction\",\"id\":\"5ef96b048806af6ef2772133\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0508d463152332381751\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":147,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0380.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0380.pdf_0rg7yu1__images_ob6beeah/img-001.png\",\"resources\":{},\"title\":\"KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction\",\"year\":2020},{\"abstract\":\"  Accurate local-level poverty measurement is an essential task for governments and humanitarian organizations to track the progress towards improving livelihoods and distribute scarce resources. Recent computer vision advances in using satellite imagery to predict poverty have shown increasing accuracy, but they do not generate features that are interpretable to policymakers, inhibiting adoption by practitioners. Here we demonstrate an interpretable computational framework to accurately predict poverty at a local level by applying object detectors to high resolution (30cm) satellite images. Using the weighted counts of objects as features, we achieve 0.539 Pearson\\'s r^2 in predicting village-level poverty in Uganda, a 31% improvement over existing (and less interpretable) benchmarks. Feature importance and ablation analysis reveal intuitive relationships between object counts and poverty predictions. Our results suggest that interpretability does not have to come at the cost of performance, at least in this important domain. \",\"aids\":[\"5611f0ad45ce1e5962a380f8\",\"53f433bfdabfaeee229903db\",\"53f45f1edabfaee1c0b4d38c\",\"5487fce8dabfae8a11fb3fcf\",\"53f4c9ecdabfaee57f78001f\"],\"authors\":[{\"id\":\"5611f0ad45ce1e5962a380f8\",\"name\":\"Ayush Kumar\"},{\"id\":\"53f433bfdabfaeee229903db\",\"name\":\"Uzkent Burak\"},{\"id\":\"53f45f1edabfaee1c0b4d38c\",\"name\":\"Burke Marshall\"},{\"id\":\"5487fce8dabfae8a11fb3fcf\",\"name\":\"Lobell David\"},{\"id\":\"53f4c9ecdabfaee57f78001f\",\"name\":\"Ermon Stefano\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/608\",\"headline\":\"Our results offer a promising approach for generating interpretable poverty predictions for important livelihood outcomes, even in settings with limited training data\",\"id\":\"5e3be3c33a55ac29c4ae7d26\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0507d463152332381737\",\"num_citation\":8,\"num_like\":0,\"num_viewed\":146,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2002/2002.01612.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2002.01612.pdf_psv7o7yk_images_n1par0u1/img-001.png\",\"title\":\"Generating Interpretable Poverty Maps using Object Detection in\\n  Satellite Images\",\"year\":2020},{\"aids\":[\"562fc2fe45cedb33997ccd12\",\"53f431f4dabfaeb2ac023f3d\",\"56066dff45cedb339687dcf2\",\"53f42fdadabfaee4dc738419\"],\"authors\":[{\"id\":\"562fc2fe45cedb33997ccd12\",\"name\":\"Yongrui Chen\"},{\"id\":\"53f431f4dabfaeb2ac023f3d\",\"name\":\"Huiying Li\"},{\"id\":\"56066dff45cedb339687dcf2\",\"name\":\"Yuncheng Hua\"},{\"id\":\"53f42fdadabfaee4dc738419\",\"name\":\"Guilin Qi\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/519\",\"headline\":\"The experimental results showed that our approach achieved superior results than the existing methods on complex questions, and produced competitive results on other simple question based datasets\",\"id\":\"5ef96b048806af6ef27721d3\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050dd4631523323817df\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0519.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0519.pdf_5fjcozbu_images_v9e06ofm/img-001.png\",\"title\":\"Formal Query Building with Query Structure Prediction for Complex Question Answering over Knowledge Base\",\"year\":2020},{\"abstract\":\"  In this paper, we study the two-facility location game on a line with optional preference where the acceptable set of facilities for each agent could be different and an agent\\'s cost is his distance to the closest facility within his acceptable set. The objective is to minimize the total cost of all agents while achieving strategyproofness. We design a deterministic strategyproof mechanism for the problem with approximation ratio of 2.75, improving upon the earlier best ratio of n/2+1. \",\"aids\":[\"5484aa67dabfaed7b5fa1aff\",\"54879930dabfaed7b5fa31c0\"],\"authors\":[{\"id\":\"5484aa67dabfaed7b5fa1aff\",\"name\":\"Li Minming\"},{\"id\":\"54879930dabfaed7b5fa31c0\",\"name\":\"Lu Pinyan\"},{\"name\":\"Yao Yuhao\"},{\"name\":\"Zhang Jialin\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/34\",\"headline\":\"It is an interesting open question to design a strategyproof mechanism with constant approximation ratio for the facility location game with three or more facilities\",\"id\":\"5d36dcc13a55ac954df90e5a\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d4631523323816f5\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/19/1907/1907.08918.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/1907.08918.pdf_t8hpy5_o_images_ng8r0fw0/img-001.png\",\"title\":\"Strategyproof Mechanism for Two Heterogeneous Facilities with Constant\\n  Approximation Ratio\",\"year\":2019},{\"aids\":[\"53f3b0abdabfae4b34b1a285\",\"5432061edabfae8cc1c0a456\",\"5603bce945cedb339622c268\",\"543074cedabfaed7c7c59851\",\"5606e4b545cedb3396987add\",\"562da30845cedb3398e94041\",\"53f47977dabfae8a6845b643\"],\"authors\":[{\"id\":\"53f3b0abdabfae4b34b1a285\",\"name\":\"Dongxiao He\"},{\"id\":\"5432061edabfae8cc1c0a456\",\"name\":\"Lu Zhai\"},{\"id\":\"5603bce945cedb339622c268\",\"name\":\"Zhigang Li\"},{\"id\":\"543074cedabfaed7c7c59851\",\"name\":\"Di Jin\"},{\"id\":\"5606e4b545cedb3396987add\",\"name\":\"Liang Yang\"},{\"id\":\"562da30845cedb3398e94041\",\"name\":\"Yuxiao Huang\"},{\"id\":\"53f47977dabfae8a6845b643\",\"name\":\"Philip S. Yu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/459\",\"headline\":\"We propose to use the adversarial idea on the representation mechanism, i.e. on the encoding mechanism under the framework of autoencoder\",\"id\":\"5ef96b048806af6ef2772198\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d46315233238167c\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":141,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0459.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0459.pdf_f4dq6f80_images_rd9117i2/img-001.png\",\"title\":\"Adversarial Mutual Information Learning for Network Embedding\",\"year\":2020},{\"abstract\":\"  The optimization of expensive to evaluate, black-box, mixed-variable functions, i.e. functions that have continuous and discrete inputs, is a difficult and yet pervasive problem in science and engineering. In Bayesian optimization (BO), special cases of this problem that consider fully continuous or fully discrete domains have been widely studied. However, few methods exist for mixed-variable domains. In this paper, we introduce MiVaBo, a novel BO algorithm for the efficient optimization of mixed-variable functions that combines a linear surrogate model based on expressive feature representations with Thompson sampling. We propose two methods to optimize its acquisition function, a challenging problem for mixed-variable domains, and we show that MiVaBo can handle complex constraints over the discrete part of the domain that other methods cannot take into account. Moreover, we provide the first convergence analysis of a mixed-variable BO algorithm. Finally, we show that MiVaBo is significantly more sample efficient than state-of-the-art mixed-variable BO algorithms on hyperparameter tuning tasks. \",\"aids\":[\"53f7b16cdabfae9467dac519\",\"5624e3c045ce1e5964b0ea24\",\"53f433d5dabfaedce551583c\",\"53f48b19dabfaea6f277b55f\"],\"authors\":[{\"id\":\"53f7b16cdabfae9467dac519\",\"name\":\"Daxberger Erik\"},{\"id\":\"5624e3c045ce1e5964b0ea24\",\"name\":\"Makarova Anastasia\"},{\"id\":\"53f433d5dabfaedce551583c\",\"name\":\"Turchetta Matteo\"},{\"id\":\"53f48b19dabfaea6f277b55f\",\"name\":\"Krause Andreas\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/365\",\"headline\":\"We propose MIVABO, a simple yet effective method for efficient optimization of expensive-toevaluate mixed-variable black-box objective functions, combining a linear model of expressive features with Thompson sampling\",\"id\":\"5d1c7ccb3a55ac8c230aa9b9\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ad463152332381784\",\"num_citation\":4,\"num_like\":0,\"num_viewed\":140,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/19/1907/1907.01329.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/1907.01329.pdf_pu7pz923_images_n3mkqffc/img-001.png\",\"title\":\"Mixed-Variable Bayesian Optimization\",\"year\":2019},{\"aids\":[\"542a8ae3dabfae2b4e1153cf\",\"53f3a52adabfae4b34ad40c8\",\"562ab5af45cedb33989474ac\",\"562d2e3a45cedb3398d7d59c\",\"560d12c945cedb33975a2887\",\"56078c2e45cedb3396af3338\",\"562506cd45cedb3398570152\"],\"authors\":[{\"id\":\"542a8ae3dabfae2b4e1153cf\",\"name\":\"Run Wang\"},{\"id\":\"53f3a52adabfae4b34ad40c8\",\"name\":\"Felix Juefei-Xu\"},{\"id\":\"562ab5af45cedb33989474ac\",\"name\":\"Lei Ma\"},{\"id\":\"562d2e3a45cedb3398d7d59c\",\"name\":\"Xiaofei Xie\"},{\"id\":\"560d12c945cedb33975a2887\",\"name\":\"Yihao Huang\"},{\"id\":\"56078c2e45cedb3396af3338\",\"name\":\"Jian Wang\"},{\"id\":\"562506cd45cedb3398570152\",\"name\":\"Yang Liu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/476\",\"headline\":\"We find that FakeSpotter achieves a better balance between precision and recall on four types of fake faces from Figure 3\",\"id\":\"5ef96b048806af6ef27721af\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0506d463152332381719\",\"num_citation\":3,\"num_like\":0,\"num_viewed\":135,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0476.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0476.pdf_v0gitdok_images_zi7rv_d5/img-001.png\",\"title\":\"FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized Fake Faces\",\"year\":2020},{\"abstract\":\"  Bipartite b-matching is fundamental in algorithm design, and has been widely applied into economic markets, labor markets, etc. These practical problems usually exhibit two distinct features: large-scale and dynamic, which requires the matching algorithm to be repeatedly executed at regular intervals. However, existing exact and approximate algorithms usually fail in such settings due to either requiring intolerable running time or too much computation resource. To address this issue, we propose \\\\texttt{NeuSearcher} which leverages the knowledge learned from previously instances to solve new problem instances. Specifically, we design a multichannel graph neural network to predict the threshold of the matched edges weights, by which the search region could be significantly reduced. We further propose a parallel heuristic search algorithm to iteratively improve the solution quality until convergence. Experiments on both open and industrial datasets demonstrate that \\\\texttt{NeuSearcher} can speed up 2 to 3 times while achieving exactly the same matching solution compared with the state-of-the-art approximation approaches. \",\"aids\":[\"53f44ff9dabfaee4dc7f7cfd\",\"53f43454dabfaedce551b305\",\"560fe71345ce1e5961f0fe0f\",\"53f43d81dabfaee1c0ad528b\",\"542bc160dabfae1bbfd1780e\",\"5d43d51f7390bff0db5ff255\",\"53f43449dabfaeecd694b202\"],\"authors\":[{\"id\":\"53f44ff9dabfaee4dc7f7cfd\",\"name\":\"Hao Xiaotian\"},{\"name\":\"Jin Junqi\"},{\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Hao Jianye\"},{\"name\":\"Li Jin\"},{\"id\":\"560fe71345ce1e5961f0fe0f\",\"name\":\"Wang Weixun\"},{\"name\":\"Ma Yi\"},{\"id\":\"53f43d81dabfaee1c0ad528b\",\"name\":\"Zheng Zhenzhe\"},{\"id\":\"542bc160dabfae1bbfd1780e\",\"name\":\"Li Han\"},{\"id\":\"5d43d51f7390bff0db5ff255\",\"name\":\"Xu Jian\"},{\"id\":\"53f43449dabfaeecd694b202\",\"name\":\"Gai Kun\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/475\",\"headline\":\"Our NeuSearcher transfers knowledge learned from previous solved instances to save more than 50% of the computing time\",\"id\":\"5eba73be91e01108d77cf63e\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381680\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":132,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.04355.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.04355.pdf_jjsj22rk_images_fokpiz5n/img-001.png\",\"title\":\"Learning to Accelerate Heuristic Searching for Large-Scale Maximum\\n  Weighted b-Matching Problems in Online Advertising\",\"year\":2020},{\"aids\":[\"5621f6d445cedb339837892a\",\"5408f140dabfae8faa666053\",\"5d43d53b7390bff0db600282\"],\"authors\":[{\"id\":\"5621f6d445cedb339837892a\",\"name\":\"Ziwei Wang\"},{\"id\":\"5408f140dabfae8faa666053\",\"name\":\"Zi Huang\"},{\"id\":\"5d43d53b7390bff0db600282\",\"name\":\"Yadan Luo\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/92\",\"headline\":\"We propose a human consensus-oriented model for image captioning\",\"id\":\"5ef96b048806af6ef2772038\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0511d463152332381840\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":131,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0092.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0092.pdf_5f4l0eh3_images_12wgs2uw/img-001.png\",\"title\":\"Human Consensus-Oriented Image Captioning\",\"year\":2020},{\"abstract\":\"  Inferring topological characteristics of complex networks from observed data is critical to understand the dynamical behavior of networked systems, ranging from the Internet and the World Wide Web to biological networks and social networks. Prior studies usually focus on the structure-based estimation to infer network sizes, degree distributions, average degrees, and more. Little effort attempted to estimate the specific degree of each vertex from a sampled induced graph, which prevents us from measuring the lethality of nodes in protein networks and influencers in social networks. The current approaches dramatically fail for a tiny sampled induced graph and require a specific sampling method and a large sample size. These approaches neglect information of the vertex state, representing the dynamical behavior of the networked system, such as the biomass of species or expression of a gene, which is useful for degree estimation. We fill this gap by developing a framework to infer individual vertex degrees using both information of the sampled topology and vertex state. We combine the mean-field theory with combinatorial optimization to learn vertex degrees. Experimental results on real networks with a variety of dynamics demonstrate that our framework can produce reliable degree estimates and dramatically improve existing link prediction methods by replacing the sampled degrees with our estimated degrees. \",\"aids\":[\"53f46917dabfaeecd6a17760\",\"53f47d63dabfaee4dc8a59e2\",\"53f39be6dabfae4b34a99107\"],\"authors\":[{\"id\":\"53f46917dabfaeecd6a17760\",\"name\":\"Jiang Chunheng\"},{\"id\":\"53f47d63dabfaee4dc8a59e2\",\"name\":\"Gao Jianxi\"},{\"id\":\"53f39be6dabfae4b34a99107\",\"name\":\"Magdon-Ismail Malik\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/457\",\"headline\":\"We show that our approaches can tolerate high level of noise added to the observed steadystates, as well as model misspecification in the form of noise added to the parameters in the dynamical system\",\"id\":\"5ea16b3491e011fa08b8fb55\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d4631523323816f7\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":130,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.10546.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2004.10546.pdf_pus3hpx__images_r9rfd34h/img-001.png\",\"title\":\"Inferring Degrees from Incomplete Networks and Nonlinear Dynamics\",\"year\":2020},{\"aids\":[\"5d50c3797390bff0db2a5114\",\"542be28cdabfae216e61cab1\",\"53f38139dabfae4b349f8a2b\",\"53f58dc0dabfaed67df8067c\",\"53f46741dabfaee4dc851a50\",\"53f43267dabfaeb1a7bcb584\",\"562d27e145cedb3398d6c781\"],\"authors\":[{\"id\":\"5d50c3797390bff0db2a5114\",\"name\":\"Dor Atzmon\"},{\"id\":\"542be28cdabfae216e61cab1\",\"name\":\"Jiaoyang Li\"},{\"id\":\"53f38139dabfae4b349f8a2b\",\"name\":\"Ariel Felner\"},{\"id\":\"53f58dc0dabfaed67df8067c\",\"name\":\"Eliran Nachmani\"},{\"id\":\"53f46741dabfaee4dc851a50\",\"name\":\"Shahaf S. Shperberg\"},{\"id\":\"53f43267dabfaeb1a7bcb584\",\"name\":\"Nathan R. Sturtevant\"},{\"id\":\"562d27e145cedb3398d6c781\",\"name\":\"Sven Koenig\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/562\",\"headline\":\"We introduced the multi-directional search algorithm Meet in the Middle* that optimally solves Multi-Agent Meeting problem\",\"id\":\"5ef96b048806af6ef2772208\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d463152332381779\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":130,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0562.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0562.pdf_olm0ktwd_images_edq1rnau/img-001.png\",\"title\":\"Multi-Directional Heuristic Search\",\"year\":2020},{\"aids\":[\"542e1ce9dabfae11fc4c5dd0\",\"53f4399fdabfaee2a1d04811\",\"561d1c8b45cedb339803f3f2\",\"53f42b4adabfaeb22f3e6b4a\",\"560cd53c45cedb339757a831\",\"540543afdabfae91d3fcd837\",\"540683ccdabfae44f083b82c\"],\"authors\":[{\"id\":\"542e1ce9dabfae11fc4c5dd0\",\"name\":\"Changbin Shao\"},{\"id\":\"53f4399fdabfaee2a1d04811\",\"name\":\"Jing Huo\"},{\"id\":\"561d1c8b45cedb339803f3f2\",\"name\":\"Lei Qi\"},{\"id\":\"53f42b4adabfaeb22f3e6b4a\",\"name\":\"Zhen-Hua Feng\"},{\"id\":\"560cd53c45cedb339757a831\",\"name\":\"Wenbin Li\"},{\"id\":\"540543afdabfae91d3fcd837\",\"name\":\"Chuanqi Dong\"},{\"id\":\"540683ccdabfae44f083b82c\",\"name\":\"Yang Gao\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/93\",\"headline\":\"The experimental results demonstrated the merits of our Biased Feature Learning method as well as its generalization capability with different network architectures and loss functions\",\"id\":\"5ef96b048806af6ef2772017\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0505d463152332381702\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":127,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0093.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0093.pdf_xb8wik8h_images_hyj4wfzq/img-001.png\",\"title\":\"Biased Feature Learning for Occlusion Invariant Face Recognition\",\"year\":2020},{\"abstract\":\"  Unsupervised image captioning with no annotations is an emerging challenge in computer vision, where the existing arts usually adopt GAN (Generative Adversarial Networks) models. In this paper, we propose a novel memory-based network rather than GAN, named Recurrent Relational Memory Network ($R^2M$). Unlike complicated and sensitive adversarial learning that non-ideally performs for long sentence generation, $R^2M$ implements a concepts-to-sentence memory translator through two-stage memory mechanisms: fusion and recurrent memories, correlating the relational reasoning between common visual concepts and the generated words for long periods. $R^2M$ encodes visual context through unsupervised training on images, while enabling the memory to learn from irrelevant textual corpus via supervised fashion. Our solution enjoys less learnable parameters and higher computational efficiency than GAN-based methods, which heavily bear parameter sensitivity. We experimentally validate the superiority of $R^2M$ than state-of-the-arts on all benchmark datasets. \",\"aids\":[\"542c00fbdabfae2b4e1cbbb2\",\"560dadd545cedb3397609cf0\",\"56cb1891c35f4f3c6565176f\"],\"authors\":[{\"id\":\"542c00fbdabfae2b4e1cbbb2\",\"name\":\"Dan Guo\"},{\"id\":\"560dadd545cedb3397609cf0\",\"name\":\"Yang Wang\"},{\"name\":\"Peipei Song\"},{\"id\":\"56cb1891c35f4f3c6565176f\",\"name\":\"Meng Wang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/128\",\"headline\":\"This paper proposes a novel recurrent relational memory network for unsupervised image captioning with low cost of supervision\",\"id\":\"5ef476b691e01165a63bbbdc\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381695\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/upload/pdf/884/764/28/5ef476b691e01165a63bbbdc_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5ef476b691e01165a63bbbdc_0.pdf_4du9k826_images_u4qf5m3m/img-001.png\",\"title\":\"Recurrent Relational Memory Network for Unsupervised Image Captioning\",\"year\":2020},{\"abstract\":\"  A major challenge in inductive logic programming (ILP) is learning large programs. We argue that a key limitation of existing systems is that they use entailment to guide the hypothesis search. This approach is limited because entailment is a binary decision: a hypothesis either entails an example or does not, and there is no intermediate position. To address this limitation, we go beyond entailment and use \\\\emph{example-dependent} loss functions to guide the search, where a hypothesis can partially cover an example. We implement our idea in Brute, a new ILP system which uses best-first search, guided by an example-dependent loss function, to incrementally build programs. Our experiments on three diverse program synthesis domains (robot planning, string transformations, and ASCII art), show that Brute can substantially outperform existing ILP systems, both in terms of predictive accuracies and learning times, and can learn programs 20 times larger than state-of-the-art systems. \",\"aids\":[\"5d50c38b7390bff0db2a607a\",\"5d50c38f7390bff0db2a63f9\"],\"authors\":[{\"id\":\"5d50c38b7390bff0db2a607a\",\"name\":\"Cropper Andrew\"},{\"id\":\"5d50c38f7390bff0db2a63f9\",\"name\":\"Dumančić Sebastijan\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/287\",\"headline\":\"We implemented our idea in Brute, a new inductive logic programming which first invents a library of predicates, including recursive predicates, and performs a best-first search informed by a given loss function to build a hypothesis using the library predicates\",\"id\":\"5ea16b2b91e011fa08b8f8a2\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381804\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2004/2004.09855.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2004.09855.pdf_tz3eo8xy_images_my_y_4ri/img-001.png\",\"title\":\"Learning large logic programs by going beyond entailment\",\"year\":2020},{\"aids\":[\"542ead9adabfae4a9e494982\",\"53f447cbdabfaedf435d1f03\",\"53f466c9dabfaeb22f53efd7\",\"53f45084dabfaeecd69d4b63\",\"53f4926bdabfaedd74eb491b\"],\"authors\":[{\"id\":\"542ead9adabfae4a9e494982\",\"name\":\"Saba Ahmadi\"},{\"id\":\"53f447cbdabfaedf435d1f03\",\"name\":\"Faez Ahmed\"},{\"id\":\"53f466c9dabfaeb22f53efd7\",\"name\":\"John P. Dickerson\"},{\"id\":\"53f45084dabfaeecd69d4b63\",\"name\":\"Mark Fuge\"},{\"id\":\"53f4926bdabfaedd74eb491b\",\"name\":\"Samir Khuller\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/1\",\"headline\":\"We propose an algorithm that guarantees an optimal solution and converges faster than a proposed approach using a black-box industrial Mixed-Integer Quadratic Program solver\",\"id\":\"5ef96b048806af6ef2771fd5\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d46315233238176e\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":126,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0001.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0001.pdf_kin01g3p_images_ydd11zeb/img-001.png\",\"title\":\"An Algorithm for Multi-Attribute Diverse Matching\",\"year\":2020},{\"aids\":[\"56311fc245cedb3399cb3327\",\"53f3588fdabfae4b34965da0\"],\"authors\":[{\"id\":\"56311fc245cedb3399cb3327\",\"name\":\"Siyu Lin\"},{\"id\":\"53f3588fdabfae4b34965da0\",\"name\":\"Peter A. Beling\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/627\",\"headline\":\"We propose an end-to-end optimal trade execution framework based on PPO\",\"id\":\"5ef96b048806af6ef2772245\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0517d4631523323818e3\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":123,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0627.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0627.pdf_72fuenkj_images_uqbq8fui/img-001.png\",\"title\":\"An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization\",\"year\":2020},{\"abstract\":\"  Existing convergence analyses of Q-learning mostly focus on the vanilla stochastic gradient descent (SGD) type of updates. Despite the Adaptive Moment Estimation (Adam) has been commonly used for practical Q-learning algorithms, there has not been any convergence guarantee provided for Q-learning with such type of updates. In this paper, we first characterize the convergence rate for Q-AMSGrad, which is the Q-learning algorithm with AMSGrad update (a commonly adopted alternative of Adam for theoretical analysis). To further improve the performance, we propose to incorporate the momentum restart scheme to Q-AMSGrad, resulting in the so-called Q-AMSGradR algorithm. The convergence rate of Q-AMSGradR is also established. Our experiments on a linear quadratic regulator problem show that the two proposed Q-learning algorithms outperform the vanilla Q-learning with SGD updates. The two algorithms also exhibit significantly better performance than the DQN learning method over a batch of Atari 2600 games. \",\"aids\":[\"5617a08e45ce1e5963e405e7\",\"5618326645ce1e5963f93d64\",\"5405a7ecdabfae450f3c22a6\",\"53f4b8f6dabfaed83b77b422\"],\"authors\":[{\"id\":\"5617a08e45ce1e5963e405e7\",\"name\":\"Bowen Weng\"},{\"id\":\"5618326645ce1e5963f93d64\",\"name\":\"Huaqing Xiong\"},{\"id\":\"5405a7ecdabfae450f3c22a6\",\"name\":\"Yingbin Liang\"},{\"id\":\"53f4b8f6dabfaed83b77b422\",\"name\":\"Wei Zhang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/422\",\"headline\":\"We study two Q-learning algorithms with Adaptive Moment Estimation-type updates, and demonstrate their superior performance over the vanilla Q-learning and deep Q-Network algorithms through a linear quadratic regulator problem and a batch of 23 Atari 2600 games\",\"id\":\"5ef96b048806af6ef27720e4\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381805\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":123,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0422.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0422.pdf_ikn8agkw_images_86w4v40v/img-001.png\",\"title\":\"Analysis of Q-learning with Adaptation and Momentum Restart for Gradient Descent\",\"year\":2020},{\"aids\":[\"53f35095dabfae4b34945bf1\",\"5611f65745ce1e5962a51665\",\"54875be8dabfae9b40134539\"],\"authors\":[{\"id\":\"53f35095dabfae4b34945bf1\",\"name\":\"Andreas Niskanen\"},{\"id\":\"5611f65745ce1e5962a51665\",\"name\":\"Daniel Neugebauer\"},{\"id\":\"54875be8dabfae9b40134539\",\"name\":\"Matti JÃ¤rvisalo\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/257\",\"headline\":\"We provided complexity results for credulous and skeptical controllability in control argumentation frameworks under five central semantics\",\"id\":\"5ef96b048806af6ef27720b8\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050ed463152332381810\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":121,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0257.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0257.pdf_5chbcjeh_images_uc88qivs/img-001.png\",\"title\":\"Controllability of Control Argumentation Frameworks\",\"year\":2020}],\"meta\":{\"context\":\"3596084E\",\"time\":\"811.139271ms\"},\"succeed\":\"true\",\"total\":645}]}\n",
    "type(page3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2 = {\"data\":[{\"items\":[{\"aids\":[\"5d50c3b57390bff0db2a8363\",\"562d490f45cedb3398db09bc\",\"53f564e9dabfae60b4f8045b\",\"5630f06645ceb49c5de19c07\",\"53f43bcedabfaec09f1b03a8\"],\"authors\":[{\"id\":\"5d50c3b57390bff0db2a8363\",\"name\":\"Zhongyang Li\"},{\"id\":\"562d490f45cedb3398db09bc\",\"name\":\"Xiao Ding\"},{\"id\":\"53f564e9dabfae60b4f8045b\",\"name\":\"Ting Liu\"},{\"id\":\"5630f06645ceb49c5de19c07\",\"name\":\"J. Edward Hu\"},{\"id\":\"53f43bcedabfaec09f1b03a8\",\"name\":\"Benjamin Van Durme\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/502\",\"headline\":\"We introduced a novel extension to lexically-constrained decoding that supports disjunctive positive constraints, where generated output is forced to contain one of a set of candidates\",\"id\":\"5ef96b048806af6ef27721d9\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0503d4631523323816bf\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":209,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0502.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0502.pdf_l5v4uks8_images_nivotp40/img-001.png\",\"title\":\"Guided Generation of Cause and Effect\",\"year\":2020},{\"abstract\":\"  Despite the huge progress in scene graph generation in recent years, its long-tail distribution in object relationships remains a challenging and pestering issue. Existing methods largely rely on either external knowledge or statistical bias information to alleviate this problem. In this paper, we tackle this issue from another two aspects: (1) scene-object interaction aiming at learning specific knowledge from a scene via an additive attention mechanism; and (2) long-tail knowledge transfer which tries to transfer the rich knowledge learned from the head into the tail. Extensive experiments on the benchmark dataset Visual Genome on three tasks demonstrate that our method outperforms current state-of-the-art competitors. \",\"aids\":[\"53f42e9cdabfaeb2acffa044\",\"53f44ba9dabfaeecd69c1ed7\",\"53f438f4dabfaee43ec48960\",\"542e56fadabfae2222dd1313\"],\"authors\":[{\"name\":\"He Tao\"},{\"id\":\"53f42e9cdabfaeb2acffa044\",\"name\":\"Gao Lianli\"},{\"id\":\"53f44ba9dabfaeecd69c1ed7\",\"name\":\"Song Jingkuan\"},{\"id\":\"53f438f4dabfaee43ec48960\",\"name\":\"Cai Jianfei\"},{\"id\":\"542e56fadabfae2222dd1313\",\"name\":\"Li Yuan-Fang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/82\",\"headline\":\"We investigate the long-tail problem existing in scene graph generation\",\"id\":\"5ee8986891e011e66831c322\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d46315233238168e\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":205,\"pdf\":\"https://static.aminer.cn/upload/pdf/209/1152/629/5ee8986891e011e66831c322_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5ee8986891e011e66831c322_0.pdf_8n3tc_9z_images_2w9g6ph0/img-001.png\",\"title\":\"Learning from the Scene and Borrowing from the Rich: Tackling the Long\\n  Tail in Scene Graph Generation\",\"year\":2020},{\"abstract\":\"  Generative adversarial imitation learning (GAIL) has shown promising results by taking advantage of generative adversarial nets, especially in the field of robot learning. However, the requirement of isolated single modal demonstrations limits the scalability of the approach to real world scenarios such as autonomous vehicles' demand for a proper understanding of human drivers' behavior. In this paper, we propose a novel multi-modal GAIL framework, named Triple-GAIL, that is able to learn skill selection and imitation jointly from both expert demonstrations and continuously generated experiences with data augmentation purpose by introducing an auxiliary skill selector. We provide theoretical guarantees on the convergence to optima for both of the generator and the selector respectively. Experiments on real driver trajectories and real-time strategy game datasets demonstrate that Triple-GAIL can better fit multi-modal behaviors close to the demonstrators and outperforms state-of-the-art methods. \",\"aids\":[\"5632006045cedb3399f8cbab\",\"53f43454dabfaedce551b305\",\"53f4327bdabfaeb22f449275\",\"53f43a9cdabfaeb2ac075577\"],\"authors\":[{\"name\":\"Fei Cong\"},{\"name\":\"Wang Bin\"},{\"name\":\"Zhuang Yuzheng\"},{\"id\":\"5632006045cedb3399f8cbab\",\"name\":\"Zhang Zongzhang\"},{\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Hao Jianye\"},{\"name\":\"Zhang Hongbo\"},{\"id\":\"53f4327bdabfaeb22f449275\",\"name\":\"Ji Xuewu\"},{\"id\":\"53f43a9cdabfaeb2ac075577\",\"name\":\"Liu Wulong\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/405\",\"headline\":\"We propose a novel multi-modal GAIL framework, named Triple-GAIL, that is able to learn skill selection and imitation jointly from both expert demonstrations and continuously generated experiences with data augmentation purpose by introducing an auxiliary skill selector\",\"id\":\"5ec7a33091e0118397f3ef17\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0502d4631523323816a7\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":203,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.10622.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.10622.pdf_ic74czz6_images_lt7brm5_/img-001.png\",\"title\":\"Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative\\n  Adversarial Nets\",\"year\":2020},{\"abstract\":\"  A feature-based model explanation denotes how much each input feature contributes to a model\\'s output for a given data point. As the number of proposed explanation functions grows, we lack quantitative evaluation criteria to help practitioners know when to use which explanation function. This paper proposes quantitative evaluation criteria for feature-based explanations: low sensitivity, high faithfulness, and low complexity. We devise a framework for aggregating explanation functions. We develop a procedure for learning an aggregate explanation function with lower complexity and then derive a new aggregate Shapley value explanation function that minimizes sensitivity. \",\"aids\":[\"5628b44445ce1e596600e0eb\",\"53f4325cdabfaedce5504bfa\",\"548c9bc1dabfaed7b5fa44fa\"],\"authors\":[{\"id\":\"5628b44445ce1e596600e0eb\",\"name\":\"Bhatt Umang\"},{\"id\":\"53f4325cdabfaedce5504bfa\",\"name\":\"Weller Adrian\"},{\"id\":\"548c9bc1dabfaed7b5fa44fa\",\"name\":\"Moura José M. F.\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/417\",\"headline\":\"This paper proposes quantitative evaluation criteria for feature-based explanations: low sensitivity, high faithfulness, and low complexity\",\"id\":\"5eb78919da5629cf244303c0\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d46315233238177d\",\"num_citation\":4,\"num_like\":0,\"num_viewed\":200,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.00631.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.00631.pdf_j0bhk9ny_images_4amnsm6z/img-001.png\",\"title\":\"Evaluating and Aggregating Feature-based Model Explanations\",\"year\":2020},{\"aids\":[\"53f45d1ddabfaec09f21d5d5\",\"53f43759dabfaee1c0aa5d40\",\"53f42c26dabfaeb22f3f5982\",\"53f49743dabfaeb6cf77b539\"],\"authors\":[{\"id\":\"53f45d1ddabfaec09f21d5d5\",\"name\":\"Bahare Fatemi\"},{\"id\":\"53f43759dabfaee1c0aa5d40\",\"name\":\"Perouz Taslakian\"},{\"id\":\"53f42c26dabfaeb22f3f5982\",\"name\":\"David Vazquez\"},{\"id\":\"53f49743dabfaeb6cf77b539\",\"name\":\"David Poole\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/303\",\"headline\":\"Given a knowledge hypergraph on τ, we evaluate various completion methods using a train and test set τtrain and τtest\",\"id\":\"5ef96b048806af6ef2772134\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0512d46315233238185c\",\"num_citation\":9,\"num_like\":0,\"num_viewed\":194,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0303.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0303.pdf_jj5_7bb__images_rndq2j_x/img-001.png\",\"title\":\"Knowledge Hypergraphs: Prediction Beyond Binary Relations\",\"year\":2020},{\"abstract\":\"  Reinforcement learning agents usually learn from scratch, which requires a large number of interactions with the environment. This is quite different from the learning process of human. When faced with a new task, human naturally have the common sense and use the prior knowledge to derive an initial policy and guide the learning process afterwards. Although the prior knowledge may be not fully applicable to the new task, the learning process is significantly sped up since the initial policy ensures a quick-start of learning and intermediate guidance allows to avoid unnecessary exploration. Taking this inspiration, we propose knowledge guided policy network (KoGuN), a novel framework that combines human prior suboptimal knowledge with reinforcement learning. Our framework consists of a fuzzy rule controller to represent human knowledge and a refine module to fine-tune suboptimal prior knowledge. The proposed framework is end-to-end and can be combined with existing policy-based reinforcement learning algorithm. We conduct experiments on both discrete and continuous control tasks. The empirical results show that our approach, which combines human suboptimal knowledge and RL, achieves significant improvement on learning efficiency of flat RL algorithms, even with very low-performance human prior knowledge. \",\"aids\":[\"53f43454dabfaedce551b305\",\"560fe71345ce1e5961f0fe0f\",\"53f443d2dabfaeb22f4b53ba\",\"562d3e7745cedb3398d9c324\"],\"authors\":[{\"name\":\"Zhang Peng\"},{\"id\":\"53f43454dabfaedce551b305\",\"name\":\"Hao Jianye\"},{\"id\":\"560fe71345ce1e5961f0fe0f\",\"name\":\"Wang Weixun\"},{\"id\":\"53f443d2dabfaeb22f4b53ba\",\"name\":\"Tang Hongyao\"},{\"name\":\"Ma Yi\"},{\"id\":\"562d3e7745cedb3398d9c324\",\"name\":\"Duan Yihai\"},{\"name\":\"Zheng Yan\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/317\",\"headline\":\"We propose a novel policy network framework called knowledge guided policy network to leverage human knowledge to accelerate the learning process of RL agents\",\"id\":\"5e4d083f3a55ac8cfd770c23\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0502d463152332381699\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":188,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2002/2002.07418.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2002.07418.pdf_3vpwq_7a_images_hjpmte6a/img-001.png\",\"title\":\"KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human\\n  Suboptimal Knowledge\",\"year\":2020},\n",
    "                           {\"aids\":[\"5d415be07390bff0db70a4c7\",\"5d415c0c7390bff0db70c49b\",\"53f478d1dabfaee4dc8965ac\",\"5603964b45cedb33961dffac\",\"542a239edabfae864af907a1\",\"53fa102edabfae7f97b045c2\",\"542d413cdabfae11fc4517d5\"],\"authors\":[{\"id\":\"5d415be07390bff0db70a4c7\",\"name\":\"Renjun Hu\"},{\"id\":\"5d415c0c7390bff0db70c49b\",\"name\":\"Xinjiang Lu\"},{\"id\":\"53f478d1dabfaee4dc8965ac\",\"name\":\"Chuanren Liu\"},{\"id\":\"5603964b45cedb33961dffac\",\"name\":\"Yanyan Li\"},{\"id\":\"542a239edabfae864af907a1\",\"name\":\"Hao Liu\"},{\"id\":\"53fa102edabfae7f97b045c2\",\"name\":\"Shuai Ma\"},{\"id\":\"542d413cdabfae11fc4517d5\",\"name\":\"Hui Xiong\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/478\",\"headline\":\"Its relationship to decision profiling is that PROUD preserves decision structures via identifying key factors and maximizing scalar projection, and the effectiveness of PROUD for preserving decision structures directly relies on the goodness of identified key factors\",\"id\":\"5e5e193693d709897ce5ca82\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d46315233238177a\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":188,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0478.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0478.pdf_g27sfckn_images_8vmag6yz/img-001.png\",\"title\":\"Why We Go Where We Go: Profiling User Decisions on Choosing POIs\",\"year\":2020},{\"aids\":[\"5609ae0845cedb3396f4be32\",\"560defcb45cedb3397628128\",\"5d415c0a7390bff0db70c3c3\",\"560763c045cedb3396a9e0c4\",\"562d4b8b45cedb3398db54eb\",\"562d24f745cedb3398d668a9\"],\"authors\":[{\"id\":\"5609ae0845cedb3396f4be32\",\"name\":\"Zihao Zhu\"},{\"id\":\"560defcb45cedb3397628128\",\"name\":\"Jing Yu\"},{\"id\":\"5d415c0a7390bff0db70c3c3\",\"name\":\"Yujing Wang\"},{\"id\":\"560763c045cedb3396a9e0c4\",\"name\":\"Yajing Sun\"},{\"id\":\"562d4b8b45cedb3398db54eb\",\"name\":\"Yue Hu\"},{\"id\":\"562d24f745cedb3398d668a9\",\"name\":\"Qi Wu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/153\",\"headline\":\"We propose Mucko for visual question answering requiring external knowledge, which focuses on multilayer cross-modal knowledge reasoning\",\"id\":\"5ef96b048806af6ef2772043\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0514d463152332381896\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":181,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0153.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0153.pdf_mj9hi_3s_images_02ywp8bp/img-001.png\",\"title\":\"Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering\",\"year\":2020},{\"aids\":[\"5628e87545ce1e59660dc3bc\",\"561546a545ce1e59636a2271\",\"5433d1e9dabfaebba5829eaa\",\"5611d59445ce1e59629b58f2\",\"56083a9745ce1e595f4cc503\",\"53f42cb6dabfaeb1a7b81161\",\"53f55f34dabfae535bf8045b\"],\"authors\":[{\"id\":\"5628e87545ce1e59660dc3bc\",\"name\":\"Riley Simmons-Edler\"},{\"id\":\"561546a545ce1e59636a2271\",\"name\":\"Ben Eisner\"},{\"id\":\"5433d1e9dabfaebba5829eaa\",\"name\":\"Daniel Yang\"},{\"id\":\"5611d59445ce1e59629b58f2\",\"name\":\"Anthony Bisulco\"},{\"id\":\"56083a9745ce1e595f4cc503\",\"name\":\"Eric Mitchell\"},{\"id\":\"53f42cb6dabfaeb1a7b81161\",\"name\":\"Sebastian Seung\"},{\"id\":\"53f55f34dabfae535bf8045b\",\"name\":\"Daniel Lee\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/390\",\"headline\":\"We propose a new exploration objective, maximizing the reward prediction error of a value function trained to predict extrinsic reward\",\"id\":\"5ef96b048806af6ef2772170\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0515d4631523323818a7\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":179,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0390.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0390.pdf_e92q5ln__images_k15nl98_/img-001.png\",\"title\":\"Reward Prediction Error as an Exploration Objective in Deep RL\",\"year\":2020},{\"aids\":[\"5629baf345ce1e596650b707\",\"53f58dc0dabfaed67df8060d\",\"560c208445cedb339749f1d4\",\"544098b0dabfae805a6d9817\",\"53f4cb26dabfaeeb13f80965\"],\"authors\":[{\"id\":\"5629baf345ce1e596650b707\",\"name\":\"Gabriele Ciravegna\"},{\"id\":\"53f58dc0dabfaed67df8060d\",\"name\":\"Francesco Giannini\"},{\"id\":\"560c208445cedb339749f1d4\",\"name\":\"Marco Gori\"},{\"id\":\"544098b0dabfae805a6d9817\",\"name\":\"Marco Maggini\"},{\"id\":\"53f4cb26dabfaeeb13f80965\",\"name\":\"Stefano Melacci\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/309\",\"headline\":\"We presented an approach that yields First-Order Logicbased explanations of a multi-label neural classifier, using another neural network that learns to explain the classifier itself\",\"id\":\"5ef96b048806af6ef2772124\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050dd4631523323817f0\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":174,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0309.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0309.pdf_hqeixdd2_images_qkb56q5z/img-001.png\",\"title\":\"Human-Driven FOL Explanations of Deep Learning\",\"year\":2020},{\"abstract\":\"  Stochastic variance-reduced gradient (SVRG) is an optimization method originally designed for tackling machine learning problems with a finite sum structure. SVRG was later shown to work for policy evaluation, a problem in reinforcement learning in which one aims to estimate the value function of a given policy. SVRG makes use of gradient estimates at two scales. At the slower scale, SVRG computes a full gradient over the whole dataset, which could lead to prohibitive computation costs. In this work, we show that two variants of SVRG for policy evaluation could significantly diminish the number of gradient calculations while preserving a linear convergence speed. More importantly, our theoretical result implies that one does not need to use the entire dataset in every epoch of SVRG when it is applied to policy evaluation with linear function approximation. Our experiments demonstrate large computational savings provided by the proposed methods. \",\"aids\":[\"562d535845cedb3398dc60f2\",\"53f430c5dabfaedd74d61d58\",\"53f4cb73dabfaee57b78116d\",\"5434eb1cdabfaebba587df4e\"],\"authors\":[{\"id\":\"562d535845cedb3398dc60f2\",\"name\":\"Zilun Peng\"},{\"id\":\"53f430c5dabfaedd74d61d58\",\"name\":\"Ahmed Touati\"},{\"id\":\"53f4cb73dabfaee57b78116d\",\"name\":\"Pascal Vincent\"},{\"id\":\"5434eb1cdabfaebba587df4e\",\"name\":\"Doina Precup\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"headline\":\"We show that Batching Stochastic variance-reduced gradient and Stochastic Gradient converge linearly when solving the saddle-point formulation of Mean Squared Projected Bellman Error\",\"id\":\"5d06e491da562926acc53f32\",\"is_like\":\"false\",\"lang\":\"en\",\"mrt_link\":\"5f4e0501d46315233238168f\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":169,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/19/1906/1906.03704.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/1906.03704.pdf_5jbexv5c_images_0bvvf0la/img-001.png\",\"title\":\"SVRG for Policy Evaluation with Fewer Gradient Evaluations.\",\"year\":2019},{\"abstract\":\"  Estimating probability distribution is one of the core issues in the NLP field. However, in both deep learning (DL) and pre-DL eras, unlike the vast applications of linear-chain CRF in sequence labeling tasks, very few works have applied tree-structure CRF to constituency parsing, mainly due to the complexity and inefficiency of the inside-outside algorithm. This work presents a fast and accurate neural CRF constituency parser. The key idea is to batchify the inside algorithm for loss computation by direct large tensor operations on GPU, and meanwhile avoid the outside algorithm for gradient computation via efficient back-propagation. We also propose a simple two-stage bracketing-then-labeling parsing approach to improve efficiency further. To improve the parsing performance, inspired by recent progress in dependency parsing, we introduce a new scoring architecture based on boundary representation and biaffine attention, and a beneficial dropout strategy. Experiments on PTB, CTB5.1, and CTB7 show that our two-stage CRF parser achieves new state-of-the-art performance on both settings of w/o and w/ BERT, and can parse over 1,000 sentences per second. We release our code at https://github.com/yzhangcs/crfpar. \",\"aids\":[\"560dbbe345ce1e5960ef7b3d\",\"560caea345cedb339755e6ac\",\"53f46586dabfaee2a1dab376\"],\"authors\":[{\"id\":\"560dbbe345ce1e5960ef7b3d\",\"name\":\"Yu Zhang\"},{\"id\":\"560caea345cedb339755e6ac\",\"name\":\"Houquan Zhou\"},{\"id\":\"53f46586dabfaee2a1dab376\",\"name\":\"Zhenghua Li\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/560\",\"headline\":\"We propose a fast and accurate neural CRF constituency parser\",\"id\":\"5ef96b048806af6ef27721d2\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0514d463152332381895\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":169,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0560.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0560.pdf_c4bfbcvw_images_4gfmi8wm/img-001.png\",\"title\":\"Fast and Accurate Neural CRF Constituency Parsing\",\"year\":2020},{\"abstract\":\"  Commonsense knowledge acquisition is a key problem for artificial intelligence. Conventional methods of acquiring commonsense knowledge generally require laborious and costly human annotations, which are not feasible on a large scale. In this paper, we explore a practical way of mining commonsense knowledge from linguistic graphs, with the goal of transferring cheap knowledge obtained with linguistic patterns into expensive commonsense knowledge. The result is a conversion of ASER [Zhang et al., 2020], a large-scale selectional preference knowledge resource, into TransOMCS, of the same representation as ConceptNet [Liu and Singh, 2004] but two orders of magnitude larger. Experimental results demonstrate the transferability of linguistic knowledge to commonsense knowledge and the effectiveness of the proposed approach in terms of quantity, novelty, and quality. TransOMCS is publicly available at: https://github.com/HKUST-KnowComp/TransOMCS. \",\n",
    "                           \"aids\":[\"560fe00145ce1e5961ede495\",\"53f42f85dabfaec22ba333b0\",\"54849c88dabfae9b40132fad\",\"53f48b48dabfaee0d9c73c7f\"],\"authors\":[{\"id\":\"560fe00145ce1e5961ede495\",\"name\":\"Zhang Hongming\"},{\"id\":\"53f42f85dabfaec22ba333b0\",\"name\":\"Khashabi Daniel\"},{\"id\":\"54849c88dabfae9b40132fad\",\"name\":\"Song Yangqiu\"},{\"id\":\"53f48b48dabfaee0d9c73c7f\",\"name\":\"Roth Dan\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/554\",\"headline\":\"We explore a practical way of mining commonsense knowledge from linguistic graphs, with the goal of transferring cheap knowledge obtained with linguistic patterns into expensive commonsense knowledge\",\"id\":\"5eafe7e091e01198d39865dc\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381692\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":167,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.00206.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.00206.pdf_11fs6_gg_images_5kzbp9hc/img-001.png\",\"title\":\"TransOMCS: From Linguistic Graphs to Commonsense Knowledge\",\"year\":2020},{\"aids\":[\"5405fb80dabfae91d3023aaf\",\"5d43d51b7390bff0db5fefda\",\"53f4cdf8dabfaeedd777b4a3\",\"53f43766dabfaee02acd305b\",\"53f431aadabfaee0d9b33395\",\"53f463f5dabfaeb22f532fed\"],\"authors\":[{\"id\":\"5405fb80dabfae91d3023aaf\",\"name\":\"Jinhuan Liu\"},{\"id\":\"5d43d51b7390bff0db5fefda\",\"name\":\"Xuemeng Song\"},{\"id\":\"53f4cdf8dabfaeedd777b4a3\",\"name\":\"Zhaochun Ren\"},{\"id\":\"53f43766dabfaee02acd305b\",\"name\":\"Liqiang Nie\"},{\"id\":\"53f431aadabfaee0d9b33395\",\"name\":\"Zhaopeng Tu\"},{\"id\":\"53f463f5dabfaeb22f532fed\",\"name\":\"Jun Ma\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/485\",\"headline\":\"We present an end-to-end auxiliary templateenhanced generative compatibility modeling scheme, which is able to comprehensively model the compatibility between fashion items from both the item-item and item-template perspectives\",\"id\":\"5ef96b048806af6ef27721a8\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d463152332381688\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":166,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0485.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0485.pdf_p2bf22z__images_pqfj2wt8/img-001.png\",\"title\":\"Auxiliary Template-Enhanced Generative Compatibility Modeling\",\"year\":2020},{\"abstract\":\"  Vehicle re-identification (reID) aims at identifying vehicles across different non-overlapping cameras views. The existing methods heavily relied on well-labeled datasets for ideal performance, which inevitably causes fateful drop due to the severe domain bias between the training domain and the real-world scenes; worse still, these approaches required full annotations, which is labor-consuming. To tackle these challenges, we propose a novel progressive adaptation learning method for vehicle reID, named PAL, which infers from the abundant data without annotations. For PAL, a data adaptation module is employed for source domain, which generates the images with similar data distribution to unlabeled target domain as ``pseudo target samples\\'\\'. These pseudo samples are combined with the unlabeled samples that are selected by a dynamic sampling strategy to make training faster. We further proposed a weighted label smoothing (WLS) loss, which considers the similarity between samples with different clusters to balance the confidence of pseudo labels. Comprehensive experimental results validate the advantages of PAL on both VehicleID and VeRi-776 dataset. \",\"aids\":[\"560dadd545cedb3397609cf0\",\"53f42ff2dabfaeb2ac00a1d6\",\"57198d7776d911115b5dc3bd\",\"542dd861dabfae11fc4a7bf6\",\"56cb1891c35f4f3c6565176f\"],\"authors\":[{\"name\":\"Jinjia Peng\"},{\"id\":\"560dadd545cedb3397609cf0\",\"name\":\"Yang Wang\"},{\"id\":\"53f42ff2dabfaeb2ac00a1d6\",\"name\":\"Huibing Wang\"},{\"id\":\"57198d7776d911115b5dc3bd\",\"name\":\"Zhao Zhang\"},{\"id\":\"542dd861dabfae11fc4a7bf6\",\"name\":\"Xianping Fu\"},{\"id\":\"56cb1891c35f4f3c6565176f\",\"name\":\"Meng Wang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/127\",\"headline\":\"We propose an unsupervised vehicle reID framework, named PAL, which iteratively updates the feature learning model and estimates pseudo labels for unlabeled data for target domain adaptation\",\"id\":\"5ef3247091e0110c353da56d\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0501d46315233238168b\",\"num_citation\":0,\"num_like\":1,\"num_viewed\":166,\"pdf\":\"https://static.aminer.cn/upload/pdf/1717/1911/1132/5ef3247091e0110c353da56d_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5ef3247091e0110c353da56d_0.pdf_z638jc68_images_4xklfetw/img-001.png\",\"title\":\"Unsupervised Vehicle Re-identification with Progressive Adaptation\",\"year\":2020},{\"abstract\":\"  In this paper, we show that a simple coloring scheme can improve, both theoretically and empirically, the expressive power of Message Passing Neural Networks(MPNNs). More specifically, we introduce a graph neural network called Colored Local Iterative Procedure (CLIP) that uses colors to disambiguate identical node attributes, and show that this representation is a universal approximator of continuous functions on graphs with node attributes. Our method relies on separability , a key topological characteristic that allows to extend well-chosen neural networks into universal representations. Finally, we show experimentally that CLIP is capable of capturing structural characteristics that traditional MPNNs fail to distinguish,while being state-of-the-art on benchmark graph classification datasets. \",\"aids\":[\"53f35d3edabfae4b34977070\",\"562c7b2c45cedb3398c35dd5\"],\"authors\":[{\"id\":\"53f35d3edabfae4b34977070\",\"name\":\"Dasoulas George\"},{\"name\":\"Santos Ludovic Dos\"},{\"id\":\"562c7b2c45cedb3398c35dd5\",\"name\":\"Scaman Kevin\"},{\"name\":\"Virmaux Aladin\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/294\",\"headline\":\"Universality was proven using the novel concept of separable neural networks, and our experiments showed that Colored Local Iterative Procedure is state-of-the-art on both graph classification datasets and property testing tasks\",\"id\":\"5df371de3a55acfd20674ba8\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050dd4631523323817dd\",\"num_citation\":3,\"num_like\":0,\"num_viewed\":165,\"pdf\":\"https://static.aminer.cn/upload/pdf/466/25/441/5df371de3a55acfd20674ba8_0.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/5df371de3a55acfd20674ba8_0.pdf_ug7307ym_images_9e96dipr/img-001.png\",\"title\":\"Coloring graph neural networks for node disambiguation\",\"year\":2019},{\"abstract\":\"  We propose a simple yet powerful test statistic to quantify the discrepancy between two conditional distributions. The new statistic avoids the explicit estimation of the underlying distributions in highdimensional space and it operates on the cone of symmetric positive semidefinite (SPS) matrix using the Bregman matrix divergence. Moreover, it inherits the merits of the correntropy function to explicitly incorporate high-order statistics in the data. We present the properties of our new statistic and illustrate its connections to prior art. We finally show the applications of our new statistic on three different machine learning problems, namely the multi-task learning over graphs, the concept drift detection, and the information-theoretic feature selection, to demonstrate its utility and advantage. Code of our statistic is available at https://bit.ly/BregmanCorrentropy. \",\"aids\":[\"562d86fd45cedb3398e45480\",\"562ccd5945cedb3398ccb50a\",\"562c73fc45cedb3398c289d7\",\"53f46c52dabfaee2a1dc6835\"],\"authors\":[{\"id\":\"562d86fd45cedb3398e45480\",\"name\":\"Yu Shujian\"},{\"id\":\"562ccd5945cedb3398ccb50a\",\"name\":\"Shaker Ammar\"},{\"id\":\"562c73fc45cedb3398c289d7\",\"name\":\"Alesiani Francesco\"},{\"id\":\"53f46c52dabfaee2a1dc6835\",\"name\":\"Principe Jose C.\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/385\",\"headline\":\"Our statistic enables the development of alternative solutions to classical machine learning problems in a fundamental manner\",\"id\":\"5eb3dc4191e011ce31f280e8\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0506d46315233238171b\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":163,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2005/2005.02196.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2005.02196.pdf_dvoxcls2_images_f1x30x8n/img-001.png\",\"title\":\"Measuring the Discrepancy between Conditional Distributions: Methods,\\n  Properties and Applications\",\"year\":2020},{\"aids\":[\"542a4c5fdabfae646d54a975\",\"5630fa8645ceb49c5de51fe2\",\"53f48bdddabfaea7cd1cd3b6\",\"53f58dbfdabfaed67df80495\",\"5429ae0fdabfaec7081a5ec0\"],\"authors\":[{\"id\":\"542a4c5fdabfae646d54a975\",\"name\":\"Min Shi\"},{\"id\":\"5630fa8645ceb49c5de51fe2\",\"name\":\"Yufei Tang\"},{\"id\":\"53f48bdddabfaea7cd1cd3b6\",\"name\":\"Xingquan Zhu\"},{\"id\":\"53f58dbfdabfaed67df80495\",\"name\":\"David Wilson\"},{\"id\":\"5429ae0fdabfaec7081a5ec0\",\"name\":\"Jianxun Liu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/398\",\"headline\":\"We proposed a novel dual-regularized graph convolutional network that contains a conditional adversarial training to enhance the separation of nodes from different classes and a distribution alignment training to enforce balanced learning between majority and minority classes\",\"id\":\"5ef96b048806af6ef277214e\",\"is_like\":\"false\",\"mrt_link\":\"5f4e0509d46315233238176f\",\"num_citation\":0,\"num_like\":0,\"num_viewed\":162,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0398.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0398.pdf_8x4vvwz5_images_8sfuhlb0/img-001.png\",\"title\":\"Multi-Class Imbalanced Graph Convolutional Network Learning\",\"year\":2020},{\"abstract\":\"  RGB-Infrared (IR) cross-modality person re-identification (re-ID), which aims to search an IR image in RGB gallery or vice versa, is a challenging task due to the large discrepancy between IR and RGB modalities. Existing methods address this challenge typically by aligning feature distributions or image styles across modalities, whereas the very useful similarities among gallery samples of the same modality (i.e. intra-modality sample similarities) is largely neglected. This paper presents a novel similarity inference metric (SIM) that exploits the intra-modality sample similarities to circumvent the cross-modality discrepancy targeting optimal cross-modality image matching. SIM works by successive similarity graph reasoning and mutual nearest-neighbor reasoning that mine cross-modality sample similarities by leveraging intra-modality sample similarities from two different perspectives. Extensive experiments over two cross-modality re-ID datasets (SYSU-MM01 and RegDB) show that SIM achieves significant accuracy improvement but with little extra training as compared with the state-of-the-art. \",\n",
    "                           \"aids\":[\"53f449fcdabfaee1c0afb982\",\"560bc4a445ce1e596038379f\",\"5405b433dabfae92b41f65e9\",\"54408ee3dabfae7d84b81202\",\"542d4074dabfae11fc4511e0\"],\"authors\":[{\"id\":\"53f449fcdabfaee1c0afb982\",\"name\":\"Mengxi Jia\"},{\"id\":\"560bc4a445ce1e596038379f\",\"name\":\"Yunpeng Zhai\"},{\"id\":\"5405b433dabfae92b41f65e9\",\"name\":\"Shijian Lu\"},{\"id\":\"54408ee3dabfae7d84b81202\",\"name\":\"Siwei Ma\"},{\"id\":\"542d4074dabfae11fc4511e0\",\"name\":\"Jian Zhang\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/143\",\"headline\":\"We introduce similarity graph reasoning and mutual nearestneighbor reasoning to infer inter-modality sample similarities by exploiting reliable intra-modality sample similarity\",\"id\":\"5ef96b048806af6ef2772012\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050dd4631523323817d8\",\"num_citation\":1,\"num_like\":0,\"num_viewed\":161,\"pdf\":\"https://static.aminer.cn/storage/pdf/arxiv/20/2007/2007.01504.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/2007.01504.pdf_hlyyqkux_images_88i7wr7a/img-001.png\",\"title\":\"A Similarity Inference Metric for RGB-Infrared Cross-Modality Person Re-identification\",\"year\":2020},{\"aids\":[\"542b6ab0dabfae2b4e163eba\",\"560527d345ce1e595e41039f\",\"53f3852edabfae4b34a0e3c2\",\"5614156c45ce1e596330dbc3\",\"56065cde45cedb3396854f9a\"],\"authors\":[{\"id\":\"542b6ab0dabfae2b4e163eba\",\"name\":\"Weiwei Wang\"},{\"id\":\"560527d345ce1e595e41039f\",\"name\":\"Yuming Shen\"},{\"id\":\"53f3852edabfae4b34a0e3c2\",\"name\":\"Haofeng Zhang\"},{\"id\":\"5614156c45ce1e596330dbc3\",\"name\":\"Yazhou Yao\"},{\"id\":\"56065cde45cedb3396854f9a\",\"name\":\"Li Liu\"}],\"conf_id\":\"5ef86d3592c7f9be218d4b9b\",\"doi\":\"10.24963/ijcai.2020/119\",\"headline\":\"This paper proposed a new kind of unsupervised crossmodal hashing method which utilized sparse graph structures to exploit similarity information to address the degradation problem in unsupervised algorithms\",\"id\":\"5ef96b048806af6ef277205a\",\"is_like\":\"false\",\"mrt_link\":\"5f4e050bd4631523323817b2\",\"num_citation\":2,\"num_like\":0,\"num_viewed\":159,\"pdf\":\"https://static.aminer.cn/storage/pdf/ijcai/20/0119.pdf\",\"picture\":\"https://cloud-api.scholarcy.com/images/0119.pdf_219vsh2h_images_pg2dql84/img-001.png\",\"title\":\"Set and Rebase: Determining the Semantic Graph Connectivity for Unsupervised Cross-Modal Hashing\",\"year\":2020}],\"meta\":{\"context\":\"E1E67B45\",\"time\":\"819.293121ms\"},\"succeed\":\"true\",\"total\":645}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_location = r'D:\\Ani\\Thesis\\papers'\n",
    "for paper in page3['data'][0]['items']:\n",
    "    title = paper['title'].replace('\\n', '').replace(':', '')\n",
    "    filename = os.path.join(folder_location, title + '.pdf')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(paper['pdf']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided Generation of Cause and Effect \n",
      "\n",
      "Learning from the Scene and Borrowing from the Rich: Tackling the Long\n",
      "  Tail in Scene Graph Generation \n",
      "\n",
      "Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative\n",
      "  Adversarial Nets \n",
      "\n",
      "Evaluating and Aggregating Feature-based Model Explanations \n",
      "\n",
      "Knowledge Hypergraphs: Prediction Beyond Binary Relations \n",
      "\n",
      "KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human\n",
      "  Suboptimal Knowledge \n",
      "\n",
      "Why We Go Where We Go: Profiling User Decisions on Choosing POIs \n",
      "\n",
      "Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering \n",
      "\n",
      "Reward Prediction Error as an Exploration Objective in Deep RL \n",
      "\n",
      "Human-Driven FOL Explanations of Deep Learning \n",
      "\n",
      "SVRG for Policy Evaluation with Fewer Gradient Evaluations. \n",
      "\n",
      "Fast and Accurate Neural CRF Constituency Parsing \n",
      "\n",
      "TransOMCS: From Linguistic Graphs to Commonsense Knowledge \n",
      "\n",
      "Auxiliary Template-Enhanced Generative Compatibility Modeling \n",
      "\n",
      "Unsupervised Vehicle Re-identification with Progressive Adaptation \n",
      "\n",
      "Coloring graph neural networks for node disambiguation \n",
      "\n",
      "Measuring the Discrepancy between Conditional Distributions: Methods,\n",
      "  Properties and Applications \n",
      "\n",
      "Multi-Class Imbalanced Graph Convolutional Network Learning \n",
      "\n",
      "A Similarity Inference Metric for RGB-Infrared Cross-Modality Person Re-identification \n",
      "\n",
      "Set and Rebase: Determining the Semantic Graph Connectivity for Unsupervised Cross-Modal Hashing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in page2['data'][0]['items']:\n",
    "    print(i['title'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_search = 'https://apiv2.aminer.cn/magic?a=GetPubs__conf.GetPubs___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\"Accept\": \"application/json\",\n",
    "         \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "         \"Accept-Language\": \"ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7,hy;q=0.6\",\n",
    "         \"Authorization\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIyLURvUm1kdVwvY0F2VUxMNzhiMDVyY1FaNElrUWlGTmJuRk1JYUdaNEllQ0YwM0JhdExQbWkyWnJmbGlUZzVkcUFDczhlNGwrNTJDcllIYWF4ZGdnckxCb0VHRkljNXkyMnVXcmpcLzc2MndnNVE9IiwidWlkIjoiNWZiYThmMzM0Yzc3NWU1YTQ3MTcwYmM5Iiwic3JjIjoiYW1pbmVyIiwicm9sZXMiOltdLCJpc3MiOiJhcGkuYW1pbmVyLm9yZyIsImV4cCI6MTYwODY1NDAwMCwiaWF0IjoxNjA2MDYyMDAwLCJqdGkiOiI4OWI3YTA4YzEwM2I3NWY5NDNkZjNiMjlmYTJhNjI4ZDQyMmE1M2IwNTI2NjI3ZmNlYmIzZWFhMWU2MmFhNjNlYTJhMDcyMmU4NmZhNDRjZGU4NDg4MDZlNmVmOGQxYjI5MmYxYTk4NDExOWRiOGI1NTc4YzJkMmE1ZDY0M2ZjMTg4NmM4MTYzZmY1NzhhZTE2ZjM0ZWI0NDc0MGU4OWIzMjI2Y2ZjZWRmZTcxZWRjM2I0MWIyOTgyZDEyZWIwNzY1NWQxMGU5YWVjNzdhZmJmMGUwNWMzYTIzMGEyYmQ2MWY3ZTZjN2E2MTY1OGE3NTllMDA3NzUyMDE0YzliMzJiIiwiZW1haWwiOiJ0ZXZvc3lhbmFuaUBtYWlsLnJ1In0.Lk55y9j1N6B2sfacWRv6HbW3N5w74_rxBfJdvvQBosw\",\n",
    "         \"Connection\": \"keep-alive\",\n",
    "         \"Content-Length\": \"345\",\n",
    "         \"Content-Type\": \"application/json\",\n",
    "         \"debug\": \"1\",\n",
    "         \"Host\": \"apiv2.aminer.cn\",\n",
    "         \"Origin\": \"https://www.aminer.org\",\n",
    "         \"Referer\": \"https://www.aminer.org/\",\n",
    "         \"sec-ch-ua\": \"'Google Chrome';v='87', '\\'Not;A\\\\Brand';v='99', 'Chromium';v='87'\",\n",
    "         \"sec-ch-ua-mobile\": \"?1\",\n",
    "         \"Sec-Fetch-Dest\": \"empty\",\n",
    "         \"Sec-Fetch-Mode\": \"cors\",\n",
    "         \"Sec-Fetch-Site\": \"cross-site\",\n",
    "         \"User-Agent\":\"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36\"}\n",
    "\n",
    "data={\n",
    "    \"action\": \"conf.GetPubs\",\n",
    "    \"parameters\": {\"conf_id\": \"5ef86d3592c7f9be218d4b9b\", \"offset\": 20, \"size\": 20, \"sort\": \"view\"},\n",
    "    \"schema\":\n",
    "        {\"publication\": [\"id\", \"year\", \"title\", \"title_zh\", \"abstract\", \"abstract_zh\", \"authors\", \"authors._id\"]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "req=requests.post(url_search,headers=headers,json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'error on decode request: json: cannot unmarshal object into Go value of type []webmodel.RequestData\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Journal of Mathematical and Computer Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_issue = [(1, 1),\n",
    "             (2, 1), (2, 2), (2, 3), (2, 4),\n",
    "             (3, 1), (3, 2), (3, 3), (3, 4),\n",
    "             (4, 1), (4, 2), (4, 3), (4, 4),\n",
    "             (5, 1), (5, 2), (5, 3), (5, 4)]\n",
    "\n",
    "url_base = 'http://www.sciencepublishinggroup.com/journal/archive?journalid=604&issueid=604'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:05<00:16,  5.56s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:08<00:09,  4.74s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:23<00:07,  8.00s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.34s/it]\u001b[A\n",
      "  6%|████▉                                                                              | 1/17 [00:31<08:19, 31.25s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:12<00:49, 12.40s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:16<00:29,  9.97s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:22<00:17,  8.79s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:28<00:08,  8.01s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:55<00:00, 11.08s/it]\u001b[A\n",
      " 12%|█████████▊                                                                         | 2/17 [01:27<09:42, 38.86s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:02<00:11,  2.98s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:06<00:09,  3.29s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:13<00:08,  4.36s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:36<00:09,  9.82s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:44<00:00,  8.91s/it]\u001b[A\n",
      " 18%|██████████████▋                                                                    | 3/17 [02:13<09:32, 40.91s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:52<03:29, 52.37s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [01:21<02:15, 45.29s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [01:45<01:17, 38.87s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:51<00:29, 29.20s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:56<00:00, 23.30s/it]\u001b[A\n",
      " 24%|███████████████████▌                                                               | 4/17 [04:11<13:51, 63.94s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|██████████████                                                                      | 1/6 [00:03<00:17,  3.45s/it]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 2/6 [00:07<00:14,  3.54s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [00:15<00:14,  4.93s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [00:22<00:10,  5.47s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [00:26<00:05,  5.16s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:37<00:00,  6.20s/it]\u001b[A\n",
      " 29%|████████████████████████▍                                                          | 5/17 [04:50<11:20, 56.69s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:31<00:00, 31.29s/it]\u001b[A\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [05:23<09:02, 49.34s/it]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:26<01:18, 26.02s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:39<00:44, 22.30s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:45<00:17, 17.49s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:05<00:00, 16.27s/it]\u001b[A\n",
      " 41%|██████████████████████████████████▏                                                | 7/17 [06:29<09:04, 54.40s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:15<00:15, 15.27s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:25<00:00, 12.66s/it]\u001b[A\n",
      " 47%|███████████████████████████████████████                                            | 8/17 [06:55<06:53, 45.96s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:17<00:00, 17.87s/it]\u001b[A\n",
      " 53%|███████████████████████████████████████████▉                                       | 9/17 [07:14<05:02, 37.85s/it]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:24<01:13, 24.60s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [01:25<01:10, 35.48s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [01:36<00:28, 28.22s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:44<00:00, 26.00s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▏                                 | 10/17 [08:59<06:46, 58.03s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:17<00:17, 17.12s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:27<00:00, 13.88s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [09:28<04:55, 49.26s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.37s/it]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 12/17 [09:42<03:13, 38.78s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:11<00:11, 11.14s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:38<00:00, 19.29s/it]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████████▋                   | 13/17 [10:22<02:35, 38.99s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:22<00:22, 22.66s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:41<00:00, 20.86s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [11:05<02:00, 40.14s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:08<00:08,  8.93s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:33<00:00, 16.92s/it]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 15/17 [11:40<01:17, 38.57s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.83s/it]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [11:52<00:30, 30.82s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.18s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [11:58<00:00, 42.29s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_location = r'D:\\Ani\\Thesis\\sciencePG\\Machine Learning Research'\n",
    "for i in tqdm(vol_issue):\n",
    "    url = url_base + '0' + str(i[0]) + '0' + str(i[1])\n",
    "    response = requests.get(url)\n",
    "    soup= BeautifulSoup(response.text, \"html.parser\") \n",
    "    papers = soup.find_all('div', class_ = 'vol_cont')\n",
    "    for paper in tqdm(papers):\n",
    "        title = paper.find('div', class_ = 'content1').find('a').text.strip().replace('\\n', '').replace(':', '').replace('/', '').replace('*', '')\n",
    "        filename = os.path.join(folder_location, title + '.pdf')\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(requests.get(paper.find_all('div', class_ = 'lin')[1].find('a')['href']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_location = r'D:\\Ani\\Thesis\\sciencePG\\Data Mining and Knowledge Discovery'\n",
    "for paper in tqdm(papers):\n",
    "    title = paper.find('div', class_ = 'content1').find('a').text.strip().replace('\\n', '').replace(':', '').replace('/', '')\n",
    "    filename = os.path.join(folder_location, title + '.pdf')\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(paper.find_all('div', class_ = 'lin')[1].find('a')['href']).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
